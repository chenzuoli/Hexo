<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[kafka集群搭建]]></title>
    <url>%2F2019%2F08%2F31%2Fkafka%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[kafka，领英开源消息队列框架，在大数据实时、批处理过程中，充当缓冲、中间存储、解耦的组件，深得工程师的喜爱，下面看下如何搭建。 1、软件环境搭建好的zookeeper集群下载kafka安装包 2、安装、修改配置文件12tar -zxvf kafka_*.tgz -C /usr/local/cd /usr/local/kafka/config 2.1修改配置文件12345678910111213vim server.propertiesbroker.id=1/* 这是这台虚拟机上的值，在另外两台虚拟机上应该是2或者3，这个值是唯一的，每台虚拟机或者叫服务器不能相同。 // 设置本机IP和端口。 我这里设置的是listeners，也可以直接设置host.name=192.168.172.10,port=9092,这个IP地址也是与本机相关的，每台服务器上设置为自己的IP地址。 /listeners=PLAINTEXT://192.168.172.10:9092advertised.listeners=PLAINTEXT://x.x.x.x:9092 //外部访问// 该端口默认是9092// 在og.retention.hours=168下面新增下面三项 #默认消息的最大持久化时间，168小时，7天message.max.byte=5242880 #消息保存的最大值5M default.replication.factor=2 #kafka保存消息的副本数，如果一个副本失效了，另一个还可以继续提供服务replica.fetch.max.bytes=5242880 #取消息的最大直接数/ 设置zookeeper的连接端口，新版本的kafka不再使用zookeeper而是通过brokerlist的配置让producer直接连接broker，这个brokerlist可以配置多个，只要有一个能连接上，就可以让producer获取道集群中的其他broker的信息，绕过了zookeeper。因此这个zookeeper.connect可以设置多个值 */zookeeper.connect=192.168.172.12:2181,192.168.172.11:2181,192.168.172.10:2181 3、启动kafka首先要启动kafka集群，并且是三台都要手动去启动。// 进入kafka的bin目录cd /opt/kafka/kafka_2.11-1.0.0/bin/// 启动kafka./kafka-server-start.sh -daemon ../config/server.properties &amp; //-daemon代表着以后台模式运行kafka集群，这样kafka的启动就不会影响我们继续在控制台输入命令。//查看服务是否正常jps 4、创建topic，测试4.1创建topic创建Topic1./kafka-topics.sh --create --zookeeper 10.0.0.60:2181 --replication-factor 2 --partitions 1 --topic shuaige // 解释 123--replication-factor 2 #复制两份--partitions 1 #创建1个分区--topic #主题为shuaige ‘’’在一台服务器上创建一个发布者’’’ 创建一个broker，发布者123./kafka-console-producer.sh --broker-list 10.0.0.60:9092 --topic shuaige&apos;&apos;&apos;在一台服务器上创建一个订阅者&apos;&apos;&apos;./kafka-console-consumer.sh --zookeeper localhost:2181 --topic shuaige --from-beginning 4.2 查看topic1./kafka-topics.sh --list --zookeeper localhost:2181 4.3 查看topic状态1/kafka-topics.sh --describe --zookeeper localhost:12181 --topic shuaige 下面是显示信息Topic:ssports PartitionCount:1 ReplicationFactor:2 Configs: Topic: shuaige Partition: 0 Leader: 1 Replicas: 0,1 Isr: 1//分区为为1 复制因子为2 他的 shuaige的分区为0//Replicas: 0,1 复制的为0，1 4.4 创建kafka topic1bin/kafka-topics.sh --zookeeper node01:2181 --create --topic t_cdr --partitions 30 --replication-factor 2 注： partitions指定topic分区数，replication-factor指定topic每个分区的副本数 partitions分区数: partitions ：分区数，控制topic将分片成多少个log。可以显示指定，如果不指定则会使用broker(server.properties)中的num.partitions配置的数量 虽然增加分区数可以提供kafka集群的吞吐量、但是过多的分区数或者或是单台服务器上的分区数过多，会增加不可用及延迟的风险。因为多的分区数，意味着需要打开更多的文件句柄、增加点到点的延时、增加客户端的内存消耗。 分区数也限制了consumer的并行度，即限制了并行consumer消息的线程数不能大于分区数 分区数也限制了producer发送消息是指定的分区。如创建topic时分区设置为1，producer发送消息时通过自定义的分区方法指定分区为2或以上的数都会出错的；这种情况可以通过alter –partitions 来增加分区数。 replication-factor副本 replication factor 控制消息保存在几个broker(服务器)上，一般情况下等于broker的个数。 如果没有在创建时显示指定或通过API向一个不存在的topic生产消息时会使用broker(server.properties)中的default.replication.factor配置的数量查看所有topic列表1bin/kafka-topics.sh --zookeeper node01:2181 --list 查看指定topic信息 1bin/kafka-topics.sh --zookeeper node01:2181 --describe --topic t_cdr 控制台向topic生产数据 1bin/kafka-console-producer.sh --broker-list node86:9092 --topic t_cdr 控制台消费topic的数据 1bin/kafka-console-consumer.sh --zookeeper node01:2181 --topic t_cdr --from-beginning 查看topic某分区偏移量最大（小）值 1bin/kafka-run-class.sh kafka.tools.GetOffsetShell --topic hive-mdatabase-hostsltable --time -1 --broker-list node86:9092 --partitions 0 注： time为-1时表示最大值，time为-2时表示最小值增加topic分区数, 为topic t_cdr 增加10个分区 1bin/kafka-topics.sh --zookeeper node01:2181 --alter --topic t_cdr --partitions 10 删除topic，慎用，只会删除zookeeper中的元数据，消息文件须手动删除 1bin/kafka-run-class.sh kafka.admin.DeleteTopicCommand --zookeeper node01:2181 --topic t_cdr 查看topic消费进度这个会显示出consumer group的offset情况， 必须参数为–group， 不指定–topic，默认为所有topic 1234567891011121314151617Displays the: Consumer Group, Topic, Partitions, Offset, logSize, Lag, Owner for the specified set of Topics and Consumer Groupbin/kafka-run-class.sh kafka.tools.ConsumerOffsetCheckerrequired argument: [group]Option Description------ -------------broker-info Print broker info--group Consumer group.--help Print this message.--topic Comma-separated list of consumertopics (all topics if absent).--zkconnect ZooKeeper connect string. (default: localhost:2181)Example,bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --group pvGroup Topic Pid Offset logSize Lag Ownerpv page_visits 0 21 21 0 nonepv page_visits 1 19 19 0 nonepv page_visits 2 20 20 0 none 以上图中参数含义解释如下： 123456topic：创建时topic名称pid：分区编号offset：表示该parition已经消费了多少条messagelogSize：表示该partition已经写了多少条messageLag：表示有多少条message没有被消费。Owner：表示消费者 细看kafka-run-class.sh脚本，它是调用 了ConsumerOffsetChecker的main方法，所以，我们也可以通过java代码来访问scala的ConsumerOffsetChecker类，代码如下： 12345678910111213import kafka.tools.ConsumerOffsetChecker;/** * kafka自带很多工具类，其中ConsumerOffsetChecker能查看到消费者消费的情况, * ConsumerOffsetChecker只是将信息打印到标准的输出流中 * */public class RunClass &#123; public static void main(String[] args) &#123; //group-1是消费者的group名称,可以在zk中 String[] arr = new String[]&#123;&quot;--zookeeper=192.168.199.129:2181,192.168.199.130:2181,192.168.199.131:2181/kafka&quot;,&quot;--group=group-1&quot;&#125;; ConsumerOffsetChecker.main(arr); &#125;&#125; 5、日志说明默认kafka的日志是保存在/opt/kafka/kafka_2.10-0.9.0.0/logs目录下的，这里说几个需要注意的日志server.log #kafka的运行日志state-change.log #kafka他是用zookeeper来保存状态，所以他可能会进行切换，切换的日志就保存在这里controller.log #kafka选择一个节点作为“controller”,当发现有节点down掉的时候它负责在游泳分区的所有节点中选择新的leader,这使得Kafka可以批量的高效的管理所有分区节点的主从关系。如果controller down掉了，活着的节点中的一个会备切换为新的controller. 6、 Kafka-manager（v2.0.0.2）（Kafka集群可视化管理）6.1 sbt编译123curl https://bintray.com/sbt/rpm/rpm &gt; bintray-sbt-rpm.repomv bintray-sbt-rpm.repo /etc/yum.repos.d/yum install sbt 检查sbt是否安装成功 1sbt version 6.2 安装部署kafka-manager12wget https://github.com/yahoo/kafka-manager/releases/kafka-manager-2.0.0.2.tar.gztar zxvf kafka-manager-2.0.0.2.tar.gz -C /usr/local 编译kafka-manager 12cd /usr/local/kafka-manager-2.0.0.2./sbt clean dist //需要一段时间 编译结果查看 1ls /usr/local/kafka-manager-2.0.0.2/target/universal/ //存在kafka-manager-2.0.0.2.zip 创建目录kafka-manager12mkdir -p /usr/local/kafka-managercp /usr/local/kafka-manager-2.0.0.2/target/universal/kafka-manager-2.0.0.2.zip /usr/local/kafka-manager 解压文件 1unzip kafka-manager-2.0.0.2.zip 修改配置文件 1vim /usr/local/kafka-manager/kafka-manager-2.0.0.2/conf/application.conf 修改信息 1234单机：kafka-manager.zkhosts=&quot;localhost:2181&quot;集群：kafka-manager.zkhosts=&quot;node3.cn:2181,node4.cn:2181,node5.cn:2181&quot; 6.3启动kafka-manager控制台启动 1bin/kafka-manager 后台守护启动 1nohup bin/kafka-manager &amp; 后台启动通过 -Dhttp.port，指定端口; -Dconfig.file=conf/application.conf指定配置文件 1nohup bin/kafka-manager -Dconfig.file=conf/application.conf -Dhttp.port=8080 &amp;]]></content>
      <categories>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建zookeeper集群]]></title>
    <url>%2F2019%2F08%2F31%2F%E6%90%AD%E5%BB%BAzookeeper%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[zookeeper作为一个hadoop生态组件的连接器，在节点服务之间的通信及元数据管理上起着非常重要的作用，下面看看搭建步骤。 1、软件环境Linux服务器。使用数量为一台，三台，五台，（2*n+1）。zookeeper集群的工作是超过半数才能对外提供服务，三台中超过两台超过半数，允许一台挂掉。最好不要使用偶数台。例如：如果有4台，那么挂掉一台还剩下三台，如果再挂掉一台就不能行了，因为是要超过半数。 Java jdk1.8 zookeeper包 2、配置与安装zookeeper配置文件zoo.cfg12345678910111213141516tar -zxvf zookeeper-*.tar.gz -C /usr/localcd /usr/local/zookeeper/confcp zoo_sample.cfg zoo.cfgvim zoo.cfgtickTime=2000initLimit=10syncLimit=5dataDir=/usr/local/zookeeper/zkdatadataLogDir=/usr/local/zookeeper/zkdatalogclientPort=2181// 此处的IP就是你所操作的三台虚拟机的IP地址，每台虚拟机的zoo.cfg中都需要填入这三个地址。第一个端口是master和slave之间的通信端口，默认是2888，第二个端口是leader选举的端口，集群刚启动的时候选举或者leader挂掉之后进行新的选举的端口默认是3888server.1=192.168.172.10:2888:3888server.2=192.168.172.11:2888:3888server.3=192.168.172.12:2888:3888// server.1 这个1是服务器的标识也可以是其他的数字， 表示这个是第几号服务器，用来标识服务器，这个标识要写到快照目录下面myid文件里创建myid文件。以现在所在的第一台虚拟机192.168.172.10为例，对应server.1，通过上边的配置信息可以查到。创建myid文件的目的是为了让zookeeper知道自己在哪台服务器上，例如现在所在的虚拟机是192.168.172.10，它对应的id是1，那么就在myid文件中写入1. 节点id配置1234echo &quot;1&quot; &gt; /usr/local/zookeeper/zkdata/myid另外两台虚拟机上也需要创建myid文件并写入相应的id，id根据zoo.cfg文件中的IP地址查询。echo &quot;2&quot; &gt; /usr/local/zookeeper/zkdata/myidecho &quot;3&quot; &gt; /usr/local/zookeeper/zkdata/myid 3、启动zookeeper12345cd /usr/local/zookeeper/bin// 启动服务 (注意！三台虚拟机都要进行该操作)./zkServer.sh start// 检查服务器状态./zkServer.sh status // 显示如下JMX enabled by defaultUsing config: /opt/zookeeper/zookeeper-3.4.6/bin/../conf/zoo.cfgMode: follower #他是主节点leader还是从节点follower 4、补充说明1. myid文件和server.myid在快照目录下存放的标识本台服务器的文件，他是整个zk集群用来发现彼此的一个重要标识，myid必须与zoo.cfg配置中的 server.? 一致。 2. zoo.cfg配置文件zoo.cfg文件是zookeeper配置文件，在conf目录里。 123456789101112// tickTime：这个时间是作为 Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。// initLimit：这个配置项是用来配置 Zookeeper 接受客户端（这里所说的客户端不是用户连接 Zookeeper 服务器的客户端，而是 Zookeeper 服务器集群中连接到 Leader 的 Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过 5个心跳的时间（也就是 tickTime）长度后 Zookeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 52000=10 秒// syncLimit：这个配置项标识 Leader 与Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个 tickTime 的时间长度，总的时间长度就是52000=10秒// dataDir：快照日志的存储路径// dataLogDir：事物日志的存储路径，如果不配置这个那么事物日志会默认存储到dataDir制定的目录，这样会严重影响zk的性能，当zk吞吐量较大的时候，产生的事物日志、快照日志太多// clientPort：这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。修改他的端口改大点]]></content>
      <categories>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink学习]]></title>
    <url>%2F2019%2F08%2F26%2FFlink%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[flink，号称第二代实时大数据计算引擎，被他的名头吸引过来，我也来学习学习，下面是我在学习过程中遇到的一些问题和解决方案。 如何保证数据处理的有序性&nbsp;&nbsp;&nbsp;&nbsp;flink通过watermark来解决这个问题。当使用事件时间来进行对事件排序时，很有必要跟踪事件的处理时间，例如在一个窗口操作t到t+5中，只有当系统能够保证没有数据的事件时间小于t+5时，然后对这个窗口中的数据进行排序计算，才是保证数据处理的有序性，那么如何确定没有数据的事件时间小于t+5呢？flink是使用watermark来确定的，它会追踪穿过系统中的每一条数据，当它知道没有数据对应的时间戳小于t1后，它会将这个t1水印广播📢到下流operators，一旦watermark被提交，下流operators在获取watermark值时就会发现并作出相应的反应。&nbsp;&nbsp;&nbsp;&nbsp;在窗口操作中，窗口会等待t+5的watermark，然后触发计算，并向下游广播t+5的watermark。&nbsp;&nbsp;&nbsp;&nbsp;当所有的operater都在等待他的watermark和输入数据时，系统会被延时，从而影响时效性。&nbsp;&nbsp;&nbsp;&nbsp;下图是实际水印、事件时间与处理时间之间的关系： you can see the original document at this link Time and Order in Streams 学习使我快乐。]]></content>
      <categories>
        <category>大数据</category>
        <category>实时计算</category>
      </categories>
      <tags>
        <tag>flink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温《头号玩家》VR游戏中的区块链世界]]></title>
    <url>%2F2019%2F08%2F19%2F%E9%87%8D%E6%B8%A9%E3%80%8A%E5%A4%B4%E5%8F%B7%E7%8E%A9%E5%AE%B6%E3%80%8BVR%E6%B8%B8%E6%88%8F%E4%B8%AD%E7%9A%84%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%96%E7%95%8C%2F</url>
    <content type="text"><![CDATA[2018年上映的电影《头号玩家》，得到许多年轻人的喜爱，故事情节紧凑而又丰富，其中包含许多区块链世界的元素，咱们一起探讨下吧。 2019-08-25更新———————————— 游戏中通用的金币、不同的游乐场景、统一的入口等等，貌似现在的区块链世界。比特币、以太坊、比特现金，谁会是区块链游戏中的通用货币呢？每个玩家都有自己的唯一私钥，可以访问不同区域不同游戏，音乐、电影、游戏、运动等等，应有尽有，其中私钥就是区块链世界的入口。而且金币可以买现实世界中的物品，所以金币属于虚拟资产，类似现在的Q币、游戏币等等。你们觉得这种游戏会在现实中出现吗？我觉得可能，中心化的游戏，为并发和性能提供支持，区块链实现资产的去中心化，不受别人控制。所有如何实现centralized app与decentralized app之间的交互呢？]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>头号玩家</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[以太坊]]></title>
    <url>%2F2019%2F08%2F18%2F%E4%BB%A5%E5%A4%AA%E5%9D%8A%2F</url>
    <content type="text"><![CDATA[以太坊 Do you like it? layer2扩展解决方案 侧链loom network 我的加密英雄 plasma 2019-08-25更新———————————— Ethereum2.0研发计划阶段0:信标链主要负责管理权益证明协议的运行，并协调所有独立的平行分片，他是整个开发中最复杂的部分，详情请看信标链 阶段1:分片链主要实现将验证者分散在1024条分片链上，点对点网络以足够快的速度与验证者之间准确无误的进行通信。 阶段2:执行层提供巨大的设计空间和无拘无束的开发氛围，提供一些不同的执行环境，例如代币转账执行环境（匿名），智能合约语言执行环境，为处理高容量Plasma侧链而优化的执行环境，以及为企业用户量身打造的执行环境，具备许可性和隐私性。 当你累了的时候，停下来做个梦吧。愿你坚持到底。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>以太坊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[拜占庭问题]]></title>
    <url>%2F2019%2F08%2F18%2F%E6%8B%9C%E5%8D%A0%E5%BA%AD%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[拜占庭问题，即去中心化网络的一致性问题。 一、问题&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;拜占庭帝国想要进攻一个强大的敌人，为此派出了 10 支军队去包围这个敌人。这个敌人虽不比拜占庭帝国，但也足以抵御 5 支常规拜占庭军队的同时袭击。这 10 支军队在分开的包围状态下同时攻击。他们任一支军队单独进攻都毫无胜算，除非有至少 6 支军队（一半以上）同时袭击才能攻下敌国。他们分散在敌国的四周，依靠通信兵骑马相互通信来协商进攻意向及进攻时间。困扰这些将军的问题是，他们不确定他们中是否有叛徒，叛徒可能擅自变更进攻意向或者进攻时间。在这种状态下，拜占庭将军们才能保证有多于 6 支军队在同一时间一起发起进攻，从而赢取战斗？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;先看在没有叛徒情况下，假如一个将军 A 提一个进攻提议（如：明日下午 1 点进攻，你愿意加入吗？）由通信兵通信分别告诉其他的将军，如果幸运中的幸运，他收到了其他 6 位将军以上的同意，发起进攻。如果不幸，其他的将军也在此时发出不同的进攻提议（如：明日下午 2 点、3 点进攻，你愿意加入吗？），由于时间上的差异，不同的将军收到（并认可）的进攻提议可能是不一样的，这是可能出现 A 提议有 3 个支持者，B 提议有 4 个支持者，C 提议有 2 个支持者等等。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;再加一点复杂性，在有叛徒情况下，一个叛徒会向不同的将军发出不同的进攻提议（通知 A 明日下午 1 点进攻， 通知 B 明日下午 2 点进攻等等），一个叛徒也会可能同意多个进攻提议（即同意下午 1 点进攻又同意下午 2 点进攻）。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;叛徒发送前后不一致的进攻提议，被称为 “拜占庭错误”，而能够处理拜占庭错误的这种容错性称为「Byzantine fault tolerance」，简称为 BFT。 二、解决方案1. 中本聪的解决方案: 工作量证明机制（POW）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在出现比特币之前，解决分布式系统一致性问题主要是 Lamport 提出的 Paxos 算法或其衍生算法。Paxos 类算法仅适用于中心化的分布式系统，这样的系统的没有不诚实的节点（不会发送虚假错误消息，但允许出现网络不通或宕机出现的消息延迟）。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;中本聪在比特币中创造性的引入了 “工作量证明（POW : Proof of Work）” 来解决这个问题，有兴趣可进一步阅读工作量证明。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过工作量证明就增加了发送信息的成本，降低节点发送消息速率，这样就以保证在一个时间只有一个节点 (或是很少) 在进行广播，同时在广播时会附上自己的签名。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个过程就像一位将军 A 在向其他的将军（B、C、D…）发起一个进攻提议一样，将军 B、C、D… 看到将军 A 签过名的进攻提议书，如果是诚实的将军就会立刻同意进攻提议，而不会发起自己新的进攻提议。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以上就是比特币网络中是单个区块（账本）达成共识的方法（取得一致性）。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;理解了单个区块取得一致性的方法，那么整个区块链（总账本）如果达成一致也好理解。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们稍微把将军问题改一下：假设攻下一个城堡需要多次的进攻，每次进攻的提议必须基于之前最多次数的胜利进攻下提出的（只有这样敌方已有损失最大，我方进攻胜利的可能性就更大），这样约定之后，将军 A 在收到进攻提议时，就会检查一下这个提议是不是基于最多的胜利提出的，如果不是（基于最多的胜利）将军 A 就不会同意这样的提议，如果是的，将军 A 就会把这次提议记下来。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这就是比特币网络最长链选择。 2. 权益证明机制（POS）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;工作量证明其实相当于提高了做叛徒（发布虚假区块）的成本，在工作量证明下，只有第一个完成证明的节点才能广播区块，竞争难度非常大，需要很高的算力，如果不成功其算力就白白的耗费了（算力是需要成本的），如果有这样的算力作为诚实的节点，同样也可以获得很大的收益（这就是矿工所作的工作），这也实际就不会有做叛徒的动机，整个系统也因此而更稳定。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;很多人批评工作量证明造成巨大的电力浪费，促使人们去探索新的解决一致性（共识）问题的机制：权益证明机制（POS: Proof of Stake）是一个代表。在拜占庭将军问题的角度来看，它同样提高了做叛徒的成本，因为账户需要首先持有大量余额才能有更多的几率广播区块。 2019-08-25更新————————————当你累了的时候，停下来做个梦吧。愿你坚持到底。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>拜占庭问题,拜占庭容错</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发与并行]]></title>
    <url>%2F2019%2F08%2F18%2F%E5%B9%B6%E5%8F%91%E4%B8%8E%E5%B9%B6%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[下面一张图片可以让你更好地理解程序中的并发与并行之间的区别： 更详细的信息，请参考链接https://golangbot.com/concurrency/]]></content>
      <categories>
        <category>计算机语言</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>并行</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DAPP到底是什么？]]></title>
    <url>%2F2019%2F08%2F14%2FDAPP%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[什么是Dapp，相比较于app，有什么不同？ 一、什么是Dapp？DAPP是Decentralized Application的缩写，即去中心化应用，也有人称为分布式应用。它被认为开启了区块链3.0时代。DAPP就是在底层区块链平台衍生的各种分布式应用，是区块链世界中的服务提供形式。DAPP之于区块链，有些类似APP之于IOS和Android。 二、Dapp的特点 1.Dapp通过网络节点去中心化操作可以运行在用户的个人设备之上，比如：手机、个人电脑。永远属于用户，也可以自由转移给任何人。2.运行在对等网络上不依赖中心服务器，不需要专门的通信服务器传递消息，也不需要中心数据库来记数据。数据保存在用户个人空间，可能是手机，也可能是个人云盘。3.数据加密后存储在区块链上可以依托于区块链进行产权交易、销售，承载没有中介的交易方式。4.参与者信息被安全存储可以保护数字资产，保证产权不会泄露、被破坏。5.Dapp必须开源、自治可以由用户自由打包生成，签名标记所属权。它的发布不受任何机构限制。 各种创意与创新可以自由表达和实现。 三、Dapp与app的区别从客户体验角度APP相对于DAPP有四大问题，一是截留用户数据，二是垄断生态平台，三是保留用户权利，四是限制产品标准扼杀创新。但是由于Dapp得到的是去中心化，所以响应速度固然没有中心化服务器快。从技术角度DAPP与APP区别主要有两个方面，一是APP在安卓或苹果系统上安装并运行；DAPP在区块链公链上开发并结合智能合约；二是APP信息存储在数据服务平台，可以运营方直接修改；DAPP数据加密后存储在区块链，难以篡改。 四、Dapp的分类根据去中心化的对象，DAPP可以进行分类。对于一个中心化服务器而言，包括计算、存储能力，以及所产生的数据三个方面，而由数据之前的关联度又产生了某种特定的“关系”。因此一般而言，去中心化包括以下几类： 1.基于计算能力的去中心化（Pow机制）2.基于存储能力的去中心化（IPFS）3.基于数据的去中心化（Steemit）4.基于关系的去中心化（去中心化ID）]]></content>
      <categories>
        <category>区块链</category>
        <category>Dapp</category>
      </categories>
      <tags>
        <tag>Dapp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言学习]]></title>
    <url>%2F2019%2F08%2F10%2Fgo%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[go语言: 面向对象、强类型、类似c的语言。 1.同一个目录下面不能有多个package main，分到不同的文件夹中即可；2.go test *_test.go是golang特有的约定，为测试文件: go run: cannot run *_test.go files; go test 默认执行当前目录下以xxx_test.go的测试文件; go test -v 可以看到详细的输出信息; go test -v xxx_test.go 指定测试单个文件，但是该文件中如果调用了其它文件中的模块会报错; go test -v -test.run Testxxx, 该测试会测试包含该函数名的所有函数. 函数修饰符view：只能读取数据，不能更改数据；修饰符pure：不访问程序中的数据，他的返回值完全取决于传入的参数 测试代码见github 2019-08-25更新————————————当你累了的时候，停下来做个梦吧。愿你坚持到底。 2019-09-01————————————推荐给大家一个非常好的入门学习中文网站，里面很全，从基本数据类型、语法，到协程并发、高阶函数、类、多态等。go语言中文网 panic和recover参考文档：panic和recover 头等函数参考文档：头等函数 反射参考文档：反射 读取文件参考文档：读取文件 写入文件/并发写入参考文档：写入文件/并发写入 当你累了的时候，停下来做个梦吧。愿你坚持到底。]]></content>
      <categories>
        <category>计算机语言</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[比原链-共享经济平台简介]]></title>
    <url>%2F2019%2F08%2F04%2F%E6%AF%94%E5%8E%9F%E9%93%BE-%E5%85%B1%E4%BA%AB%E7%BB%8F%E6%B5%8E%E5%B9%B3%E5%8F%B0%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[Origin Protocol ：基于以太坊，开源的共享经济平台，是否能够成功呢？ Origin Protocol ：基于以太坊，开源的共享经济平台诸如Airbnb、Uber、Craigslist、WeWork等共享经济公司出现之后，共享经济改变了整个商业世界的规则：消费者更喜欢去拥有一个事物的使用权，而不是所有权；而服务提供者从自己提供服务变成了生产者和消费者之间连接的纽带。整个商业模式发生了变化。 到2016年为止，美国有大约22%成年人成为了共享经济的供应商，共享经济平台的收入在2017年是186亿美元，而据估计在2022年会达到400多亿美元，这是一个巨大的市场。 痛点现有市场还存在哪些问题呢？ 首先，价值的分配是不公平的。都说第一个吃螃蟹的人能够获取更多的利益，但是第一个开Uber、第一个给Airbnb提供房间的人并没有因为自己是早期参与者（共建者）而受益，利益全部都在公司本身手里。 其次，高昂的终结费用。Airbnb对房客收取5%-15%手续费，对房东也收取3%-5%，Uber也会对司机和乘客收取类似比例的费用。并且在平台做大之后，他们为了垄断会把收入用在阻碍创新上。 然后，还有数据的所有权、安全性等问题。 其实上述的问题都是中心化平台出现的问题。Origin Protocol就是为解决上述的痛点开发的。 ￼ 简介Origin Protocol是基于以太坊上的共享经济平台，并用IPFS解决文件的存储问题，在分布式网络环境中促进开放、免费的服务交换。平台主要由三个部分组成： 1、 Origin Dapp：分布式应用（Dapp）服务提供者能够锁定一定的代币作为抵押来创建列表，让用户搜索服务，在Dapp中能够利用法币、ERC20代币来进行结算。在不同垂直行业可以开发不同的应用来做到定制化。并且，在Origin Protocol中注册的用户能够方便地访问基于Origin Protocol的所有应用。 2、 Origin 共享数据层和标准共享数据层能够让所有人都能够访问数据库。这些数据存储在IPFS和以太坊中，任何人都可以从中获取到列表项目、交易记录和买卖双方的信誉评级，从而能够被信任。 3、 Origin 社区基金很大一部分的资金会交与基金管理，保证平台的长期发展。基金需要负责；项目管理、项目的孵化、雇佣开发者编写以及审核代码、财务和技术审核、提供仲裁服务等。 4、Origin Protocol的特点用智能合约保证价值的点对点传播（无中介，安全可靠） 支持数百种列表类型，提供多元化的服务 用共享数据鼓励创新 利用区块链技术保证数据和身份的安全 5、团队目前，Origin的核心团队有10名成员，延伸团队有8名成员，涵盖了技术团队、社群运营专家、商业产品团队，具备了项目研发、商业落地的人力资源。核心成员来自伯克利、斯坦福等高校，拥有丰富的创业经验，其创业项目被沃尔玛、雅虎等公司收购。首席区块链工程师曾任Sphero（知名智能玩具公司）的核心技术工程师，技术团队都拥有软硬件开发的从业经历。总的来说，这是一个组成完备，从业经验丰富的团队。￼ 6、Origin Protocol代币技术层面上Origin Protocol的代币是十分复杂的，具体可以参考白皮书。一句话来说，代币的作用是用正面和负面的激励来确保平台的安全、实现管理并且促进买卖双方的交易。 一个具体的场景是，为了避免垃圾信息，卖家在实施相关措施的时候需要抵押一定的代币，通过“押金-质疑-投票”机制，鼓励用户抵押等量代币，标记出质疑的内容，社区进行投票，胜利方可以获得这些代币，通过这样的机制来避免垃圾信息。 具体代币分配暂未公布。 目前在COINLIST上开放投资者注册通道，不允许中国投资者参与，请需要参加的准备好相关材料。 7、开发路线Origin Protocol项目从17年五月开始，12月份就推出了测试网络，预计在18年第三季度完成平台的开发，19年达到去中心化并且正式运行。 合作伙伴 官网上列出大量合作伙伴，并且有不少团队已经开始基于Origin Protocol的app开发。 ￼ 总结总体来看，Origin Protocol相比于各类提出4.0、5.0概念的公链，是一个十分落地的项目，并且已经与大量的企业建立合作关系。目前Origin Protocol的测试网络已经上线，我们期待未来Origin Protocol的发展。 官网：https://www.originprotocol.com 白皮书：https://www.originprotocol.com/en/product-brief DEMO视频：https://demo.originprotocol.com 个人观点比原链如何避免共享平台的垃圾信息、虚假信息呢？比原链的解决方案是，卖家在实施相关措施的时候需要抵押一定的代币，通过“押金-质疑-投票”机制，鼓励用户抵押等量代币，标记出质疑的内容，社区进行投票，胜利方可以获得这些代币，通过这样的机制来避免垃圾信息。那在所有人都可以参与的情况下，如何保证刷单的事情发生呢？卖家同时拥有许多账号，并且进行投票给自己的竞争对手，此时，就会形成恶性竞争。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>比原链</tag>
        <tag>公链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[公链如此多，而应用却寥寥无几]]></title>
    <url>%2F2019%2F08%2F04%2F%E5%85%AC%E9%93%BE%E5%A6%82%E6%AD%A4%E5%A4%9A%EF%BC%8C%E8%80%8C%E5%BA%94%E7%94%A8%E5%8D%B4%E5%AF%A5%E5%AF%A5%E6%97%A0%E5%87%A0%2F</url>
    <content type="text"><![CDATA[现在很多公司都在开发自己的公链，真正应用落地的很少，其中包括IBM开源，贡献给Linux基金会的HyperLedger，另一个就是以太坊了。 下面来看看为什么？ 现在很多公司都在开发自己的公链。创业团队在开发公链，一些加密数字货币交易所也在开发公链。我曾经见过一个由三个年轻人组成的创业团队，不仅开发了自己的公链，而且还提出了一个新的共识算法。但目前的公链市场却出现了一个非常尴尬的局面，一方面是公链产品无穷多，但另外一方面却是公链落地的项目寥寥无几。显然在区块链产品落地应用方面，出现了明显的脱节。当然任何一个新技术的落地应用都需要一段时间。对于区块链技术这个从根本上改变现有的以中心化技术为基础的计算模式的新技术来说，其应用落地的时间就更长。但在目前的公链产品落地应用的过程中，还是有些方面可以改进，以此来加速公链技术应用落地的。在当前的社会中，其实不缺区块链应用的落地场景。市场中的很多问题实际上都能应用区块链能得到非常好的解决。区块链技术的最强项是采用完全信息真实透明的方式杜绝欺诈，是用技术的方式保证多方的合作顺利完成。如果从这个角度看，现实中太多的问题都可以用区块链来解决了。譬如个人借贷的违约方面。违约者的一个主要动机就是因为违约成本非常低。他可以欺诈了一个出借方之后，再去欺诈另外一个欺诈方。但是如果每个人的信贷记录都真实无误地记录在公链上，任何个人和机构都能查到这个借贷记录，那么借贷者进行欺诈动机就小多了。对于一直没有被现有的金融机构服务到的客户来说，如果其在金融机构之外的各种借贷记录都真实无误的记录在区块链上，那么他个人的信用历史就是真实可信的。金融机构就可以基于这个信用向其进行贷款，因为在这个过程中，征信的成本几乎为零，而征信成本过高正是金融机构不愿意进行贷款的一个原因。在公司的层面，同样存在着大量的可以应用区块链技术的地方，譬如贸易金融和银团的联合贷款。在证券领域，区块链技术除了在交易后清算之外，另外一个最直接的应用就是投行项目的融资过程。由于上市的收获巨大，所以在这个过程中，各个参与者在各个融资阶段铤而走险进行欺诈的案例屡见不鲜。在这个过程中的一个主要欺诈方面就是信息作假。如果采用区块链技术来管理这个流程，每个参与者都需要为自己上传到链上的信息负责，那么每个参与者作假的动机就会大幅减小。即使有人铤而走险进行造假，那么此后的法律诉讼过程中的取证就非常容易，也就容易形成及时公正的判决。那么为什么现实中有这么多的需求，但于此同时基于区块的应用却为什么这么少？在这个方面既有产品通常规律中犯错的地方，也有区块链技术应用的具体问题。 1、产品同市场的需求不匹配首先，造成这种局面的原因主要还是产品与市场需求的不匹配，也就是缺少 Product Market Fit. 一些区块链技术的开发方专注于解决区块链技术本身的问题，而忽略了解决其技术应该解决的市场中的问题。一些公链项目总是在宣扬自己的产品的性能如何好，能达到多少的 TPS。但这个卖点本身就是错误的定位。首先，一个企业级技术产品的衡量指标不只是性能，而且还有稳定性、安全性、权限控制等其他方面。其次，市场中对区块链技术的评价，首先会把它同相应的中心化解决方案相比较。在性能方面，基于区块链的解决方案绝对无法同基于中心化技术的解决方案相比的。所以一味地强调性能根本无法说服市场来接受这个产品。区块链技术最擅长的解决是多方合作中的信任问题。而在现实的场景中，很多这种场景是不需要高性能的。譬如贸易金融的合作过程，又譬如企业融资过程中的各类机构合作的过程。这些过程更注重于性能以外的其他因素，如信息的一致性、权限控制和使用的便捷性等等。如果公链一味地追求性能，那么它就同市场中的真正需求南辕北辙了。 2、高度竞争的领域公链产品定位的另外一个主要错误是在开发一个同以太坊相竞争的普适的公链。但这样的产品定位，其成功的可能性极小。以太坊的问题很多，这是众所周知的。但它已经是经过几年的发展，已经基本上成为市场中默认的公链选择。现在希望取代以太坊的公链创业项目太多了。在这样的高度竞争的环境中，胜出的几率是非常小的。在这个方面，很多公链团队都做出了错误的选择。选择加入到了一个高度竞争的领域。这恰恰违背了一个产品开发的基本规律，就是避开竞争。记得彼得•蒂尔的建议避开竞争的观点吗？避开竞争的一个有效手段就是采用创新的方式来解决市场中的一个问题。因为创新一开始是并不为市场接受，所以并没有太多的竞争者做同样的事情。当创新的方式逐渐为市场接受时，这个创新产品在市场中已经占据稳定的地位了。别的团队就无法再做同样的产品进行竞争。在这个方面，中本聪发明的比特币就是此方面的最好的代表。中本聪的初衷是发行一个电子现金来取代市场中的货币。但是他并没有以直接同现有货币竞争的方式发行一种货币。比特币的金融属性直到多年以后才被市场发现，拥有了众多的用户，并开始对现有的金融市场形成了巨大的挑战。尽管后来也持续不断的有模仿者，但这些模仿者都已经无法对比特币的地位形成挑战了。 3、改变群体行为的困难区块链技术本身的特点也决定它比其它的产品更难被市场接受。这是因为它需要改变的是一个群体行为，而不是一个个体行为。譬如在多方合作的过程中，如果只有一方愿意采用基于区块链的解决方案，但其他它方没有动力的情况下，这个解决方案就没法推动。特别是当其中的一些参与方本来的想法就是利用信息的不透明来为自己谋利。那么如何才能实现区块链技术的快速落地应用呢？首先我认为从技术的角度来切入市场没问题，但更应该从需求的角度来切入市场，也就是说从市场中的一个具体的问题出发，来分析如何用区块链技术来解决这个问题。鉴于目前市场中互不信任和欺诈行为的普遍存在，所以找到这样的场景并不困难。其次才是自己开发或在市场中找到合适的区块链底层来进一步开发。而这样的区块链技术底层并不一定需要各项技术指标方面都十全十美。它只要能对针对需要解决的问题能够令人满意的解决就可以了。看一看目前的国内市场，获得市场欢迎和资本支持的一些成功的区块链项目并不是基于什么技术性能特别好的公链项目，实际上这些项目是利用的只是区块链技术最基本的分布式存储和不可更改的功能。但是这些技术底层为需要解决的问题提供了足够好的技术方案，这就足以创造很好的商业价值了。其次就是不要挑战以中心化技术为基础的现有实力最强的地方。这些领域如零售支付、稳定币、证券和银行领域中的清算。在这些领域中采用区块链技术，产生的收益未必足够大，但遇到的风险和阻力却会非常大，因此在这些领域中应用区块链技术需要非常慎重。第三，一定要用创新的方式解决现有的问题。在这方面，比特币是最优秀的典范。在现有的很多问题中，由于技术、监管、经营习惯和、成本、应用落地所需的时间和风险等方面的考虑，行业中现有的参与者们并没有很强的动力去采用区块链技术、区块链技术的应用一定要找到非常创新，容易被市场接受的地方。尽管这个初始应用的市场并不大，但只要是此方面应用的商业和技术模式具有很强的可扩展性，并且是针对潜在的巨大市场，只要项目方做好商业和技术方面的顶层设计（见我的相关文章区块链时代的顶层设计）；另外，再由于这种创新方式不一定被广泛认可，因此也不会迅速地吸引竞争者，这个方式因此就有足够的时间逐步发展起来。等到市场的各方终于发现这种创新模式的价值的时候，同它的竞争和对它的打压都已经来不及了。这就是在本质上重新复制了比特币的成功模式。 本文摘抄自链接：https://www.jianshu.com/p/58f4cce02e3f]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>公链</tag>
        <tag>区块链</tag>
        <tag>区块链应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018年全球各国谋杀比例]]></title>
    <url>%2F2019%2F08%2F04%2F2018%E5%B9%B4%E5%85%A8%E7%90%83%E5%90%84%E5%9B%BD%E8%B0%8B%E6%9D%80%E6%AF%94%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[Murders rate per 100,000 people, last available year.2018年，每10万人中被谋杀的比例如下： 比例 国家 🇭🇳HON: 90 洪都拉斯 🇻🇪VEN: 54 委内瑞拉 🇧🇷BRA: 25 巴西 🇲🇽MEX 21.5 墨西哥 🇳🇬NIG: 20 尼日尔 🇷🇺RUS: 9.2 俄罗斯 🇵🇰PAK: 7.7 巴基斯坦 🇺🇸USA: 4.7 美国 🇮🇳IND: 3.5 印度 🇹🇷TUR: 2.6 土耳其 🇨🇦CAN: 1.6 加拿大 🇦🇺AUS 1.1 澳大利亚 🇨🇳CHN: 1 中国 🇬🇧GBR: 1 英国 🇫🇷FRA: 1 法国 🇰🇷KOR: 0.9 韩国 🇮🇹ITA: 0.9 意大利 🇩🇪GER: 0.8 德国 🇪🇸ESP: 0.8 西班牙 🇦🇪UAE: 0.7 阿联酋 🇯🇵JPN: 0.3 日本]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>谋杀比例</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿甘正传剪辑]]></title>
    <url>%2F2019%2F08%2F03%2F%E9%98%BF%E7%94%98%E6%AD%A3%E4%BC%A0%E5%89%AA%E8%BE%91%2F</url>
    <content type="text"><![CDATA[var player = new YKU.Player( 'youkuplayer',{ styleid: '0', client_id: 'YOUR YOUKUOPENAPI CLIENT_ID', vid: 'XNDI5NzE3Mzk0MA', newPlayer: true } );]]></content>
      <categories>
        <category>视频剪辑</category>
      </categories>
      <tags>
        <tag>阿甘正传</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[airbnb开源调度系统airflow的一些命令及使用方法]]></title>
    <url>%2F2019%2F08%2F02%2Fairbnb%E5%BC%80%E6%BA%90%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9Fairflow%E7%9A%84%E4%B8%80%E4%BA%9B%E5%91%BD%E4%BB%A4%E5%8F%8A%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[python写的调度系统，用python脚本，动态生成dag，跨dag依赖，是一个不错的调度系统，下面介绍一些我使用过程中用到的命令和问题的解决方案。 1.operator12345678BashOperatorPythonOperatorEmailOperatorHTTPOperatorSqlOperatorSensorDockerOperatorHiveOperator 2.给DAG实例传递参数执行命令 1airflow trigger_dag example_passing_params_via_test_command -c &apos;&#123;&quot;foo&quot;:&quot;bar&quot;&#125;&apos; 代码获取变量： 123def my_py_command(ds, **kwargs):logging.info(kwargs)logging.info(kwargs.get(&apos;dag_run&apos;).conf.get(&apos;foo&apos;)); 3.填补数据1234#清除dag在这段时间内的状态，清除后airflow会自动启动这些任务，如果dag设置了catchup=True;dependency_on_past=True;那么dag会按照时间顺序一天一天跑任务，这对于修补数据很有用哦airflow clear db2src_usersdb_byshell -s 2018-12-01 -e 2018-12-04#回填数据，当新建一个dag，需要补跑以前的数据，回填命令是个不错的选择airflow backfill db2src_usersdb_byshell -s 2018-12-03 -e 2018-12-04 4.根据depend_on_pastTrue or False来判断是否需要依赖start_time前段时间跑的相同的任务情况来运行现在的任务。 5.airflow卡住的问题连接元数据mysql库：select * from task_instance where state = ‘running’; 6.airflow自带变量：12345678910111213141516171819202122232425262728| Variable | Description || :------: | :---------: ||&#123;&#123; ds &#125;&#125; |the execution date as YYYY-MM-DD||&#123;&#123; ds_nodash &#125;&#125; |the execution date as YYYYMMDD||&#123;&#123; yesterday_ds &#125;&#125; |yesterday’s date as YYYY-MM-DD||&#123;&#123; yesterday_ds_nodash &#125;&#125; |yesterday’s date as YYYYMMDD||&#123;&#123; tomorrow_ds &#125;&#125; |tomorrow’s date as YYYY-MM-DD||&#123;&#123; tomorrow_ds_nodash &#125;&#125; |tomorrow’s date as YYYYMMDD||&#123;&#123; ts &#125;&#125; |same as execution_date.isoformat()||&#123;&#123; ts_nodash &#125;&#125; |same as ts without - and :||&#123;&#123; execution_date &#125;&#125; |the execution_date, (datetime.datetime)||&#123;&#123; prev_execution_date &#125;&#125; |the previous execution date (if available) (datetime.datetime)||&#123;&#123; next_execution_date &#125;&#125; |the next execution date (datetime.datetime)||&#123;&#123; dag &#125;&#125; |the DAG object||&#123;&#123; task &#125;&#125; |the Task object||&#123;&#123; macros &#125;&#125; |a reference to the macros package, described below||&#123;&#123; task_instance &#125;&#125; |the task_instance object||&#123;&#123; end_date &#125;&#125; |same as &#123;&#123; ds &#125;&#125;||&#123;&#123; latest_date &#125;&#125; |same as &#123;&#123; ds &#125;&#125;||&#123;&#123; ti &#125;&#125; |same as &#123;&#123; task_instance &#125;&#125;||&#123;&#123; params &#125;&#125; |a reference to the user-defined params dictionary||&#123;&#123; var.value.my_var &#125;&#125; |global defined variables represented as a dictionary||&#123;&#123; var.json.my_var.path &#125;&#125; |global defined variables represented as a dictionary with deserialized JSON object, append the path to the key within the JSON object||&#123;&#123; task_instance_key_str &#125;&#125; |a unique, human-readable key to the task instance formatted &#123;dag_id&#125;_&#123;task_id&#125;_&#123;ds&#125; ||conf |the full configuration object located at airflow.configuration.conf which represents the content of your airflow.cfg||run_id |the run_id of the current DAG run||dag_run | a reference to the DagRun object||test_mode | whether the task instance was called using the CLI’s test subcommand| 7.导入导出airflow变量12airflow variables --import variable.jsonairflow variables --export variable.txt 8.Template Not FoundTemplateNotFound: sh /data/airflow_dag/dags_migration/sh/export-variables.sh这是由于airflow使用了jinja2作为模板引擎导致的一个陷阱，当使用bash命令的时候，尾部必须加一个空格 12345t2 = BashOperator(task_id=‘sleep‘,bash_command=&quot;/home/batcher/test.sh&quot;, // This fails with `Jinja template not found` error#bash_command=&quot;/home/batcher/test.sh &quot;, // This works (has a space after)dag=dag) 9. 手动触发dag运行1airflow trigger_dag dag_id -r RUN_ID -e EXEC_DATE 10. 手动触发task运行1airflow run dag_id task_id EXEC_DATE 11. “Failed to fetch log file from worker”查看task_instance中hostname字段，存储的均为localhost；分析：修改/etc/hosts文件，删除127.0.0.1 hostname映射；worker log服务获取到hostname后，映射到ip后得到127.0.0.1，故无法访问到log。 12. airflow中每个task对应的执行priority计算方式dummy2 = DummyOperator( task_id=’dummy_’ + src_db, pool=’db’, priority_weight=weight, dag=dag) 所有后置依赖的priority_weight之和，最后一个任务的priority_weight如果没有自定义，默认为1，这样，在同一个pool中做到了任务优先运行；]]></content>
      <categories>
        <category>调度系统</category>
      </categories>
      <tags>
        <tag>airflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令相关]]></title>
    <url>%2F2019%2F07%2F28%2FLinux%E5%91%BD%E4%BB%A4%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[关于linux操作系统的一些使用命令，看下面。 1. linux下查看某个文件或文件夹占用的磁盘空间大小1du -ah --max-depth=1 2.sed修改文件在每行行首或者行尾添加相同的字符串 12sed &apos;s/^/HEAD&amp;/g&apos; text.file 每行行首添加HEADsed &apos;s/$/&amp;TAIL/g&apos; text.file 每行行尾添加TAIL 如果要修改原文件，则添加 -i参数 12sed -i &apos;s/^/HEAD&amp;/g&apos; text.filesed -i &apos;s/$/&amp;TAIL/g&apos; text.file 递归替换 1find . -type f -print0 | xargs -0 sed -i &apos;s/10.1.0.33,10.1.0.44,10.1.0.48/$&#123;es_nodes&#125;/g&apos; 文件第一行添加字符串 1sed -i &quot;1i\添加内容&quot; filename 3.查看centos版本1cat /etc/redhat-release 4.查看cpu12cat /proc/cpuinfo |grep &quot;physical id&quot;|sort|uniq|wc -l 查看cpu核数cat /proc/cpuinfo | grep &quot;cpu cores&quot; | uniq 物理cpu个数 5.查看内存1free -h 6.查看磁盘容量1df -h 7.查看端口号对应进程号1netstat -tunlp|grep 端口号 8.查看未释放空间的进程1lsof | grep deleted 9.杀死未释放空间的进程1lsof | grep deleted | awk &apos;&#123;print $2&#125;&apos; | sort | uniq | xargs kill -9 10.grep12345grep -o &quot;ods\.[a-z|A-Z|_]*&quot; ods2report.py | grep &quot;_&quot; | sort | uniq -cgrep -o只显示匹配内容uniq -c计算重复行数量grep &quot;\&quot;db\&quot;&quot; *.py | awk -F &apos;:&apos; &apos;&#123;print $1&#125;&apos; | sort | uniqgrep -o &quot;ods\.[a-z|A-Z|_|0-9]*&quot; *.py | awk -F &apos;:&apos; &apos;&#123;print $2&#125;&apos; |grep &quot;_&quot; | sort | uniq -c 11.查看详细进程信息1top -c]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hive相关]]></title>
    <url>%2F2019%2F07%2F21%2Fhive%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[下面的内容包含hive的简单操作，增删改查，权限，一些异常的解决方案。 1. 在linux命令行端执行hql语句1hive -e &apos;show table tableName&apos; 2. 在linux命令行端执行hql文件1hive -f fileName 3. 按照分区查看hive表中的数据量1hive -e &apos;select dt, count(1) from test_hive.wps_android_uuid_userid group by dt&apos; 4. 添加分区1alter table test_hive.wps_android_uuid_userid add if not exists partition (dt=&apos;2018-08-04&apos;) 5. 赋表权限1grant select on table usersdb.account_src to user w_wangzhe 6. 赋库权限12345GRANT ALL ON DATABASE DEFAULT TO USER fatkun;GRANT ALL ON TABLE test TO GROUP kpi;REVOKE ALL ON TABLE test FROM GROUP kpi;GRANT ALL TO USER fatkun;REVOKE ALL FROM fatkun; 7. 重命名1alter table data_platform.td_request_log rename to data_platform.td_request_log_old 8. Errorwhile processing statement: FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask 1set hive.auto.convert.join = false; 9.执行sql文件1hive -d etldate=&apos;2018-08-16&apos; -f loan_periods.hql 10.add jar1add jar /usr/hdp/current/hive-client/lib/commons-httpclient-3.0.1.jar; 11.add column1hive -e &quot;alter table report.user_detail_20180614 add columns(identifier_type string comment &apos;注册类型&apos;,channel string comment &apos;注册渠道&apos;)&quot; 12.load 文件到hive表本地文件： 1hive -e &quot;load data local inpath &apos;/data/code/app_list_0814.csv&apos; into table dim.dim_app_list&quot; hdfs文件： 1hive -e &quot;load data inpath &apos;/data/code/app_list_0814.csv&apos; into table dim.dim_app_list&quot; 13.列13.1修改列位置alter table factor.mf_bus_finc_app change column submit_op_no submit_op_no string after company_id 13.2增加列hive -e “alter table data_platform_new.face_request_log add columns(channel string)” 14.修改权限hive -e “grant select on table stg.risk_apply_users to user userName” 15.自定义函数12create function dateformat as &apos;com.kso.dw.hive.udf.DateFormat&apos; using jar &apos;hdfs://hdfs-ha/hiveudf/dw_hive_udf.jar&apos;;mysql -h10.0.1.160 -uadmin -pmd854NHmv3bF0kl9 hive4fac31f3 -e &apos;select name from dbs&apos; | xargs -n 1 -i echo &quot;create function &#123;&#125;.mymd5_kc as &apos;com.kso.dw.hive.udf.MyMd5_KeyCenter&apos; using jar &apos;hdfs://hdfs-ha/hiveudf/dw_hive_udf.jar&apos;;&quot; 16.全局替换1sed -i &apos;s/CREATE TABLE/CREATE EXTERNAL TABLE/g&apos; *.hql 17.not a file exceptionnot a file ks3://online-hadoop/ods/report/dt=2019-01-01/1 1set mapreduce.input.fileinputformat.input.dir.recursive=true; 18.exception1set hive.execution.engine=mr; 19. too many countersorg.apache.hadoop.mapreduce.counters.LimitExceededException: Too many counters: 121 max=120resolved:change the tez configuration 1tez.counters.max= 200 20.SHOW TRANSACTIONS12345ABORT TRANSACTIONS 4951;show locks;mysql:select * from hive_locks;select * from hive_locks where HL_TXNID &gt; 0; 21.acquiring locksFAILED: Error in acquiring locks: Lock acquisition for LockRequest(component:[LockComponent(type:EXCLUSIVE关闭事务： set hive.support.concurrency=false 22.事务表查询12345set hive.support.concurrency=true;set hive.exec.dynamic.partition.mode=nonstrict;set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;set hive.compactor.initiator.on=true;set hive.compactor.worker.threads=1; 23. 内部表转外部表1alter table default.test set TBLPROPERTIES(&apos;EXTERNAL&apos;=&apos;true&apos;); 24. 外部表转内部表1alter table tableA set TBLPROPERTIES(&apos;EXTERNAL&apos;=&apos;false&apos;) 25.修改元数据路径元数据库：123UPDATE dbs SET DB_LOCATION_URI=REPLACE(DB_LOCATION_URI,&apos;hdfs-ha&apos;,&apos;bjCluster&apos;);``` 元数据表： UPDATE sds SET LOCATION=REPLACE(LOCATION,’ks-jinrong-dw’,’online-hadoop’);UPDATE sds SET LOCATION=REPLACE(LOCATION,’hdfs-ha’,’bjCluster’); 1自定义函数： UPDATE func_ru SET RESOURCE_URI=REPLACE(RESOURCE_URI,’hdfs-ha’,’bjCluster’); 123# 26.set role admin# 27.控制map个数 set mapred.max.split.size=400000000;set mapred.min.split.size.per.node=400000000;set mapred.min.split.size.per.rack=400000000;set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;]]></content>
      <categories>
        <category>IT</category>
        <category>hive</category>
      </categories>
      <tags>
        <tag>hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[debezium实时同步mysql、postgresql数据介绍]]></title>
    <url>%2F2019%2F07%2F20%2Fdebezium%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5mysql%E3%80%81postgresql%E6%95%B0%E6%8D%AE%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[给大家介绍一个实时同步数据库的组件debezium，它可以同步mysql、postgresql、mongo、oracle、sql server数据库到hdfs、kafka，功能强大，具体如下。 大致安装步骤： 1.插件decoderbufs或者wal2json2.postgresql配置logical等3.confluent平台搭建4.配置connector 参考文档：https://debezium.io/docs/connectors/ for postgresql to kafka 核心：一个active slot，多个connector 1. bin/connect-distributed etc/kafka/connect-distributed.properties三台服务器分别执行启动distributed服务（相同的slot.name、group.id保证复制同一个slot replication，保证在同一个组内） 123bin/connect-distributed etc/kafka/connect-distributed-8084.propertiesbin/connect-distributed etc/kafka/connect-distributed-8085.propertiesbin/connect-distributed etc/kafka/connect-distributed-8086.properties 2. bin/connect-standalone etc/kafka/connect-standalone.properties etc/kafka-connect-postgres/debezium.propertiesbin/kafka-console-consumer –zookeeper localhost:2182 –topic postgres.localhost.public.test –from-beginning 3. 安装decoderbufs、wal2json pluginhttps://github.com/debezium/postgres-decoderbufs/blob/master/README.mdhttps://github.com/eulerto/wal2json/blob/master/README.md 安装wal2json时出现的问题：Makefile:10: /usr/lib64/pgsql/pgxs/src/makefiles/pgxs.mk: No such file or directoryyum install postgresql10-devel即可 4. 配置参考文档：https://zhubingxu.me/2018/06/05/debezium-postgres/ share/java/下创建debezium文件夹，创建文件debezium.properties： 1234567891011121314name=events-debeziumtasks.max=1connector.class=io.debezium.connector.postgresql.PostgresConnectordatabase.hostname=localhostdatabase.port=5432database.user=postgresdatabase.password=postgresdatabase.dbname=postgresdatabase.history.kafka.bootstrap.servers=localhost:9092database.server.id=1database.server.name=postgres.localhostplugin.name=wal2jsoninclude.schema.changes=trueslot.name=my\_slot\_name 5. 异常Error while fetching metadata with correlation id 1 : {postgres.localhost.public.test=LEADER_NOT_AVAILABLE} https://stackoverflow.com/questions/35788697/leader-not-available-kafka-in-console-producer 配置debezium中$DEBEZIUM_HOME/etc/kafka/server.properties 指定参数advertised.host.name ERROR A logical replication slot named ‘debezium’ for plugin ‘wal2json’ and database ‘postgres’ is already active on the server.You cannot have multiple slots with the same name active for the same database (io.debezium.connector.postgresql.connection.PostgresReplicationConnection:104) 在创建connector的配置参数中添加新的slot.name，slot.name的规范必须为字母数字下划线。不指定的话默认为debezium，会产生冲突。 6. 分布式kafka connector配置：https://archive.cloudera.com/kafka/kafka/2/kafka-0.9.0-kafka2.0.1/connect.html分布式connector需要通过rest api进行增删改 https://mapr.com/docs/52/Kafka/Connect-distributed-mode.html connect-distributed.properties 连接参数配置：https://debezium.io/docs/connectors/postgresql/#connector-properties 7. 注意：table.whitelist格式：schemaName.tblname 如果启动connector出现权限不足时：需要给用户赋update权限： GRANT SELECT, UPDATE ON TABLE test TO debezium; 不监控无主键的表 8. 查看postgresql slota.登陆：psql -U user -d db -h host -p port -Wb.查看所有slot： select * from pg_replication_slots;c.添加slot：SELECT * FROM pg_create_physical_replication_slot(‘pg96_102’);d.删除slot：SELECT * FROM pg_drop_replication_slot(‘pg96_102’); for mysql to kafka 核心：启动多个connector即可 1. 账户及权限mysql user: debezium:******* GRANT SELECT, RELOAD, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO ‘debezium’ IDENTIFIED BY ‘******‘; 2. 配置https://debezium.io/docs/connectors/mysql/#setting-up-mysql 3. 启动bin/connect-standalone etc/kafka/connect-standalone.properties share/java/debezium/mysql-debezium-8087.properties 三台服务器分别运行： 123bin/connect-distributed etc/kafka/mysql-connect-distributed-8134.propertiesbin/connect-distributed etc/kafka/mysql-connect-distributed-8134.propertiesbin/connect-distributed etc/kafka/mysql-connect-distributed-8134.properties 4. kafka connector请求添加connector-task，随便在哪一台服务器添加1个task curl -X POST -H “Content-Type: application/json” –data @share/java/debezium/mysql-8134.json http://localhost:8134/connectors table.whitelist格式：dbname.tblname 测试环境test-hadoop：/mnt/confluent下生成的topic名称为：servername.dbname.tblname 5. 异常（未解决） 如果有解决方案，请联系我邮箱chenzuoli709@163.com，不胜感激。]]></content>
      <categories>
        <category>组件</category>
      </categories>
      <tags>
        <tag>实时同步</tag>
        <tag>mysql</tag>
        <tag>oracle</tag>
        <tag>postgresql</tag>
        <tag>mongo</tag>
        <tag>sql server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[英国构成国]]></title>
    <url>%2F2019%2F07%2F07%2F%E8%8B%B1%E5%9B%BD%E6%9E%84%E6%88%90%E5%9B%BD%2F</url>
    <content type="text"><![CDATA[英国，全称为大不列颠及北爱尔兰联合王国（United Kingdom of Great Britain and Northern Ireland），世界第五大经济体。 听说，去了北爱尔兰，不要说英格兰好，不然会被打，哈哈 地理位置： 构成国： 各构成国详情：]]></content>
      <categories>
        <category>世界国家</category>
      </categories>
      <tags>
        <tag>英国</tag>
        <tag>北爱尔兰</tag>
        <tag>英格兰</tag>
        <tag>苏格兰</tag>
        <tag>威尔士</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[世界各国人民平均汽车拥有量]]></title>
    <url>%2F2019%2F06%2F29%2F%E4%B8%96%E7%95%8C%E5%90%84%E5%9B%BD%E4%BA%BA%E6%B0%91%E5%B9%B3%E5%9D%87%E6%B1%BD%E8%BD%A6%E6%8B%A5%E6%9C%89%E9%87%8F%2F</url>
    <content type="text"><![CDATA[【世界银行：每1000人拥有的汽车数量，美国为837辆最高，中国为173辆】 具体排名如下： 美国：837澳大利亚：747意大利：695加拿大：670日本：591德国：589英国：579法国：569马来西亚：433俄罗斯：373巴西：350墨西哥：297沙特：209土耳其：199伊朗：178南非：174中国：173印度尼西亚：87尼日利亚：64印度：22]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>汽车</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[说英语的国家]]></title>
    <url>%2F2019%2F06%2F28%2F%E8%AF%B4%E8%8B%B1%E8%AF%AD%E7%9A%84%E5%9B%BD%E5%AE%B6%2F</url>
    <content type="text"><![CDATA[有哪些以英语为母语的国家呢？ 参照下图，印度人说的最多。 英语学起来，走向全世界。]]></content>
      <categories>
        <category>语言</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[世界十大语言排名]]></title>
    <url>%2F2019%2F06%2F11%2F%E4%B8%96%E7%95%8C%E5%8D%81%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%8E%92%E5%90%8D%2F</url>
    <content type="text"><![CDATA[世界语言排名，瑞士社会学家按照母语、第二语言、国家经济实力、科学外交重要性、社会、文学地位等方面进行综合评价，得出如下排名。 瑞士社会家者George Weber提出了这样的语言评价体系（图）： 具体来说，评价语言地位需要按这6条标准加权评分综合考虑： 1. 以该语言为母语人数:最高得分 4 2. 以该语言为第二语言的人数: 最高得分 6 3. 使用该语言国家的经济实力: 最高得分8 4. 科学、外交中该语言的重要性:最高得分8 5. 使用该语言的国家数和人口数：最高得分7 6. 该语言的社会、文学地位：最高得分4分（如果是联合国工作语言加1分） 一种语言，在当今世界上处于什么样的排名，地位如何，主要取决于6个指标。 1 使用某种语言的母语人口数量。 （Number of native speakers of the language） 评分：4分 2 使用某种语言的非母语人口数量。 （Number of non-native speakers of the language） 评分：6分 3 使用这种语言的国家数量与人口。 （Number and population of countries using the language） 评分：7分 4 使用这种语言的国家的经济，科技与军事实力。 （Economic, scientific and military power of the countries using the language） 评分：8分 5 在外交，国际贸易，国际组织，学术交流等领域使用这种语言的频率。 （Number of major fields, such as diplomacy, international trade relations, international organizations and academic community, using the language globally） 评分：8分 6 在社会人文领域的声望。（例如：某种语言获得过多少次诺贝尔文学奖，某种语言有过多少世界名著等等） （International socio-literary prestige of the language） 评分：4分 （如果是联合国的官方语言，额外加3分） 上面6个指标，就是判断一种语言在当今世界的排名，地位的综合指标。满分是40分。按母语人口排序的前10名是： 12345678910（1）中文（占世界总人口20.7%）（2）英语（6.2%）（3）西班牙语（5.6%）（4）印地、乌尔都语（4.7%）（5）阿拉伯语（3.8%）（6）孟加拉语（3.5%）（7）巴西葡萄牙语（3.0%）（8）俄语（3.0%）（9）日语（2.3%）（10）德语（1.8%） 值得注意的是法语连前10名都没有进，仅排在第13位（1.4%），险胜排在第14位的韩语。 再看第二项指标：有多少人以该语言为第二语言： 12345678910（1）法语（约1亿8千万）（2）英语（约1亿5千万）（3）俄语（约1亿2千万）（4）葡萄牙语（约3000万）（5）阿拉伯语（约2400万）（6）西班牙语（约2200万）（7）中文（约2100万）（8）德语（约2000万）（9）日语（约1000万）（10）印地语 当然括号中的数字只是大致的估算，不是也不可能是科学统计，但先后顺序大致是不错的。 George Weber先生对其他4项指标也做了估算，限于篇幅不一一叙述，他最后排出了世界语言的前十名： 根据上面那6个指标，所做出的排名 12345678910 第一名：英语 37分 第二名：法语 23分 第三名：西班牙语 20分 第四名：俄语 16分 第五名：阿拉伯语 14分 第六名：汉语 13分 第七名：德语 12分 第八名：日语 10分 第九名：葡萄牙语 10分 第十名：印地语 9分 综上总结： 全球性交流媒介：英语 洲际交流媒介：法语、西班牙语、俄语、阿拉伯语、葡萄牙语]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Turkish]]></title>
    <url>%2F2019%2F05%2F21%2FTurkish%2F</url>
    <content type="text"><![CDATA[土耳其，一个横跨欧亚大陆，南临地中海，东南与叙利亚、伊拉克接壤，西临爱琴海，并与希腊以及保加利亚接壤，东部与格鲁吉亚、亚美尼亚、阿塞拜疆和伊朗接壤，有热气球的浪漫国家，这边的人民对于工作有什么想法呢？ Where Turkish workers would like to move for work. US Germany Italy Canada UK France Australia Japan Russia China South Korea Brazil India Saudi Argentina (BCG) US.]]></content>
  </entry>
  <entry>
    <title><![CDATA[儿童贫困率排行]]></title>
    <url>%2F2019%2F05%2F19%2F%E5%84%BF%E7%AB%A5%E8%B4%AB%E5%9B%B0%E7%8E%87%E6%8E%92%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[世界儿童贫困率排行，来看看。 Child poverty rate, 2016. (%) 🇨🇳CHN: 33.1%🇧🇷BRA: 30.1%🇹🇷TUR: 25.3%🇮🇳IND: 23.6%🇪🇸ESP: 22.1%🇺🇸USA: 20.9%🇲🇽MEX: 19.7%🇮🇹ITA: 18.3%🇨🇦CAN: 17.1%🇯🇵JPN: 13.9%🇦🇺AUS: 13.0%🇬🇧GBR: 11.8%🇫🇷FRA: 11.3%🇩🇪GER: 11.2%🇨🇭SUI: 9.5%🇸🇪SWE: 8.9%🇰🇷KOR: 7.1%🇫🇮FIN: 3.3%🇩🇰DEN: 2.9% (OECD)]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>贫困率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[世界失业率排行]]></title>
    <url>%2F2019%2F05%2F19%2F%E4%B8%96%E7%95%8C%E5%A4%B1%E4%B8%9A%E7%8E%87%E6%8E%92%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[来看看倒数第一是谁，哈哈。 失业率排行：South Africa（南非）: 27%Nigeria（尼日利亚）: 23%Spain（西班牙）: 14.7%Turkey（土耳其）: 14.7%Brazil（巴西）: 12.7%Iran（伊朗）: 12.2%Italy（意大利）: 10.2%France（法国）: 8.7%Egypt（埃及）: 8.1%Pakistan（巴基斯坦）: 5.9%Canada（加拿大）: 5.7%Australia（澳大利亚）: 5.2%Indonesia（印度尼西亚）: 5%Russia（俄国）: 4.7%UK（英国）: 3.8%US（美国）: 3.6%India（印度）: 3.5%Germany（德国）: 3.2%Mexico（墨西哥）: 3.2%Japan（日本）: 2.5% 此列不包含一些发达国家和未公布失业率的国家。]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>失业率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Starbucks]]></title>
    <url>%2F2019%2F05%2F14%2FStarbucks%2F</url>
    <content type="text"><![CDATA[Starbucks，founded at March 31, 1971. It is an American coffee company and coffeehouse chain. 2018年全球员工总数：29.1万 在欧洲的门店数量： 英国：1,030土耳其：470法国：175德国：168西班牙：154俄罗斯：135荷兰：106爱尔兰：82波兰：72瑞士：65罗马尼亚：46捷克共和国：40希腊：31匈牙利：28比利时：26挪威：23葡萄牙：23奥地利：19 （星巴克） 星巴克，一个卖咖啡的，不仅给了我们咖啡、空间，就业也是它对社会的价值。]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>Starbucks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[美国软件巨头Oracle简介]]></title>
    <url>%2F2019%2F05%2F11%2F%E7%BE%8E%E5%9B%BD%E8%BD%AF%E4%BB%B6%E5%B7%A8%E5%A4%B4Oracle%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[甲骨文公司（英语：Oracle，NASDAQ：ORCL）是一间全球性的大型企业软件公司。总部位于美国加州红木城的红木岸（Redwood Shores），现时首席执行官为公司创办人劳伦斯·埃里森（Lawrence J. Ellison）。甲骨文是继微软后，全球收入第二多的软件公司。随着中美之间的贸易摩擦升级，美国软件巨头Oracle公司撤离中国区研发中心，只留下销售部门。这个软件巨头什么来历呢？ 发展历史 1977年劳伦斯·埃里森、鲍勃·迈纳（Bob Miner）、埃德·奥茨（Ed Oates）在美国加州资成立公司，名为软件发展实验室（Software Development Laboratories，SDL)。其中创始人拉里·埃里森以670亿美元的身价排名全球第六。1978年，开发出第一版甲骨文系统（Oracle），以汇编语言写成；1979年，更名为关连式软件公司（Relational Software, Inc.，RSI)。1982年，推出甲骨文系统，公司也更名为甲骨文系统公司（Oracle Systems Corporation）；2016年，每年的研发投入$22亿美金，应用软件收入$70亿美金，中间件收入$10亿美金。30,000应用软件客户，30,000中间件客户，270,000数据库客户。Oracle 在云端 SaaS 上的收入已为全球最大。 产品 主要分两类：1.服务器及工具 数据库服务器：12c 应用服务器：Oracle WebLogic Application Server 开发工具：Oracle JDeveloper，Oracle Designer，Oracle Developer，等等 2.应用软件 应用软件包与2010年9月20日甲骨文OpenWorld大会上推出的Oracle Fusion Application，一个全面的模块化的应用包； 企业资源计划（ERP）软件。已有10年以上的历史。2005年，并购了开发企业软件的仁科软件公司以增强在这方面的竞争力； 客户关系管理（CRM）软件。自1998年开始研发这种软件。2005年，并购了开发客户关系管理软件的希柏软件公司（Siebel）； 人力资源管理（HCM），收购了仁科（PeopleSoft）软件； 操作系统SolarisOracle Linux 虚拟技术Oracle VMVirtualBox Java平台JavaGlassFish（Sun Java System Application Server）WebLogic 数据库管理系统Oracle数据库Berkeley DBMySQLJava DB 云计算Oracle Cloud下图是Oracle Cloud在全球市场份额占比： 其它软件NetBeansSun Grid EngineSun Studio 都有自己的操作系统了，真的厉害]]></content>
      <categories>
        <category>公司</category>
      </categories>
      <tags>
        <tag>软件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全球各国人均GDP排行]]></title>
    <url>%2F2019%2F05%2F07%2F%E5%85%A8%E7%90%83%E5%90%84%E5%9B%BD%E4%BA%BA%E5%9D%87GDP%E6%8E%92%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[在这个世界上，人均GDP的提高，不仅需要天时地利，更重要的是人和。来看看全球各国人均GDP排行吧，并介绍下人均GDP最高的国家：卢森堡大公国。 2018年度全球各国人均GDP排名如下：来介绍下人均收入最高的卢森堡大公国吧： 基本信息 语言：卢森堡语、德语、法语 首都：卢森堡市 货币：欧元 国土面积：0.25万平方公里 简介卢森堡是欧盟成员国，因境内有欧洲法院、欧洲审计院、欧洲投资银行等多个欧盟机构被称为继布鲁塞尔和斯特拉斯堡之后的欧盟“第三首都”。卢森堡实行君主立宪制。 国家元首为卢森堡大公，也是目前欧洲唯一的一个大公国。而行政权则由内阁行使。国会共有60个席位，议员任期为5年。 地理位置卢森堡位于西欧内陆，地势北高南低，东邻德国，南接法国，北部和西部同比利时接壤。北部为阿登高原，森林茂密，南部为丘陵。气候温和，属温带海洋性气候，风景优美。首都卢森堡城有“花都”之称。铁矿丰富。这里也是中世纪的要塞。最高点为布尔格普拉兹峰，海拔约550米。 经济自1999年以来，卢森堡一直是欧元区的一部分。卢森堡的经济过去以工业为主，现在卢森堡则是全球最大的金融中心之一。卢森堡是欧元区内最重要的私人银行中心及全球第二大的投资信托中心（仅次于美国）。 1）银行：仅次于美国的世界第二、欧洲最大的基金管理中心； 2）阿塞洛尔—米塔尔集团（Arcelor-Mittal）：卢第一大企业，世界第一大钢铁集团； 3）欧洲卫星公司（SES GLOBAL）：成立于1985年，拥有卫星数量52颗，居欧洲首位、世界第二，其卫星信号全球覆盖率达99.999%。1.22亿欧洲家庭可接收该公司卫星转播的2400套电视、电台节目； 4）卢森堡货运航空公司（Cargolux Airlines International）：成立于1970年，是欧洲最大全货运航空公司，拥有波音747货机26架，员工1856人，航线90多条，覆盖全球50多个国家和地区； 5）卢森堡广播电视公司（RTL）：该公司系卢与德 [5] 国联合组建的欧洲最大的视听媒体集团，拥有40个电视台和33个广播电台。 教育教育体制中卢、德、法三语循序渐进，并行不悖。小学低年级用卢森堡语授课，高年级开始用德语讲习，中学开始再转化成法语。熟练掌握这三门语言是当地中学毕业的必要条件。 人种卢森堡的外国侨民特别多，占全国人口的三成以上，最大的移民团体是葡萄牙人和意大利人。他们也同时带来了自己的语言。不过，葡萄牙语和意大利语基本只限于移民团体内部交流，在大范围内运用并不广泛。 宗教多数信奉天主教，亦有部分信奉其他宗教（包含基督新教和犹太教）。]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>GDP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[截至2019年5月5日世界上最富有的人排行]]></title>
    <url>%2F2019%2F05%2F05%2F%E6%88%AA%E8%87%B32019%E5%B9%B45%E6%9C%885%E6%97%A5%E4%B8%96%E7%95%8C%E4%B8%8A%E6%9C%80%E5%AF%8C%E6%9C%89%E7%9A%84%E4%BA%BA%E6%8E%92%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[截至2019年的最富有的人。（以十亿美元计） 马云在2018年7月已跌出亚洲首富，现为印度人穆克什·安巴尼，世界排名如下： 12345678910🇺🇸杰夫·贝索斯：161 亚马逊 电子商务 美国🇺🇸比尔·盖茨：102 微软 软件 美国🇫🇷伯纳德·阿诺特：94 LVMH集团总裁 奢侈品 法国🇺🇸沃伦·巴菲特：90 伯克希尔哈撒韦 投资、咨询 美国🇺🇸马克·扎克伯格：73 Facebook 社交 美国🇺🇸拉里·埃里森：67 甲骨文Oracle 软件服务 美国🇪🇸阿曼西奥·奥特加：66 Zara 服装零售 西班牙🇲🇽卡洛斯·斯利姆：61 卡尔索集团 商业、电信 墨西哥🇮🇳穆克什·安巴尼：56 信诚工业集团 商业 印度🇺🇸迈克尔·布隆伯格：55 彭博 媒体、慈善 美国]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>世界财富排名</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全球最受欢迎的无广告网站-维基百科]]></title>
    <url>%2F2019%2F05%2F04%2F%E5%85%A8%E7%90%83%E6%9C%80%E5%8F%97%E6%AC%A2%E8%BF%8E%E7%9A%84%E6%97%A0%E5%B9%BF%E5%91%8A%E7%BD%91%E7%AB%99-%E7%BB%B4%E5%9F%BA%E7%99%BE%E7%A7%91%2F</url>
    <content type="text"><![CDATA[全球最受欢迎的网站排行，前三当属Google、YouTube、Facebook，没有广告、最受欢迎的网站呢，当属wikipedia莫属。没有广告的维基百科，收入从哪里来呢，谁在运营？ 下面来看看该网站的基本信息： 创建日期：2001-01-15创始人：吉米·威尔士与拉里·桑格持有者：维基媒体基金会（非营利组织）总部：美国网站类型：自由内容、自由编辑的网络百科全书名称来源：Wikipedia是混成词，分别取自于网站核心技术“Wiki”以及英文中百科全书之意的“encyclopedia”语言：301种官方网站：维基百科 哈哈，你能访问吗？ 根据知名的Alexa Internet其网络流量统计数字指出全世界总共有近3.65亿名民众使用维基百科，且维基百科也是全球浏览人数排名第五高的网站，同时也是全世界最大的无商业广告的网站。 目前网站运营资金来源于捐款，在wikipedia18岁生日的时候，Google捐款310万美元，10年接收捐款总额超过7500万美元。]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>维基百科</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链三大公链Dapp平台ETH、EOS、TRON对比]]></title>
    <url>%2F2019%2F04%2F27%2F%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%89%E5%A4%A7%E5%85%AC%E9%93%BEDapp%E5%B9%B3%E5%8F%B0ETH%E3%80%81EOS%E3%80%81TRON%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[区块链三大公链Dapp平台ETH、EOS、TRON对比，根据创始人经历、平台共识机制、平台发展历程、目前发展现状等方面进行对比，寻找最有可能实现未来去中心化操作系统的平台。 一、创始人1.ETH以太坊创始人：维塔利克·布特林（Vitalik Buterin） 出生日期：1994年1月31日 国籍：俄罗斯裔加拿大人 学历：加拿大滑铁卢大学肄业 区块链经历：2012年17岁时从他父亲那里了解了比特币，开始研究比特币、为比特币杂志写文章转比特币稿费，当时出版社给他一篇文章5个比特币；2013年18岁时获得奥林匹亚资讯奖铜牌，经常去访问其他国家的比特币社区开发人员，讨论比特币的发展与问题；2014年19岁自加拿大滑铁卢大学休学；该年11月，公布《以太坊白皮书》初版，开始募集开发者；2015年20岁获得硅谷知名的亿万富翁设立的泰尔奖学金10万美元成立非营利组织以太坊基金会，全职在以太坊工作；在迈阿密的比特币会议公开发表以太坊计画，该年7月，启动以太坊计画众售募资，募得3.1万枚比特币（当时约合1840万美元）2016年21岁以太坊最初版本Frontier问世、以太币开始在世界各地交易所公开交易2017年22岁被《财星》杂志评选为2016年40岁以下的40大杰出人物 2.EOS柚子创始人：丹尼尔·拉里默（Daniel Larimer） 出生日期：未查到 国籍：美国 学历：2003年毕业于佛吉尼亚大学计算机系本科学士学位 区块链经历：2009年对比特币感兴趣，开始了解；2013年创建BitShares去中心化交易所，是一个拥有钱包, 账本, 交易所, 货币系统，社群与一身的产品，与之对应的是BTS(比特股)虚拟货币的发行，目前市值排名51；2016年离开BitShares创建Steem区块链平台和利用区块链技术实现的社交app steemit，该平台可以对用户的创作予以代币奖励；项目完成后，2017年7月发布EOS白皮书，提供分散式应用程序托管﹑智能合约功能与分散式储存的企业方案，解决比特币和以太坊等区块链的可扩展性问题，并消除用户的交易费用。成立了Block.One公司并搭建了EOSIO平台，并发行以ERC-20方式发行1亿枚EOS代币 3.TRON波场创始人：孙宇晨 出生日期：1990年 国籍：中国 学历：北京大学、宾夕法尼亚大学硕士 区块链经历：2013年以前投资比特币，获得二十倍以上收益；由于比特币的投资经历，孙宇晨活跃于美国比特币社区，并对加密货币，去中心化清算协议产生了极其浓厚的兴趣。经过长期调查与研究，他对于诞生于加州硅谷的全球第一个分布式清算支付网络协议——Ripple协议产生了极其浓厚的兴趣。2013年底加入RippleLabs，成为Ripple协议缔造者与研发者中的一员；2014年，他回国创立锐波并兼任CEO，锐波也成为中国首家从事去中心化清算系统产品开发的互联网科技公司；2017年，孙宇晨在“世界区块链峰会上”发表《From it to bit》主题演讲，讲述了互联网的发展历史，阐释了web 4.0的观点。7月，随后推出了自己所做的项目：波场TRON，发布波场白皮书，基于区块链的开源去中心化内容娱乐协议，致力于利用区块链与分布式存储技术，构建一个全球范围内的自由内容娱乐体系，这个协议可以让每个用户自由发布，存储，拥有数据，并通过去中心化的自治形式，以数字资产发行，流通，交易方式决定内容的分发、订阅、推送，赋能内容创造者，形成去中心化的内容娱乐生态。2018年7月，完成了对于BitTorrent及其旗下所有产品的收购，并将其并入到波场生态中。 二、区块链共识机制先来介绍下三种共识机制的概念 POW：Proof Of Work工作量证明机制：通过计算机随机不停地计算得到指定hash值后获得记账权，并将区块链接到区块链上的机制，每个获得记账权的矿工会获得一定的代币，作为记账的奖励，这个过程俗称挖矿。 POS：Proof Of Stake权益证明机制：人们对于POW日趋中心化的算力分布(矿池)心怀忌惮之际，产生了权益证明机制，即对于验证人/节点的奖励，不是通过算力挖矿，而是通过持币而产生利息，这里就要引入一个概念叫做—币龄，币龄=币量x持有天数。这是根据你持有货币的量和时间，给你发利息的一个制度。当你获得了利息以后，你的所有币龄将被清空，你的持币时间将从0重新算起。 DPOS：Delegated Proof Of Stake委托权益证明机制：可以说DPOS是POS共识机制理念的一个变种。先通过选举，产生若干超级节点；后续记账权将以相同概率分配于超级节点中。它有点像是议会制度或人民代表大会制度。如果代表不能履行他们的职责(当轮到他们时，没能生成区块)，他们会被除名，网络会选出新的超级节点来取代他们。DPOS让每一个持有代币的人都有权利通过投票给验证人的方式行使自己的权利，利用科技的手段实现民主治理。 1.ETH 第一阶段，边境（Frontier，2015年7月）以太坊的第一次版本发布，允许开发人员对以太坊进行挖矿，并基于以太坊进行 DApp 与工具软件的开发。 第二阶段，家园（Homestead，2016年3月）发布了第一个生产环境版本，对许多协议进行了优化改进，为之后的升级奠定了基础，并且加快了交易速度。 第三阶段，大都会（Metropolis，2017年10月）第三阶段分为两次升级，分别命名为拜占庭（Byzantium，2017年10月）和君士坦丁堡（Constantinople，2019年1月），将会使得以太坊更轻量、更快速、更安全。 第四阶段，宁静（Serenity，时间待定）这个版本将会使用期待已久的 PoS 共识，其中将会使用 Casper 共识算法。 目前第三阶段已升级完成，所以ETH仍然使用POW共识机制。 2.EOSDPOS目前已选出21个超级节点进行选举出块。 3.TRONDPOS 第一阶段：Exudos，出埃及记数据自由-基于点对点的分布式的内容上传、存储和分发机制。出埃及记阶段，波场（TRON）将建立在以IPFS为代表的分布式存储技术之上，为用户提供一个可以完全自由可依赖的数据发布，存储，传播平台。 第二阶段：Odyssey，奥德赛（2019年1月-2020年6月，2019年5月发布2.0，9月发布3.0）内容赋能-经济激励赋能内容生态。区块链技术，将为内容产生，分发，传播建立一整套充分竞争、回报公平的经济机制，激励个体，赋能内容，从而不断拓展系统的边界。 第三阶段：Great Voyage（2020年7月-2021年7月）伟大航程，人人发行数字价值。波场（TRON）基于区块链的优势，解决了收益衡量、红利发放和支持者管理三大难题，实现了从“粉丝经济”向“粉丝金融”的重大转变，波场（TRON）基于区块链以波场币（TRX）为官方代币的自治经济体系使得个人内容生产者在体系内的每一笔收入和支出都公开、透明且不可篡改，通过智能合约，支持者们可以自动参与内容生产者的数字资产购买并按照约定自动共享红利成长，不需要任何第三方进行监督即可公正地完成全部流程。 第四阶段：Apollo，阿波罗（2021年8月-2023年3月）价值自由流动-去中心化的个体专属代币交易。当每一个波场（TRON）体系内的内容生产者都可以发行自己的专属代币，则系统必须拥有一整套完整的去中心化交易所解决方案，方能实现价值的自由流动。 第五阶段：Star Trek，星际旅行（2023年4月-2025年9月）流量变现-去中心化的博弈与预测市场。全球博弈市场规模2014年超过4500亿美元。波场（波场（TRON））内容平台所带来的流量，为构建去中心化的线上博弈平台提供了可能。开发者可以通过波场（TRON）自由搭建线上博弈平台，提供全自治的博弈预测市场功能。 第六阶段：Eternity，永恒之地（2025年10月-2027年9月）流量转化-去中心化的游戏。2016年，全球电子游戏市场规模达996亿美元，其中手机游戏市场规模461亿美元，占比42%。波场（波场（TRON））为构建去中心化的线上游戏平台提供了可能。开发者可以通过波场（TRON）自由搭建游戏平台，实现游戏开发众筹，并为普通投资者提供参与投资游戏的可能。 目前第二阶段升级到1.0版本。 平台功能ETH1.Smart Contract：智能合约2.EVM：以太坊虚拟机，提供智能合约运行的分布式区块链环境3.ICO：发币融资（如：BNB）4.DAPPs5.转账 EOS1.Smart Contract：智能合约2.ICO：发币融资3.DAPPs4.转账 TRON1.内容上传、存储和分发2.给予内容创作者奖励3.ICO（未实现）4.去中心化的博弈与预测市场（未实现）5.去中心化游戏（未实现）6.DAPPs7.转账 三、平台目前发展现状实时数据据 DAppTotal4月29日数据显示，过去一周，综合对比 ETH、 EOS、 TRON四大公链的 DApp生态情况发现： 总用户量(个)EOS(292,337)&gt; TRON(87,261)&gt; ETH(31,678)； 总交易次数(笔)EOS(26,393,841)&gt; TRON(9,856,747)&gt; IOST(2,360,126)&gt; ETH(373,918)； 总交易额(美元)EOS(144,852,700)&gt; TRON(88,426,176)&gt; ETH(39,182,195)； 跨四条公链按用户量 TOP3 DAppsEOS Global(EOS)、 Endless Game(EOS)、 Lore Free(EOS)； 按交易次数 TOP3 DAppsHash Baby(EOS)、 TRONbet(TRON)、 Dice(EOS)； 按交易额 TOP3 DAppsTRONbet(TRON)、 EOS Global(EOS)、 TronWoW(TRON)。 统计数据尴尬，这个网站：State of Dapps 没有统计TRON平台的数据。 转账交易速度TPS由于平台共识机制不同，导致去中心化程度、运行速度也不同，下面是几大平台交易速度：其中EOS，TPS可达3500.比其他几大平台都快。 这些是目前公共区块链平台的一些基本信息，希望对大家有用，如有错误的地方还请指正，联系方式：chenzuoli709@163.com，一起交流学习。]]></content>
      <categories>
        <category>数字货币</category>
      </categories>
      <tags>
        <tag>Dapp</tag>
        <tag>公链</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[世界上钻石价格排行]]></title>
    <url>%2F2019%2F04%2F27%2F%E4%B8%96%E7%95%8C%E4%B8%8A%E9%92%BB%E7%9F%B3%E4%BB%B7%E6%A0%BC%E6%8E%92%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[世界上最贵的钻石，在哪里呢，来看看。 1.Koh-i-Noor: 现在英国，产地印度，21.12 g，无价；2.The Sancy: 现在印度，11.046 g，无价3.The Cullinan: 现在英国，产地南非，1905年被发现时621.35g，后来被拆分成105颗，价值4亿美元；4.The Hope Diamond: 现在美国，产地印度9.11g，价值3.5亿美元；5.Millennium Star: 属于戴比尔斯集团，产地扎伊尔，40.6.8g，价值1.29亿美元；6.Centenary Diamond: 属于戴比尔斯集团，产地南非，54.77g，价值1亿美元；7.Pink Star: 属于戴比尔斯集团，产地南非，11.92g，价值7千万美元；8.The Regent Diamond: 现在法国，产地印度，28.12g，价值6200万美元；]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>钻石</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全球奢侈珠宝品牌排名]]></title>
    <url>%2F2019%2F04%2F24%2F%E5%85%A8%E7%90%83%E5%A5%A2%E4%BE%88%E7%8F%A0%E5%AE%9D%E5%93%81%E7%89%8C%E6%8E%92%E5%90%8D%2F</url>
    <content type="text"><![CDATA[珠宝首饰一直是人们爱美时的装饰品，一直都是如此，下面来看下全球珠宝首饰排名，了解世界品牌。 10 萧邦choppard国家：瑞士创建日期：1860年创始人：路易•尤利斯•萧邦简介：除了制作奢华的瑞士手表外，萧邦的房子也以其奢华的珠宝系列而闻名。 Chopard的日常珠宝系列仅采用最优质的材料制成，采用厚度为18K的黄金和最高等级的宝石制成。不仅如此，萧邦还非常注重细节和精确度，为其已经很昂贵的产品线增加了更多价值。 9 Mikimoto御木本国家：日本创建日期：1893年创始人：御木本幸吉简介：Mikimoto的创始人Kokichi Mikimoto不仅因其收藏而闻名，而且因为他发明并传播了使用养殖珍珠制作珠宝首饰的事实。 Mikimoto的系列仅选用最好的珍珠，包括南海珍珠，粉红海螺珍珠，大溪地珍珠，白珍珠和其他稀有标本。最重要的是，Mikimoto的珠宝系列仅使用18k金和铂金作为金属部件和顶级钻石。只有最好的丝线用于有珍珠串的首饰。 8 Bvlgari宝格丽国家：意大利创建日期：1884年创始人：索帝里欧·宝格丽简介：宝格丽毫无疑问是一个着名的奢侈品牌，从时装到手表再到珠宝。而对于后者而言，这个以罗马为基础的品牌将优雅和奢侈品完美结合，并且不失其对传统的偏好。即使在今天，Bvlagri的系列仍然标榜着该房子的标志性特征，包括用于中心件的大型宝石，大胆的形状以及凸圆形宝石的使用（这一传统可追溯到1960年代的意大利魅力）。除了最好的宝石外，宝格丽仅使用18K黄金作为其收藏品。 7 伯爵伯爵国家：瑞士创建日期：1874创始人：乔治．伯爵简介：Piaget是普通人的另一个熟悉的名字，最初是作为汝拉瑞士部分的制表公司开始的。随着业务的增长，该公司很快就进入了珠宝行业，并在其中脱颖而出，为那些能够负担公司要求的价格的人们制作奢侈品。今天，Piaget以旧世界概念和现代设计相结合为荣，现在设计时尚线条和大胆的角度。但其最着名的外观是玫瑰，它已成为伯爵的标志性设计。 6 Graff格拉夫国家：英国创建日期：1960年创始人：劳伦斯·格拉夫简介：格拉夫是顶级品牌，在富人和精英中非常受欢迎。使Graff的系列与众不同的不仅仅是用于制作昂贵单品的宝石和金属的工艺或质量。相反，它是Graff在其珠宝系列中使用的宝石的大小。他们是巨大的，格拉夫的创始人劳伦斯格拉夫喜欢这样。 5 Tiffany＆Co。蒂芙尼国家：美国创建日期：1837年创始人：查理斯·路易斯·蒂芙尼和泰迪·杨简介：甚至大众都知道蒂芙尼在珠宝方面是一个巨大的奢侈名称，主要是因为他们的产品线包括日常穿着的件，无论什么场合。他们广泛的收藏不仅限于女性，蒂芙尼也适合男性和儿童。自1837年开始运营以来，Tiffany的创作产生了经典设计，由专业工匠制作。那些被归类为超豪华的人往往需要数年才能完成。 4 Buccellatibucellati国家：意大利创建日期：1919年创始人：Mario Buccellati简介：Buccellati用最好的意大利金制作优雅的珠宝，彰显罗马的传统。这家总部位于罗马的珠宝公司制作了罗马风格的设计，并将其融入其收藏中。罗马风格的项链和手镯袖口只是他们最畅销的一些。 Buccellati也为能够提供某些设计而感到自豪，这些设计使其珠宝具有非常吸引人的外观，如使用高品质的宝石和钻石刷金属和哑光，以及厚重的结壳。 3 Van Cleef＆Arpels梵克雅宝国家：法国创建日期：1896年创始人：Alfred Van Cleef和Salomon Arpels简介：当Estelle Arpels和Alfred Van Cleef决定将他们的合作作为永久性安排时，Van Cleef＆Arpels成立。虽然它的大部分系列都展现了旧世界物品中的优雅风格，但它还有其他系列产品，散发着自己的风格和阶级。这座房子展示了一个庞大的系列，融合了传统和叙事风格以及技术专长。 2卡地亚卡地亚国家：法国创建日期：1847年创始人：路易-弗朗索瓦·卡地亚简介：列表中的另一个家喻户晓的名字，卡地亚是一个已存在多年的名字。 卡地亚成立于1860年，一直是皇室成员的珠宝商，他们希望拥有个性化的系列。 黑豹是卡地亚最知名的设计，经过不断的修改和重新概念化，以吸引客户不断变化的品味。 卡地亚以其装饰艺术历史而闻名，但也创造了几条线条来庆祝旧世界的优雅。 1 Harry Winston温斯顿国家：美国创建日期：1932创始人：哈里温斯顿简介：一个在珠宝行业引起共鸣的名字，Harry Winston于1932年开始创业，并一直处于领先地位。 Harry Winston的系列仅使用最好的宝石和最好的金属，仅由珠宝工艺大师设计。 Harry Winston家居的产品不仅优雅而奢华，而且耐用，并且很容易通过时间的考验。]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>珠宝</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[以太坊（Ethereum）简介]]></title>
    <url>%2F2019%2F04%2F23%2F%E4%BB%A5%E5%A4%AA%E5%9D%8A%EF%BC%88Ethereum%EF%BC%89%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[以太坊是一个开源的有智能合约功能的公共区块链平台。通过其专用加密货币以太币（Ether，又称“以太币”）提供去中心化的虚拟机（称为“以太虚拟机”Ethereum Virtual Machine）来处理点对点合约。 以太坊（Ethereum）简介 概念：是一个开源的有智能合约功能的公共区块链平台。通过其专用加密货币以太币（Ether，又称“以太币”）提供去中心化的虚拟机（称为“以太虚拟机”Ethereum Virtual Machine）来处理点对点合约。 以太坊的概念首次在2013至2014年间由程序员维塔利克·布特林受比特币启发后提出，大意为“下一代加密货币与去中心化应用平台”，在2014年透过ICO众筹得以开始发展。 截至2018年6月，以太币是市值第二高的加密货币，以太坊亦被称为“第二代的区块链平台”，仅次于比特币。 创始人Vitalik Buterin（V神）国籍：俄裔加拿大人出生日期：1994年1月31日事迹：以太坊创始人、以太坊白皮书作者 特点1.智能合约（smart contract）存储在区块链上的程序，由各节点运行，需要运行程序的人支付手续费给节点的矿工或权益人。 2.代币（tokens）智能合约可以创造代币供分布式应用程序使用。分布式应用程序的代币化让用户、投资者以及管理者的利益一致。代币也可以用来进行首次代币发行。 3.叔块（uncle block）将因为速度较慢而未及时被收入母链的较短区块链并入，以提升交易量。使用的是有向无环图的相关技术。 4.权益证明（proof-of-stake）相较于工作量证明更有效率，可节省大量在挖矿时浪费的计算机资源，并避免特殊应用集成电路造成网络中心化。 5.支链（Plasma）用较小的分支区块链运算，只将最后结果写入主链，可提升供单位时间的工作量。 6.状态通道（state channels）原理类似比特币的闪雷网络，可提升交易速度、降低区块链的负担，并提高可扩展性。尚未实现，开发团队包括雷电网络（Raiden Network）和移动性网络（Liquidity Network）。 7.分片（sharding）减少每个节点所需纪录的数据量，并透过平行运算提升效率。 8.分布式应用程序以太坊上的分布式应用程序不会停机，也不能被关掉。 发展历程1.激活：边境以太坊的公共区块链在2015年7月30日引导。最初的以太坊版本称为边境（Frontier，也有“前锋”的意思），用的是[工作量证明]（proof-of-work）的算法，目前转换成[权益证明]（proof-of-stake）。 2.硬分叉自最初版本以来，以太坊网络成功进行了数次硬分叉。第一次分叉调整了未来挖矿的难度，确保未来的用户会有转换至权益证明的动机。当前第五个分叉正在开发中。 3.第二次分叉：家园2016年春季进行了第二次分叉，发布了第一个稳定版本，称作“家园”（Homestead）。 4.第三次分叉：DAO和区块链分叉2016年六月，以太坊上的一个去中心化自治组织被骇，造成市值五千万美元的以太币被移动到只有该黑客可以控制的“分身DAO”。因为程序不允许黑客立即提取这些以太币，以太坊用户有时间讨论如何处理此事，考虑的方案包括取回以太币和关闭DAO，而DAO去中心化的本质也表示没有中央权力可以立即反应，而需要用户的共识。最后在2016年7月20日，以太坊进行硬分叉，作出一个向后不兼容的改变，让所有的以太币（包括被移动的）回归原处，而不接受此改变的区块链则成为古典以太坊。这是第一次有主流区块链为了补偿投资人，而透过分叉来更动交易记录。 在这次分叉之后，造成了在两个区块链之间进行重放攻击的可能，加上其他网络攻击，让以太坊和古典以太坊又各自进行了数次分叉来避免攻击。 5.第四次分叉：减重和防DDoS2016年11月底进行了第四次的分叉。这次分叉为区块链减重（de-bloat），并加入一些避免网络攻击的设计。因为沟通疏失，这次分叉短暂造成以太坊的两个主要客户端程序 Parity 和 Geth 失去共识而产生意外的分叉，但问题在数小时内即被找出并修正。 发展与挑战2018年9月，比特币核心开发者Jeremy Rubin在美国科技媒体TechCrunch上发表文章《ETH的崩溃无法避免》，称就算以太坊网络继续存续，ETH的价值也会必然归零。以太坊创始人Vitalik在回应中承认了问题的存在：“如果以太坊不改变，Jeremy Rubin的言论可能是对的”。此番言论造成ETH的价钱一度下挫。同时，许多以太坊的项目开始转移到EOS﹑波场等的其他公链上，有人担心以太坊将被取代。在ETH的价格影响下，以太坊的全网算力开始收缩，按etherscan.io的算力统计显示，9月到11月以太坊全网算力下跌了20％，从近300TH/s收缩至240TH/s。 2018年12月10日，Vitalik在推特上宣称，未来采用基于[权益证明 (PoS)]的分片技术的区块链“效率将提高数千倍”。 2019年，以太坊项目进行君士坦丁堡硬分叉，这是一个刺激以太坊网络改变其核心共识机制算法的代码，这一段代码引导之后以太坊便会面临所谓的“冰河时代”，在该网络上的创建新区块的难度将会不断提升，最终减慢到完全停止。在该硬分叉升级之后，以太坊区块链的状态将“永久性”的改变。]]></content>
      <categories>
        <category>数字货币</category>
      </categories>
      <tags>
        <tag>以太坊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[人们最有可能帮助陌生人的十大国家]]></title>
    <url>%2F2019%2F04%2F23%2F%E4%BA%BA%E4%BB%AC%E6%9C%80%E6%9C%89%E5%8F%AF%E8%83%BD%E5%B8%AE%E5%8A%A9%E9%99%8C%E7%94%9F%E4%BA%BA%E7%9A%84%E5%8D%81%E5%A4%A7%E5%9B%BD%E5%AE%B6%2F</url>
    <content type="text"><![CDATA[2018年, 人们最有可能帮助陌生人的十大国家: 排名如下： 利比亚: 83% 伊拉克: 81% 科威特: 80% 利比里亚: 80% 塞拉利昂: 80% 巴林: 74% 冈比亚: 74% 沙特阿拉伯: 74% 肯尼亚: 72% 美国: 72% (World Giving Index)]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[2018年全球道路质量排行]]></title>
    <url>%2F2019%2F01%2F10%2F%E9%81%93%E8%B7%AF%E8%B4%A8%E9%87%8F%E6%8E%92%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[Quality of roads, 2018. (of 140 countries) index as below:1.🇸🇬Singapore 新加坡2.🇨🇭Switzerland 瑞士3.🇳🇱Netherlands 荷兰 6.🇯🇵Japan 日本7.🇫🇷France 法国9.🇦🇪UAE 阿拉伯联合酋长国11.🇺🇸USA 美国13.🇪🇸Spain 西班牙19.🇩🇪Germany 德国25.🇨🇦Canada 加拿大26.🇬🇧UK 英国33.🇹🇷Turkey 土耳其42.🇨🇳China 中国51.🇮🇳India 印度69.🇵🇰PAK 巴基斯坦104.🇷🇺Russia 俄国110.🇲🇳Mongolia 蒙古112.🇧🇷Brazil 巴西132.🇳🇬Nigeria 尼日利亚]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>道路质量</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全球数字货币市值排名第三瑞波币XRP介绍]]></title>
    <url>%2F2019%2F01%2F06%2F%E7%91%9E%E6%B3%A2%E5%B8%81%EF%BC%88XRP%EF%BC%89%2F</url>
    <content type="text"><![CDATA[下面介绍瑞波币（XRP）的信息，希望对大家数字货币及投资有帮助。 概述： 旨在消除比特币对集中交换的依赖，比比特币使用更少的电力，并且比比特币更快地执行交易； Ripple加密货币协议于2012年推出，其主要目标是确保“任何规模的安全，即时和几乎免费的全球资金运营，无需任何退款”。该协议支持使用法定货币，加密货币，货物或任何其他单位（如旅客奖励里程或移动会议纪要）付款。 Ripple数字货币系统确认交易不是采矿，而是网络参与者的共识。 这种方法消除了对比特币中使用的集中交换的依赖。 Ripple也比比特币使用更少的电力，而交易执行得更快。 创始人： Ripple coin于2004年由加拿大温哥华市的网络开发人员Ryan Fugger首次实施跨境支付； 2005年，Fugger开始将Ripplepay建成金融服务，通过全球网络为在线社区成员提供安全支付选项； 在此协议的基础上，2011年5月出现了一种新的数字货币系统，其中发布了自己的加密货币XRP； 发行量：1000亿枚 发行时间：2011年 用途： 在Ripple中，用户通过使用以任意现实世界资产（美元，黄金，飞行里程等）计价的加密签名交易在他们之间进行支付。 为此，Ripple保留了一个分类账，用于记录彼此信任的用户之间的债务。 通过这种方式，所有资产都表示为债务。 当在彼此信任的两个用户之间进行支付时，根据每个用户设置的限制调整相互信用额度的余额。 为了在没有直接建立信任关系的用户之间发送资产，系统尝试在两个用户之间找到路径，使得路径的每个链接在具有信任关系的两个用户之间。 然后沿路径平衡所有，同时原子性调整。 客户：欧洲进出口银行、SendFriend、JNFX、FTCS、科威特Ahli银行、Transpaygo、BFC Bahrain、ConnectPay、GMT、WorldCom Finance、Olympia Trust company、Pontual/USEND和Rendimento等200家商业银行和金融机构。 事件： 1.2011-04-18，瑞波币是Ripple网络的基础货币，它可以在整个ripple网络中流通，总数量为1000亿 2.2015-01-20，Ripple Labs任命前白宫顾问Gene Sperling为董事 Sperling表示：“我很高兴加入Ripple Labs，他们的使命是通过一个通用的互联网协议大幅提高跨境支付的速度和效率。“与货币无关的Ripple协议是一项独特的技术，可以从根本上改变通信银行业务，并导致实时支付系统。 3.2016-10-20，Ripple和R3在跨境银行支付方面取得突破 该试验发生在旧金山的Ripple和由数十家银行支持的金融创新联盟R3之间。周四发布的公告涉及到12家银行，其中包括巴克莱和BMO,这些银行使用Ripple的货币XRP来为跨境结算提供流动性 4.2017-10-11：瑞波全球支付网络产品签署九个新用户 计划进行跨境资金转移 新成员包括国际支付处理服务商Bexs Banco de Cambio、为优步和GoDaddy提供支付服务的dLocal。目前该网络成员超过100，包括Credit Agricole、Currencies Direct、IFX、TransferGo、Cuallix, Krungsri和Rakbank。 5.2018年2月6日，交易平台BitMEX对外公布一份Ripple调查报告，其中阐述瑞波币早期的分类账本中已遗失32570个区块，无法修复并获得其中的数据，而无法完整审核整个瑞波币区块链和1000亿XRP币的完整路径； 6.2018年2月，西联汇款宣布与Ripple公司合作，测试通过Ripple进行资金交易并实现资本最优化。 7.2018年某段时期一度超越以太坊成为第二大加密货币，目前第三位。]]></content>
      <categories>
        <category>数字货币</category>
      </categories>
      <tags>
        <tag>XRP</tag>
        <tag>瑞波币</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全球游戏公司游戏营收排行]]></title>
    <url>%2F2019%2F01%2F05%2F%E6%B8%B8%E6%88%8F%E5%B8%82%E5%9C%BA%E8%90%A5%E6%94%B6%E6%8E%92%E5%90%8D%2F</url>
    <content type="text"><![CDATA[游戏市场市场研究机构Newzoo发布2018年全球游戏市场报告，报告中显示，腾讯游戏相关营收增长9%，达到197亿美元，占据全球游戏市场近15%的份额。索尼以142亿美元营收排名第二，微软营收98亿美元排名第三。 游戏营收排名：1.腾讯2.索尼3.微软4.苹果5.动视暴雪6.谷歌7.网易8.EA9.任天堂10.万代南梦宫]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>游戏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[恒星币（XLM）]]></title>
    <url>%2F2019%2F01%2F04%2F%E6%81%92%E6%98%9F%E5%B8%81%EF%BC%88XLM%EF%BC%89%2F</url>
    <content type="text"><![CDATA[下面介绍全球数字货币市值排名第九的恒星币（XLM） 概述：代码是基于瑞波币的基础上修改的。用于搭建一个数字货币与法定货币之间传输的去中心化网关，是一个用于价值交换的开源协议； 该协议由非营利性、非股票型组织因此，基金的创始人无法从其经营或出售其股份中获益； Stellar Development Foundation基金会提供支持； 平台完全对外开源； 该平台承诺发布涵盖其活动的各种报告：关于雇员工资的报告;关于流氓补助金工作人员的报告;预算;分布流明数;流明的分布机制等； 在平台上可以看到发行量，每周产生的流量（每年产生1%的认为通胀），基金的发展将要花多少钱（总数的5%）； 大多数免费发放，5%作为运营使用，25%流向非营利组织； 拥有大量恒星币的组织或个人必须拥有5年以上才能出售其资产； Stellar平台的组织者已经尽一切可能从这个项目中排除任何赌博组件； 2019年3月，IBM发布公告称，包括Banco Bradesco，Bank Rusan和Rizal Commercial Banking Corporation在内的六家国际银行签署了在World Wire上发行自己的稳定币的意向书，这是IBM利用Stellar公共区块链的支付网络。 创始人：瑞波币的前创始人Jed McCaleb，电驴（BT下载软件）的创始人 发行量：1000亿枚，95%用于免费发放。目前流通量约为191亿枚： 50%通过直接分发计划分配给全世界； 25%通过增加覆盖计划分配给非营利组织以给予金融服务匮乏的人群； 20%通过比特币计划分配； 5%留作运营费用恒星币运营。 发行时间：2014年 用途：去中心化网关，通过转换全球各国之间的稳定加密货币的方式，进行跨境支付 客户：IBM、菲律宾的RCBC、巴西的Banco Bradesco、韩国的Bank Busan 2017年10月Stellar宣布与IBM合作，成为IBM Blockchain平台战略的一部分，为跨国界提供更便宜，更快速的支付]]></content>
      <categories>
        <category>数字货币</category>
      </categories>
      <tags>
        <tag>XLM</tag>
        <tag>恒星币</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[德国的世界品牌]]></title>
    <url>%2F2019%2F01%2F04%2F%E5%BE%B7%E5%9B%BD%E7%9A%84%E4%B8%96%E7%95%8C%E5%93%81%E7%89%8C%2F</url>
    <content type="text"><![CDATA[Companies based in Germany:德国的世界品牌： 品牌如下： 1234567891011121314151617181920- Volkswagen 大众 汽车- Allianz 安联 保险- Mercedes Benz 奔驰 汽车- Audi 奥迪 汽车- BMW 宝马 汽车- Porsche 保时捷 汽车- Lufthansa 汉莎 航空- Siemens 西门子 电子电器工程- BASF 巴斯夫 化工- Bayer 拜耳 医疗保健、化工及农业- Fresenius 费森尤斯 医药- Merck 默克 生物科技- Linde 林德 工业机械- ThyssenKrupp Group蒂森克虏伯 工业工程、钢铁- SAP 思爱普 企业管理、咨询- Deutsche Telekom 德国电信 电信- Aldi 阿尔迪 食品连锁超市- Bosch 博世 工业、交通- Lidl 历德 零售（欧洲的沃尔玛）- Adidas 阿迪达斯 服装 你用到了哪些呢？]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>德国</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[尼古拉·特斯拉]]></title>
    <url>%2F2019%2F01%2F03%2F%E5%B0%BC%E5%8F%A4%E6%8B%89%C2%B7%E7%89%B9%E6%96%AF%E6%8B%89%2F</url>
    <content type="text"><![CDATA[下面介绍 尼古拉·特斯拉 这个交流电之父。 24岁的特斯拉全无天才的气质，甚至可以说，是一个失败者。1882年，成为一家电话公司的工程师。特斯拉开始展现才华，设计出第一台感应电机模型。1884年，带着前雇主的推荐信，特斯拉第一次来到美国，见到了传说中的爱迪生，成为他的助手。后来辞职后创业。爱迪生是直流电的死忠，特斯拉主推交流电。可以说，直流电与交流电之争决定两家公司的生死。再后来，交流电取代直流电，成为主流，奠定了现代电力的基础。因此，特斯拉，而非爱迪生才是真正的“电气时代之父”。1897年就获得了无线电技术的专利。1898年，特斯拉制造了能产生人工地震的振荡器，在输入频率时，差点将纽约市夷为平地。1899年，特斯拉造出一大堆球状闪电，这是迄今为止，世界上唯一一次在实验室制造出球状闪电。1901年，特斯拉建造了沃登克里弗塔，用于横跨大西洋的无线电能传输实验。1917年，特斯拉就向美国海军提出雷达的概念。特斯拉先于伦琴发现X射线。还发明了遥控器、发动机火花塞、霓虹灯、现代电动机。建立了第一次成功记录接收了来自外太空无线电电波，他在一百多年前就持有晶体管的专利世界上第一个水利发电站——尼亚加拉水电站。现在手机吹嘘的“无线充电技术”，其实是特斯拉100年前玩剩下的。特斯拉的无线照明特斯拉还设计过一种”没有机翼，没有副翼，没有螺旋桨，没有其他外部装置的飞机“。飞行速度极高，完全通过反作用实现续航和驱动。 他每天只睡2个小时，独自取得700多项发明专利，合作开发1000种以上。他被诺贝尔物理学奖提名11次，全部让贤。作为交流电的发明人，一年之内，就可以靠专利费，成为世界首富。他却毅然将“交流电专利”撕毁，免费向社会开放。最终，一生贫困潦倒。1943年，尼古拉·特斯拉在贫穷、孤独中去世。今天，提起特斯拉，大部分人想到的只是一辆电动车，而非一位科学家。]]></content>
      <categories>
        <category>人物</category>
      </categories>
      <tags>
        <tag>特斯拉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各国诺贝尔奖数]]></title>
    <url>%2F2019%2F01%2F02%2F%E5%90%84%E5%9B%BD%E5%BE%97%E8%AF%BA%E5%A5%96%E6%95%B0%2F</url>
    <content type="text"><![CDATA[Nobel prizes.诺贝尔奖数： 排名如下：US: 377 美国UK: 130 英国Germany: 108 德国France: 70 法国Sweden: 32 瑞典Japan: 27 日本Canada: 26 加拿大Switzerland: 26 瑞士Russia 25 俄国Austria: 21 奥地利Netherlands: 21 荷兰Italy: 20 意大利Poland: 14 波兰Denmark: 13 丹麦Norway: 13 挪威Hungary: 13 匈牙利Australia: 12 澳大利亚Israel: 12 以色列Belgium: 11 比利时India: 10 印度South Africa: 10 南非China: 8 中国Spain: 8 西班牙 中国： 大陆：第十四世达赖喇嘛 刘晓波 莫言 屠呦呦 台湾：丁肇中 李遠哲 李政道 杨振宁]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>诺贝尔奖</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[印度处于领先地位的产品]]></title>
    <url>%2F2019%2F01%2F02%2F%E5%8D%B0%E5%BA%A6%E5%A4%84%E4%BA%8E%E9%A2%86%E5%85%88%E5%9C%B0%E4%BD%8D%E7%9A%84%E4%BA%A7%E5%93%81%2F</url>
    <content type="text"><![CDATA[印度处于领先地位的产品： 香蕉 芒果 番木瓜 柠檬 水牛奶 山羊奶 辣椒 生姜 鹰嘴豆 小米 黄麻 木材燃料 你用过或者吃过吗？]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>印度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019年最健康的国家指数]]></title>
    <url>%2F2019%2F01%2F01%2F%E6%9C%80%E5%81%A5%E5%BA%B7%E7%9A%84%E5%9B%BD%E5%AE%B6%E6%8C%87%E6%95%B0%EF%BC%8C2019%E5%B9%B4%2F</url>
    <content type="text"><![CDATA[最健康的国家指数，2019年 排名如下：1.西班牙2.意大利3.冰岛4.日本6.瑞典7.澳大利亚8.新加坡9.挪威10.以色列12.法国16.加拿大17.韩国19.英国23.德国26.希腊35.美国40.波兰48.匈牙利51.土耳其52.中国53.墨西哥54.阿根廷（彭博社） 希望你所在的国家，没有食品安全问题。]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>健康</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中本聪与比特币]]></title>
    <url>%2F2018%2F12%2F31%2F%E4%B8%AD%E6%9C%AC%E8%81%AA(Satoshi%20Nakamoto)%26%E6%AF%94%E7%89%B9%E5%B8%81%2F</url>
    <content type="text"><![CDATA[介绍下比特币与中本聪的故事，点击更多 中本聪(Satoshi Nakamoto) 【BTC设计初衷】并不希望数字加密货币被某国政府或中央银行控制，而是希望其成为全球自由流动、不受政府监管和控制的货币。 【BTC发展概述】比特币协议及其相关软件Bitcoin-Qt的创造者，但真实身份未知。于2008年发表了一篇名为《比特币：一种点对点式的电子现金系统》（Bitcoin: A Peer-to-Peer Electronic Cash System）的论文，描述了一种被他称为“比特币”的电子货币及其算法。2009年，他发布了首个比特币软件，并正式启动了比特币金融系统。2010年，他逐渐淡出并将项目移交给比特币社区的其他成员。2015年，加州大学洛杉矶分校金融学教授Bhagwan Chowdhry曾提名中本聪为2016年诺贝尔奖经济学奖的候选人。Bhagwan Chowdhry说：“比特币的发明简直可以说是革命性的。中本聪的贡献不仅将会彻底改变我们对金钱的思考方式，很可能会颠覆央行在货币政策方面所扮演的角色，并且将会破坏如西联这样高成本汇款的服务，彻底消除如Visa，MasterCard、PayPal他们收取2-4%的中间人交易税，消除费事且昂贵的公证和中介服务，事实上它将彻底改变法律合约的方式。” 【中本聪身份猜测】1.中情局特勤小组有阴谋论者认为比特币其实是由美国金融机构与政府联手打造的一款骗局工具，目的是地巨大利差引诱投资者巨额投入，再以利差吸取这些投资以平衡美国政府财政。因此中本聪并不是一个人，而是一个小组的代号。这种说法并未得到任何机构或个人的认可，但在反比特币者当中认同度很高。随着近期比特币等加密货币价格的暴跌，这种说法开始在一些比特币持有者当中流传。 2.望月新一2012年5月，计算机科学家泰德·尼尔森认为中本聪就是日本数学家望月新一，认为其足够聪明，研究领域包含比特币所使用的数学算法。更重要的是，望月不使用常规的学术发表机制，而是习惯是独自工作，发表论文后让其他人自己理解。然而也有人提出质疑，认为设计比特币所需的密码学并非望月的研究兴趣。望月本人亦予以否认。 3.尼克·萨博2013年12月，博客作家Skye Grey通过对中本论文的计量文体学分析得出结论，认为其真实身份是前乔治华盛顿大学教授尼克·萨博。萨博热衷于去中心化货币，还发表过一篇关于“比特黄金”（bit gold）的论文，被认为是比特币的先驱。他也是一个著名的从90年代起就喜欢使用化名的人。在2011年5月的一篇文章中，萨博谈起比特币创造者时表示：“在我认识的人里面，对这个想法足够感兴趣，并且能付诸实施的，本来只有我自己、戴维（Wei Dai）、哈尔·芬尼三个人，后来中本出现了（假定中本不是芬尼也不是戴维）。” 4.多利安·中本最为公众所熟知的猜测发生在2014年3月6日。新闻周刊记者Leah McGrath Goodman发表文章称自己已经找到真正的中本，是一个居住在加利福尼亚州的日裔美国人，名叫多利安·中本，而“哲史”是他出生时的名字。除了名字相同以外，Goodman还找到了一些佐证，其中最有力的一条是，当Goodman在当面采访并提出比特币的问题时，多利安的回答看起来确认了其比特币之父的身份：“我已经不再参与它了，不能讨论它。它已经被转交给其他人。他们现在在负责。我已经没有任何联系。”这段话的真实性亦得到了当时在场的洛杉矶郡警察的确认。报道被公开后受到了包括比特币社区在内舆论的质疑和批评，但同时也引起了媒体的巨大兴趣。记者们蜂拥而至多利安的住宅外蹲守，甚至追逐他的汽车。然而在后来的正式访谈中，多利安否认了自己与比特币的全部联系，称自己从未听说过，只是误解了Goodman的提问，以为她问的是自己之前从军方承接的保密性工作。当天晚些时候，中本聪本人也站出来否认。他在P2P基金会的账户在尘封五年之后发了第一条消息，称：“我不是多利安·中本。” 5.克雷格·史蒂芬·怀特2015年12月，《连线杂志》报道说澳大利亚学者克雷格·史蒂芬·怀特很有可能是中本聪的本尊。同时也指出，也许只是他精心设计的一个高明的骗局想让我们相信他就是中本聪本人。直到2016年5月2日，澳大利亚企业家克雷格·史蒂芬·怀特公开承认自己就是发明比特币的中本聪，首度有人公开承认。其证据是中本聪的加密签名档，但被质疑该档只要是稍微高端一点的黑客都能在暗网中找到下载，早就在不少计算机高手圈流传，另一证据是早期第1及第9区块比特币地址的私钥，但此私钥如果是早期比特币开发人员或其亲近者都有可能拿到。最关键证明是导入比特币至2009年的比特币第一笔交易地址，该地址被视为是中本聪所有，并要求表演汇回，BBC记者将0.017个比特币导入，但最终没有汇回。BBC刊退出和他的访谈片段，自称他就是比特币发明者。但克雷格声明与证据的真实性受到普遍的质疑，在最后阶段要求演示关键证据时，克雷格拒绝并发布了一篇顾左右而言他的博客文章。 6.Vincent van Volkmer自2018年以来，互联网声称美国艺术家Vincent van Volkmer是中本聪。对此同时也有一系列证据，例如：他谈到他是一名数学家和密码学家的事实，他也与拥有导致阻碍技术相关知识的专家保持着良好的联系。不过，他自己也反驳了他就是中本聪的这种说法。 7.其它猜测还有一些其他个人或团体被认为是中本聪的真身。其中包括：芬兰经济社会学家Dr Vili Lehdonvirta及爱尔兰密码学研究生Michael Clear。两人分别否认。德国及美国研究人员Neal King、Vladimir Oksman和Charles Bry。他们曾共同申请注册一项与比特币相关的专利，而比特币项目官方网站的域名bitcoin.org恰好注册于专利申请提交之后的第三天。三人均否认此猜测。比特币基金会首席科学家Gavin Andresen、比特币交易平台Mt. Gox创始人Jed McCaleb，或某个政府机构。[1]美国企业家及安全研究员Dustin D. Trammell，但他公开否认。也有人认为Satoshi Nakamoto的名字实际上是四家公司名字的组合，包括三星（Samsung）、东芝（Toshiba）、中道（Nakamichi）和摩托罗拉（Motorola），暗示着比特币其实是这四家公司联手开发并以Satoshi Nakamoto，即“中本聪”的化名来发表。]]></content>
      <categories>
        <category>数字货币</category>
      </categories>
      <tags>
        <tag>数字货币</tag>
        <tag>中本聪</tag>
        <tag>比特币</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三星集团]]></title>
    <url>%2F2018%2F12%2F30%2F%E4%B8%89%E6%98%9F%E9%9B%86%E5%9B%A2%2F</url>
    <content type="text"><![CDATA[下面介绍下三星集团的基本信息： 三星集团1.公司名称：三星集团2.成立时间：1938年3.创始人：李秉哲4.现任会长：李健熙5.总部位置：韩国首尔6.公司分类：电子、金融、机械、化学7.全球员工人数：20万8.年营收：2119.41亿美元（2018年），约等于14200亿人民币9.全球500强：第12位10.旗下所有业务：电子： 三星电子：消费型电子（手机、显示器）、内存、闪存等； 三星SDI：太阳能电池、燃料电池、能源储存； 三星SDS：IT相璃基板、等离子过滤器、显像管和玻璃； 三星航空：三星贝尔427，为贝尔、波音等公司的产品提供服务； 三星半导体：主要业务为生产SD卡，世界最大的存储芯片制造商；机械 三星重工：主要业务为造船； 三星工程：主要业务为制造电子零件装备、军用飞机零组件； 三星道逹尔：主要业务为制造塑料、化工产品、石油产品。； 三星石油化学：主要业务为PTA； 三星精密化学：主要业务为制造电子化学材料、精密化学制品； 三星BP化学：主要业务为制造硝酸、H2、VAM；金融保险 三星生命保险：主要业务为人寿保险和金融服务； 三星火灾海上保险：主要业务为人寿保险和金融服务； 三星信用卡 [18] ：主要业务为信用卡业务，贷款，租赁服务； 三星证券：主要业务为资产管理、中介业务； 三星投资信托管理：主要业务为投资信托； 三星风险投资：主要业务为风险投资业务；其他 三星物产：主要业务有贸易部门和建设部门； 三星第一毛织：主要业务为是时装、纺织、化工、电子材料相关； 三星第一广告：主要业务为是广告代理业务； 三星新罗酒店：主要业务为是酒店相关业务； 三星爱宝乐园：位于京畿道龙仁市的游乐园，是韩国第二大游乐园，由庆典世界、加勒比海湾、爱宝乐园赛车场组成； 三星首尔医院：位于韩国首尔的医院，韩国最大、最具影响力的医院，隶属于三星集团； 三星狮：韩国职业棒球捧场数最多的球队；]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>三星</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019世界上城市生活成本排行]]></title>
    <url>%2F2018%2F12%2F29%2FWorld's%20most%20expensive%20cities%2C%202019.%20(cost%20of%20livi%2F</url>
    <content type="text"><![CDATA[World’s most expensive cities, 2019. (cost of living)2019世界上城市生活成本排行： 排名如下： 1234567891011=1.🇸🇬Singapore 新加坡 新加坡=1.🇫🇷Paris 巴黎 法国=1.🇭🇰Hong Kong 香港 中国4.🇨🇭Zurich 苏黎世 瑞士=5.🇨🇭Geneva 日内瓦 瑞士=5.🇯🇵Osaka 大阪 日本=7.🇰🇷Seoul 首尔 韩国=7.🇩🇰Copenhagen 哥本哈根 丹麦=7.🇺🇸New York 纽约 美国=10.🇮🇱Tel Aviv 特拉维夫 以色列=10.🇺🇸Los Angeles 洛杉矶 美国 The Economist Intelligence Unit, 2019]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>城市生活成本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018世界医药顶尖大学]]></title>
    <url>%2F2018%2F12%2F29%2FTop%20universities%20in%20medicine%2C%202018%2F</url>
    <content type="text"><![CDATA[Top universities in medicine, 2018.2018世界医药顶尖大学： 排名如下： 123456789101. Harvard 哈佛大学 美国2. Oxford 牛津大学 英国 3. Cambridge 剑桥大学 英国4. Stanford 斯坦福大学 美国5. John Hopkins 约翰·霍普金斯大学 美国6. Karolinska Institutet 卡罗林斯卡学院 瑞典7. Uni of California, LA 加州大学洛杉矶分校 美国8. Yale 耶鲁大学 美国9. MIT 麻省理工学院 美国10. University College London 伦敦大学学院 英国]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>医药大学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019世界上最著名的运动员]]></title>
    <url>%2F2018%2F12%2F28%2FThe%20world%E2%80%99s%20most%20famous%20athletes%2C%202019%2F</url>
    <content type="text"><![CDATA[The world’s most famous athletes, 2019.2019世界上最著名的运动员： 1234567891011121314151617181920排名 人名 中文名 职业 就职国家 国籍 1 Ronaldo 罗纳尔多 足球 西班牙 葡萄牙2 LeBron 勒布朗·詹姆斯 篮球 🇺🇸美国 美国3 Messi 里奥·梅西 足球 🇦🇷阿根廷 阿根廷4 Neymar 内马尔·达席尔瓦 足球 法国 巴西5 McGregor 康纳·麦格雷戈 格斗 🇮🇪爱尔兰 爱尔兰6 Federer 罗杰·费德勒 网球 🇨🇭瑞士 瑞士7 Kohli 维拉·哥利 板球 🇮🇳印度 印度8 Nadal 拉菲尔·纳达尔 网球 🇪🇸西班牙 西班牙12 Pogba 保罗·博格巴 足球 🇫🇷法国 几内亚14 Mbappe 姆巴佩 足球 🇫🇷法国 法国17 Serena 塞雷娜·威廉姆斯 网球 🇺🇸美国 美国19 Özil 梅苏特·厄齐尔 足球 🇩🇪德国 德国21 󠁧Hamilton 理查德·汉密尔顿 篮球 🇺🇸美国 美国30 Salah 穆罕默德·萨拉赫 足球 🇪🇬埃及 埃及33 Bale 加雷斯·贝尔 足球 威尓士 威尓士38 Ramos 塞尔吉奥·拉莫斯 足球 🇪🇸西班牙 西班牙41 Ninja Ninja 电竞 🇺🇸美国 美国 58 Benzema 卡里姆·本泽马 足球 🇫🇷法国 法国73 Kroos 托尼·克罗斯 足球 🇩🇪德国 德国]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>运动员</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The world's Top 100 Airports for 2018]]></title>
    <url>%2F2018%2F12%2F27%2FThe%20world's%20Top%20100%20Airports%20for%202018%2F</url>
    <content type="text"><![CDATA[The world’s Top 100 Airports for 2018, as voted for by air travellers around the world during the 2017/2018 survey periodPlease note that over 500 airports were covered in the survey but we only feature the top 100 listing here (this listing may not be reproduced without the consent of Skytrax). as blow: 1 Singapore Changi 1 20172 Seoul Incheon 3 20173 Tokyo Haneda 2 20174 Hong Kong 5 20175 Doha Hamad 6 20176 Munich 4 20177 Centrair Nagoya 7 20178 London Heathrow 9 20179 Zurich 8 201710 Frankfurt 10 2017 15 Taiwan Taoyuan 21 2017 18 Shanghai Hongqiao 18 2017 28 London City 36 2017 33 Beijing Capital 25 2017 37 Paris CDG 32 2017 51 San Francisco 39 2017]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>Airports</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日本近几年的经济数据]]></title>
    <url>%2F2018%2F12%2F26%2FJapan%20Economy%20Data%2F</url>
    <content type="text"><![CDATA[Japan Economy Data ![日本近几年经济数据](Japan Economy Data/japan_economy_data.jpg) 你看到了什么？]]></content>
      <categories>
        <category>经济</category>
      </categories>
      <tags>
        <tag>日本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全球各国家离婚率排行]]></title>
    <url>%2F2018%2F12%2F26%2FHighest%20Divorce%20Rate%20by%20Country%2F</url>
    <content type="text"><![CDATA[Highest Divorce Rate by Country全球各国家离婚率排行： 1.Luxembourg : 87% 卢森堡2.Spain: 65% 西班牙3.France: 55% 法国4.Russia: 51% 俄国5.United States: 46% 美国6.Germany: 44% 德国7.United Kingdom: 42% 英国8.New Zealand: 42% 新西兰9.Australia: 38% 澳大利亚10.Canada 38% 加拿大. .. India 1% 印度 你们国家的离婚率大概是多少呢？let me know in the comments.]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>离婚率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019全球国家手机网络连接速度排行]]></title>
    <url>%2F2018%2F11%2F26%2FAverage%20speed%20of%20mobile%20internet%20connections%2C%202019%2F</url>
    <content type="text"><![CDATA[Average speed of mobile internet connections, 2019. (in MBPS)2019全球国家手机网络连接速度排行（MB/s) 1.ISL: 73.93 以色列2.NOR: 70.29 挪威3.CAN: 65.68 加拿大4.AUS: 56.70 澳大利亚5.SIN: 54.96 新加坡6.KOR: 52.53 韩国7.FRA: 43.34 法国8.USA: 33.19 美国9.JPN: 32.08 日本10.HK: 32.00 香港11.GER: 31.46 德国12.KSA: 30.80 沙特阿拉伯13.GBR: 30.12 英国14.CHN: 30.08 中国15.RUS: 19.16 俄国16.IND: 10.13 印度 (Ookla) 你在哪个国家呢？]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>移动通信</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows_C盘垃圾清理]]></title>
    <url>%2F2018%2F11%2F03%2Fwindows-C%E7%9B%98%E5%9E%83%E5%9C%BE%E6%B8%85%E7%90%86%2F</url>
    <content type="text"><![CDATA[windows c盘垃圾清理程序，清理各类软件的缓存文件、日志文件等，长时间未清洗，可以空出10多G的空间出来，具体程序如下，创建一个abc.bat可执行文件（名字随便取），点击运行即可： 12345678910111213141516171819@echo off echo 正在清除系统垃圾文件，请稍等...... del /f /s /q %systemdrive%\*.tmp del /f /s /q %systemdrive%\*._mp del /f /s /q %systemdrive%\*.log del /f /s /q %systemdrive%\*.gid del /f /s /q %systemdrive%\*.chk del /f /s /q %systemdrive%\*.old del /f /s /q %systemdrive%\recycled\*.* del /f /s /q %windir%\*.bak del /f /s /q %windir%\prefetch\*.* rd /s /q %windir%\temp &amp; md %windir%\temp del /f /q %userprofile%\小甜饼s\*.* del /f /q %userprofile%\recent\*.* del /f /s /q &quot;%userprofile%\Local Settings\Temporary Internet Files\*.*&quot; del /f /s /q &quot;%userprofile%\Local Settings\Temp\*.*&quot; del /f /s /q &quot;%userprofile%\recent\*.*&quot; echo 清除系统LJ完成！ echo. &amp; pause 随便放在电脑的一个位置，点击运行即可。]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>垃圾清理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019年全球最具价值的餐饮品牌]]></title>
    <url>%2F2018%2F10%2F26%2F2019%E5%B9%B4%E5%85%A8%E7%90%83%E6%9C%80%E5%85%B7%E4%BB%B7%E5%80%BC%E7%9A%84%E9%A4%90%E9%A5%AE%E5%93%81%E7%89%8C%2F</url>
    <content type="text"><![CDATA[2019年全球最具价值的餐饮品牌，拒绝食品垃圾。 品牌名称 国家 成立日期1.星巴克 美国 19712.麦当劳 美国 19553.赛百味 美国 19654.肯德基 美国 19525.提姆霍顿 加拿大 19646.达美乐披萨 美国 19607.汉堡王 美国 1952 公司能经营六七十年，背后是对品质、服务的追求，难道我们不应该支持吗？让地沟油、毒奶粉死去吧。 海底捞 中国 1994真功夫 中国 1990永和大王 中国 1995德克士 中国 1994喜家德 中国 2002味多美 中国 1996嘉和一品 中国 2004渝是乎 中国 2015呷哺呷哺 台湾 1998 半个世纪后见。]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>餐饮</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里巴巴mysql数据库binlog的增量订阅与消费组件canal]]></title>
    <url>%2F2018%2F09%2F05%2F%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4mysql%E6%95%B0%E6%8D%AE%E5%BA%93binlog%E7%9A%84%E5%A2%9E%E9%87%8F%E8%AE%A2%E9%98%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E7%BB%84%E4%BB%B6canal%2F</url>
    <content type="text"><![CDATA[首先介绍下canal他可以做什么，基于日志增量订阅&amp;消费支持的业务, 监控mysql数据，将mysql增量数据从binlog中获取过来实现数据库的镜像、数据库实时备份、多级索引、业务cache刷新等，具体参考阿里开源项目代码：canal github canaldbkafka简介canaldbkafka是连接canal和kafka的一个中间件。目的是实现数据库某个表格数据变更转变成消息流的形式，以便后续业务消费kafka的消息流。 canal wiki:https://github.com/alibaba/canal/wiki 消息的类型canal的binlog 会被解析成以下3中类型的消息。其他的类型被过滤掉了。 insert12345678910111213141516171819202122232425&#123; &quot;data&quot;: &#123; &quot;need_sub&quot;: &#123; &quot;type&quot;: &quot;int(11)&quot;, &quot;updated&quot;: true, &quot;value&quot;: &quot;0&quot; &#125;, &quot;order_description&quot;: &#123; &quot;type&quot;: &quot;varchar(1024)&quot;, &quot;updated&quot;: true, &quot;value&quot;: &quot;&quot; &#125;, &quot;pay_amount&quot;: &#123; &quot;type&quot;: &quot;int(11)&quot;, &quot;updated&quot;: true, &quot;value&quot;: &quot;0&quot; &#125;, &quot;pay_order&quot;: &#123; &quot;type&quot;: &quot;varchar(30)&quot;, &quot;updated&quot;: true, &quot;value&quot;: &quot;&quot; &#125; &#125;, &quot;type&quot;: &quot;insert&quot;&#125; delete12345678910111213141516171819202122232425&#123; &quot;data&quot;: &#123; &quot;need_sub&quot;: &#123; &quot;type&quot;: &quot;int(11)&quot;, &quot;updated&quot;: true, &quot;value&quot;: &quot;0&quot; &#125;, &quot;order_description&quot;: &#123; &quot;type&quot;: &quot;varchar(1024)&quot;, &quot;updated&quot;: true, &quot;value&quot;: &quot;&quot; &#125;, &quot;pay_amount&quot;: &#123; &quot;type&quot;: &quot;int(11)&quot;, &quot;updated&quot;: true, &quot;value&quot;: &quot;0&quot; &#125;, &quot;pay_order&quot;: &#123; &quot;type&quot;: &quot;varchar(30)&quot;, &quot;updated&quot;: true, &quot;value&quot;: &quot;&quot; &#125; &#125;, &quot;type&quot;: &quot;delete&quot;&#125; updatedata对象是各字段类型、是否被更新、值。olddata对象是之前的状态。 123456789101112131415161718192021222324252627&#123; &quot;data&quot;: &#123; &quot;Quota&quot;: &#123; &quot;type&quot;: &quot;tinyint(4)&quot;, &quot;updated&quot;: false, &quot;value&quot;: &quot;0&quot; &#125;, &quot;ReqAmount&quot;: &#123; &quot;type&quot;: &quot;int(11)&quot;, &quot;updated&quot;: true, &quot;value&quot;: &quot;100&quot; &#125; &#125;, &quot;olddata&quot;: &#123; &quot;Quota&quot;: &#123; &quot;type&quot;: &quot;tinyint(4)&quot;, &quot;updated&quot;: false, &quot;value&quot;: &quot;0&quot; &#125;, &quot;ReqAmount&quot;: &#123; &quot;type&quot;: &quot;int(11)&quot;, &quot;updated&quot;: false, &quot;value&quot;: &quot;0&quot; &#125; &#125;, &quot;type&quot;: &quot;update&quot;&#125; 使用说明编译安装123456789101112131415mvn compilemvn packagell target/canal-dbkafka #可部署total 0drwxr-xr-x 5 xxx staff 170B 12 21 21:26 bindrwxr-xr-x 3 xxx staff 102B 12 21 21:26 confdrwxr-xr-x 24 xxx staff 816B 12 21 21:26 libdrwxr-xr-x 2 xxx staff 68B 12 21 21:26 logsll target/canal-dbkafka/bin #startmy.sh为启动示例-rwxr-xr-x 1 xxx staff 271B 12 21 21:26 startmy.sh-rwxr-xr-x 1 xxx staff 2.5K 12 21 21:26 startup.sh-rwxr-xr-x 1 xxx staff 1.0K 12 21 21:26 stop.sh 启动说明已startmy.sh为例 123456789101112#!/bin/bashcurrent_path=`pwd`case &quot;`uname`&quot; in Linux) bin_abs_path=$(readlink -f $(dirname $0)) ;; *) bin_abs_path=`cd $(dirname $0); pwd` ;;esaccd $&#123;bin_abs_path&#125; &amp;&amp; ./startup.sh testdb thetable 127.0.0.1:2181 127.0.0.1:9092 testdb 是canal配置的destination thetable kafka的具体topic 127.0.0.1:2181 是canal配置HA 对应的zookeeper的地址 127.0.0.1:9092 是kafka的地址 使用注意事项 mysql binlog模式设置为row模式 为了保证数据库消息的顺序性，将消息存储kafka的时候组件采用了同步的方式 canal 必须配置zookeeper ha的模式 https://github.com/alibaba/canal/wiki/AdminGuide#ha%E6%A8%A1%E5%BC%8F%E9%85%8D%E7%BD%AE 之前使用针对的是数据库中的一个表在canal配置中已经过滤所以消息中没有表名 可以说是个设计的缺陷。 高可用及分布式监控多个mysqlcanal分服务端和客户端，我们需要监控多个mysql时，可以配置多个instance，具体编辑服务端配置文件canal.properties： 123456789############################################################# destinations ##############################################################canal.destinations=dest21,dest14# conf root dircanal.conf.dir = ../conf# auto scan instance dir add/remove and start/stop instancecanal.auto.scan = truecanal.auto.scan.interval = 5 其中dest21和dest14为不同的instance，目录结构如下： 12345-rwxr-xr-x 1 root root 2882 Aug 27 18:44 canal.propertiesdrwxr-xr-x 2 root root 4096 Sep 5 19:08 dest14drwxr-xr-x 2 root root 4096 Sep 5 19:09 dest21-rwxr-xr-x 1 root root 3038 Jun 19 17:18 logback.xmldrwxr-xr-x 3 root root 4096 Jun 19 17:18 spring dest14和dest21目录分别为监控不同mysql的配置文件放置位置，具体如下： 12345678910111213141516171819202122232425262728293031323334353637################################################### mysql serverIdcanal.instance.mysql.slaveId=14# position infocanal.instance.master.address=1.1.1.1:3306canal.instance.master.journal.name=canal.instance.master.position=canal.instance.master.timestamp=# table meta tsdb infocanal.instance.tsdb.enable=truecanal.instance.tsdb.dir=$&#123;canal.file.data.dir:../conf&#125;/$&#123;canal.instance.destination:&#125;canal.instance.tsdb.url=jdbc:h2:$&#123;canal.instance.tsdb.dir&#125;/h2;CACHE_SIZE=1000;MODE=MYSQL;#canal.instance.tsdb.url=jdbc:mysql://127.0.0.1:3306/canal_tsdbcanal.instance.tsdb.dbUsername=canalcanal.instance.tsdb.dbPassword=canal#canal.instance.standby.address =#canal.instance.standby.journal.name =#canal.instance.standby.position =#canal.instance.standby.timestamp =# username/passwordcanal.instance.dbUsername=canalcanal.instance.dbPassword=*****canal.instance.defaultDatabaseName=canal.instance.connectionCharset=UTF-8# table regex#canal.instance.filter.regex=.*\\..*canal.instance.filter.regex=event_collection\.user_location_lng_lat# table black regexcanal.instance.filter.black.regex=################################################# 你需要修改的地方： 12345canal.instance.mysql.slaveId -- 不同的instance分配不同的slaveId，因为canal监控mysql的原理就是伪装成mysql的slave来获取binlog日志的canal.instance.master.address -- 配置监控的mysql ip地址canal.instance.dbUsername -- 连接mysql的用户名canal.instance.dbPassword -- 连接mysql的密码canal.instance.filter.regex -- 监控mysql中的哪个库，哪个表 其中监控mysql的哪个库哪个表编写格式如下： 123.*\\..* --表示监控mysql所有库所有表test\..* --表示监控mysql test库下的所有表test\.test --表示监控mysql test库下的test表 阿里巴巴，我们程序员的梦想，开源的canal还是不错的，希望大家借助这篇文章能够熟练掌握canal的简单使用，如果遇到什么问题，欢迎一起讨论，在下方留言或者mail我：chenzuoli@gmail.com]]></content>
      <categories>
        <category>监控组件</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>canal</tag>
        <tag>监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[北京租房小中介骗局]]></title>
    <url>%2F2018%2F07%2F29%2F%E5%8C%97%E4%BA%AC%E7%A7%9F%E6%88%BF%E5%B0%8F%E4%B8%AD%E4%BB%8B%E9%AA%97%E5%B1%80%2F</url>
    <content type="text"><![CDATA[给大家说说我亲身经历的租房骗局，小中介如何骗你的钱。我会不定期在网站发布个人生活中遇到的各种骗局，发布到【个人黑名单】分类中，请大家持续关注，避免遇到同样的坑，打击坑蒙拐骗，让那些只顾赚钱，不顾服务的商家，淘汰掉。 中介公司美丽家园房地产有限公司、昊园恒业房地产有限公司 产品大熊公寓 总部地址北京市朝阳区财满街8号楼2单元703室 个人情况首先说说我的情况，码农一枚跟朋友一起租房，3个人，租2间房，一间2人，一间1人，无奈北京房租太贵，链家、我爱我家中介费太高，只好找小中介，不受中介费。 租房第一个坑：预付款时，一定看好是“订金”还是“定金”找到一个小中介公司，在一个小区里面租下15平米左右的主卧2000元，收了一个月押金。当时保证押金可以退回，家具家电均可以上门维修。于是就签合同，另一个朋友，在签合同的时候，了解到，如果中途退租的话，需要找到接盘侠，才能退租，把押金退给你，他不干，于是签了一半的合同终止了，但是中介不干啊，他说合同是要收钱的，200块，你说气不气人，还有，跟他们争论的时候，还问他们索要订金200块，但是那个条子上写的是“定金”，意思就是你已经预付款一些金钱把这个房子定下来了，于是发现情况不对，就对他们客气地说话，说我们之前没弄清楚情况，麻烦谅解一下，最后扣了100块，定金退了。所以大家以后预付款的时候，一定看好是“订金”还是“定金”。 第二个坑：房租付款方式，自付最好，不要和第三方借贷平台签约租金结算方式为58月付，58月付是一个借贷平台，通过借贷的方式，一次性借贷1年的房租也就是20000元，58月付一下子就把钱打给了中介公司，然后58每个月从你的银行卡中扣除2000元，这样中介公司实际就获得了20000元的借款，可以拿去投资或者业务扩张了，而实际是你借的钱。这种借贷是上了征信的，如果你有违约，征信就会出现问题，所以我没一次敢怠慢。 第三个坑：房屋中的家电不能用租下房子之前看过了房子，家电、桌椅、床等设施都齐全，灯、空调、冰箱都使用过了，确实是好的，于是签了合同，住进来才发现洗衣机没法用，缺少一根水管，于是联系他们，配一根洗衣机水管，于是他就叫我们自己弄，公司没有这项规定，也没有相应的业务人员做这个事情，于是只能自己网上买水管了啊，合同都签了。还有一次，灯不亮了，也叫他们过来维修，同样的理由，叫我们自己网上买个灯管，我们真是服了，对于服务这么差的中介，绝对不会合作第二次。 第三个坑：重新签合同，导致交租金提前美丽家园被收购，母公司重新过来签合同，之前是每月16日交租，现在12日交租，房租提前4天交，他们的业务员说会把这4天的钱退给我们，但是一直没退。 第四个坑：退租，乱扣租金退租的时候，房管一副高高在上的样子，好像谁欠他钱似的，查看了房间，检查了家电，押金中扣了我们300元，我去你大爷，住了10个月，给你换了灯管、镇流器、洗衣机水管，还给我们说损坏费用。这300块，100块写在单子上付给公司，另外200块说私下给他转过去，这是拿回扣啊，好好好给你这个死胖子。好了，这押金搞定了，还有房租的事情，因为每次交房租都是交的下个月的，于是我们最后一个月交的是下个月的，应该退我们1个月的房租，但是~一脸横肉的房管，硬生生给我们算成了26天，我跟他算数，他不跟我算数，一直按照他的那套算法来，他妹的，你们还差我4天前没退呢，最后也懒得跟这种人打交道了，就26天了，拿了单子走人了。最后说是押金和租金会在1-2个月内退回，你妹的，你们工作效率这么低吗，要这么长时间。我拿了押金条，快速离开了这个人。这里附上退租押金条： 第五个坑：不退押金，原因是财务正在处理一个月到了确实退了我们租金，但是押金没有退给我们，于是找他们要，第一次，他说提交给财务，第二次去催催财务，第三次去催催财务，这几次，态度极其恶劣，如果不是钱在他手里，我就骂死他，于是又忍气吞声1个月半月过去了，承诺给我们的1-2个月已经超过了半个月，继续联系，我们同一个套间里面的其他朋友也都在催，于是叫我们联系客服，客服电话一直打不通，一次没打通过，于是跟他理论，自己去总部要钱，他说不知道总部位置，我晕死，你一个业务人员不知道总部的位置，还干啥啊，回家种田吧，又联系一次，说是找找总部位置，给我发了一个地址：朝阳区牌坊街8号楼2单元703，好了，我带着沉重的心情去总部要钱，没把握要到钱啊，位置离我2个小时车程。到了，没有公司牌子，很像一个租户的屋，于是敲门，问问，果然是的。于是恼火了，我2个小时到这里，你给我一个错误的地址？打电话过去骂他，我们互相对骂，这几年没骂人了，骂的痛快，你不让我好过，我也不让你好过。无奈啊，找物业问了，也是说没有这个房地产公司。于是找当初带我们看房子的业务员，问他总部位置，说是：朝阳区财满街8号楼2单元703，于是有话2小时去这个地方，这个地方是对的，找到他们领导，说明了情况，登记了紧急退租表，给我们说是8月10号退租。其实这时候心还是有点怀疑他们说的话，但是不信也没什么办法啊，于是回家了，今天一天都在处理这个事情了，上午9点出发，下午4点才到家，等吧。这里附上总部图片：还有房管的电话：15510302000，欢迎去骚扰他，骂他更好。 好了，希望大家记住这几点，并告诉身边的朋友们，多谢了。]]></content>
      <categories>
        <category>个人黑名单</category>
      </categories>
      <tags>
        <tag>租房</tag>
        <tag>骗局</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链应用]]></title>
    <url>%2F2018%2F07%2F25%2F%E5%8C%BA%E5%9D%97%E9%93%BE%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[区块链技术，会颠覆传统互联网信息技术行业，成为下一个风口，你要把握住吗？下面来聊聊区块链在目前各大行业中的一些应用，和目前开发区块链应用用到了平台和技术。 一、分类1.公有链任何人均可参加和退出 联盟链加入和退出需要经过联盟授权 3.私有链权利完全控制在一个组织中 二、开发平台1.以太坊2.Hyperledger：IBM开源3.商用区块链组件：共识层（可插拔） 智能合约层 通讯层 数据抽象层 加密抽象层 身份服务 策略服务 API 互操作、模块化三、Hyperledger应用1.金融服务提升透明度，减少交易时间、降低风险数字贸易链：银行间交易跨境支付：swift组织绿色资产管理平台：IBM与中国合作数字身份：菲律宾银行账户的问题房地产交易：房产属主，解决房产产权鉴定的问题 2.供应链环节真实性，透明度更高，效率更高海鲜供应链追踪：偷猎，食品供应链钻石供应链：防止钻石引起的武装冲突食品安全：每个环节的食品安全 3.医疗患者不同医疗组织、机构之间的病例共享医疗记录：病例共享州际医疗许可：美国各州之间的医疗共享 四、开发语言以太坊：c++、java、python、go、solidityHyperledger：js]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链技术存在的问题]]></title>
    <url>%2F2018%2F07%2F14%2F%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8A%80%E6%9C%AF%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[区块链技术，可以说是可以颠覆传统行业规则的一个革命性技术，去中性化、不可篡改、可回溯等特点，让全球化加速，让世界变得可以信赖，这不就是我们想要的世界吗，但是目前区块链经过了几年的发展，各种乱象横生，需要我们清晰地认识，别走弯路，下面介绍下区块链技术目前所存在的问题，开发者们或者区块链创业者们需要了解的。 1.标准不统一区块链是什么，目前业界还没有一个统一的清晰明确的概念。没有清晰统一的概念界定，又缺少权威的机构对区块链产品进行评定，这极易造成在涉及区块链的项目谈判、实施过程中出现问题，更谈不上区块链的大规模推广和应用。市场上已有的区块链应用也是“鱼龙混杂”，无法有效评价产品质量。区块链亟需建立一套统一的标准规范来界定其内涵和外延，并说明评判的方法，从而引导市场健康发展。然而区块链技术仍在不断创新变化，应用场景也在不断地探索中，过早的标准化会限制区块链技术的创新和行业的发展。因此，为适应目前区块链行业的发展阶段，区块链的标准化工作应从满足用户的角度出发，以测试某个区块链系统对用户需求的匹配度为原则，开展功能和性能测试的“黑盒”标准化，而不是过早地对区块链技术进行规范。 2.衍生市场混乱处于炒作高峰期的区块链技术，不仅受到社会大众的广泛关注，而且存在着被不法分子所利用进行欺诈的情况。目前市场上存在着大量的打着数字货币的旗号，进行传销、诈骗、非法融资，这些数字货币利用门户网站、微博、微信公众号、贴吧等渠道进行宣传和招商活动，进行炒作，而不真正地拿着投资者的钱去研究、开发区块链引用上。 3.安全威胁在大量资本融入到区块链行业中时，区块链技术得到了飞速的发展，同时，安全问题也得到了广泛的关注，近期许多数字货币交易平台出现黑客攻击，盗取用户的数字货币达到百亿元级别，这是交易平台技术上未达到安全的要求。而在区块链财务类系统中，私钥是用户身份的唯一凭证，在有些应用中，需要将用户的私钥跟用户身份进行绑定，这样就需要通过平台来对用户的私钥进行管理，这种情况下，秘钥的管理会存在安全问题，而这个问题，并不能通过区块链系统自身来解决，而是需要区块链系统外部来解决。 4.难以监管区块链技术采用去中心化的理念，摆脱了传统中心化的管理机制所带来的诸多问题，但去中心化也意味着，主体不明确，监管困难，缺少对主体的有效控制，比如在上次的黑客勒索时间，犯罪分子以比特币作为交易赎金，导致其身份极其难以追查。 大概介绍到这里，未完待续，我们一起来见证区块链的崛起，有意见，欢迎mail我，邮箱chenzuoli709@gmail.com.]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka命令行基本操作]]></title>
    <url>%2F2018%2F07%2F14%2Fkafka%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[这里先介绍下kafka的基本知识及应用场景：它是一个分布式、高吞吐量、容错性好的消息队列，基于生产者、消费者模型来实现消息的生产消费，在我们的应用系统中，可以起到数据流缓存、解耦合、高效的作用。下面是kafka命令行的基本操作。 对于kafka集群的安装配置，这里就不讲解了，apache官网有详细配置方案，可参考：apache kafka配置详解注：本次使用操作的基本环境为kafka 1.1.0、centos 7.4 1.后台启动kafka broker1./bin/kafka-server-start.sh -daemon config/server.properties 2.关闭kafka broker：1./bin/kafka-server-stop.sh 3.创建topic：1./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 2 --partitions 2 --topic test 4.创建生产者：1./bin/kafka-console-producer.sh --broker-list hadoop31:9092,hadoop32:9092,hadoop33:9092 --topic test 5.创建消费者：1./bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning 6.查看所有topic：1./bin/kafka-topics.sh --list --zookeeper localhost:2181 7.查看topic状态：1./bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test 8.查看topic消费情况：1./bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list hadoop31:9092,hadoop32:9092,hadoop33:9092 --topic sparktest --time -1 9.删除某个topic：1./bin/kafka-topics.sh --delete --zookeeper hadoop31:2181,hadoop32:2181,hadoop33:2181 --topic sparktest 注意设置配置参数delete.topic.enable=true，然后重启kafka和zookeeper才可以生效； 好了，到这里还没完，后期会持续更新，我会把我工作中使用到的经过测试没问题的kafka知识记录下来分享给大家，如果有什么问题，请大家mail我，希望大家支持。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[比特币原理]]></title>
    <url>%2F2018%2F07%2F05%2F%E6%AF%94%E7%89%B9%E5%B8%81%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[大家好，今天来说说18年很火的比特币，由于现代社会的全球化进程加快，各个国家之间的信息交换，信息共享出现了许许多多的问题，比如你出国旅游，还得更换货币，还得办个护照来证明你是个人，还有就是各个银行或金融机构对货币的监督和管理，一旦这些机构出现问题，那么我们的钱就这样没了，这是不是很亏呢，今天将的区块链技术，就可以解决这个问题，下面来详细讲解它的运行原理和应用场景。 一、去中心化1.如何确认付款方是否有足够的比特币进行支付？去中心化网络，舍去银行等金融机构（他们通过用户账户余额来解决这个问题）的依赖，比特币的解决方案是每笔交易都必须把以前的交易记录作为基础。 2.转账记录的存储和维护2.1如何进行同步，互联网上的计算机交易记录同步；2.2如何防止黑客篡改记录；2.3如何防止同一笔比特币收入被重复使用这个时候就需要用到区块链技术，区块链仅仅维护一个交易链，每个人将自己的转账记录发布到网络上，矿工收集这些转账记录，生成一个区块，世界上有许多矿工，那么到底哪一个矿工生成的区块才能链接到区块链的末尾呢？这时，就出现了一个机制，每个矿工在生成了这个区块后，需要对前一个区块链上前一个区块的sha256函数值+这个新区块的基本信息+这个新区块所包含的所有交易记录+随机数进行sha256函数计算，得到一个hash值前72位均为0，那么找到符合要求的随机数需要进行2的72次方sha256函数运算，计算机大概平均需要10分钟左右算出来，然后发布到区块链网络上，在这10分钟之内，一般只有一个矿工能够计算出符合要求的随机数，所以就避免了多个矿工同时生成区块而无法判断到底将哪一个区块链接到区块链的尾端的问题了。矿工得到符合要求的随机数后，发布到网络上，网络上的其他计算机会进行校验：随机数校验，交易记录校验。一切都没有问题后，就讲该区块添加到自己电脑上区块链的末尾，完成交易记录的同步 二、不可篡改：针对转账交易来进行说明，利用非对称加密算法，达到不可篡改的目的，具体如下,如，小红转账给小白50元，这条记录 1.原始记录进行SHA256加密得到hash值1；2.小红利用她的私钥对hash值1进行加密得到hash值2；3.其他人利用小红的公钥（公钥是公开的），对hash值2进行解密得到hash值3；如果hash值3等于hash值1，那么说明这个签名是针对这条记录的，并且这条记录是小红发出的，接受到的记录与原始记录相同，未被篡改。 三、记录可回溯比特币的每条交易记录都记录在区块链上，当小红转账给小白时，会先计算所有转账给小红的比特币数量，来确认小红有足够的比特币进行交易，所以记录可回溯。 四、比特币问答1.比特币是如何发行的？新比特币作为对矿工的奖励，进入比特币网络进行流通，每生成21万个区块，奖励减半，从第0个区块到第21万个区块，每生成一个区块，奖励给矿工50个比特币，从第21万个区块开始的21万个区块，每生成一个区块，奖励给矿工25个比特币，从第42万个区块开始的21万个区块，每生成一个区块，奖励给矿工12.5个区块，以此类推。从第693个区块开始，对矿工的奖励为0，也就是不再有新的比特币流入比特币网络，到时，累计有2100万个比特币流入到比特币网络，矿工的收入将完全来自于每笔比特币转账交易的交易费，交易费只是比特币在账户之间转移，不是新产生的比特币。也就是说，比特币网络上的比特币总量永远不会超过2100万个。 2.比特币存在什么地方？比特币一般存在比特币客户端软件的数据文件里如果把数据文件弄丢了，比如计算机硬盘坏了，就永远地失去了里面的比特币，而且比特币网络里流通的比特币总量也会减少。 3.比特币转账和支付宝转账有啥区别？比特币不是任何银行和金融机构发行的，使用比特币不需要绑定银行卡，不需要任何身份证明，不需要手机短信认证，只要能上网，只要安装了比特币客户端软件，就可以转账或收款，所有的账户不受任何机构监督和管理，转错了人，没有后悔药，完全没有挽回的余地。在中国大陆，支付宝转账转的一般是人民币，人民币是中国人民银行发行的，人民币的发行量由中国人民银行根据社会发展需要决定。使用支付宝，需要绑定银行卡，转账或收款受支付宝和银行管理。转错了人，可以找支付宝和银行协调，有可能挽回损失。 4.比特币转账的手续费怎么算？比特币软件会给一个推荐值和最低值，但具体多少由付款方自己定。既然手续费自己定，那么付款方将手续费设为最低值会怎么样呢？请看下面这张图片：比特币网络中，支付最少交易费是可以的。但是请注意，当交易量大到超出网络可处理时，矿工会选择手续费更高的交易记录到账本，而您的交易可能永远被搁置，无法确认。 5.比特币所使用的主要技术和特点：5.1利用sha256和非对称加密算法制作签名；5.2利用区块链中的区块存储比特币交易记录；5.3设置额外的工作，从而控制单位时间内生成区块的个数，同时保护比特币网络；5.4将一定数额的比特币和区块内的所有交易费奖励给成功生成该区块的矿工激励更多矿工加入比特币网络，促进比特币网络的茁壮成长；5.5比特币转账不依赖任何银行或其他金融机构；好了，到这里基本上就讲完了，这是我最近从youtube网站上看过很多次讲解的各种比特币、区块链的视频才了解的，国内的资源还很少，天朝也不看好比特币，但是区块链技术是在积极推动的，希望大家看完了总结之后，对比特币的原理有一定的了解，如果有什么不对的地方，请留言指正，或者发送到邮箱chenzuoli709@gmail.com. 附上资源：比特币原理https://www.youtube.com/watch?v=obRzfcvMshM&amp;t=0s&amp;list=LL6p-2jKOMljSPte26mVy3Vw讲解比特币的实现原理区块链开放前景及学习平台https://www.youtube.com/watch?v=8YY8yuKqziw&amp;t=0s&amp;list=LL6p-2jKOMljSPte26mVy3Vw讲解比特币底层区块链技术的开发许知远对话搜狗CEO王小川将区块链https://www.youtube.com/watch?v=pV2DxjxpKu4&amp;t=0s&amp;list=LL6p-2jKOMljSPte26mVy3Vw通俗讲解区块链在货币、商业、政治上的应用现状及前景 五、数字货币投资鄙人还是非常非常看好比特币、区块链技术的，也在火币平台上购买了一些比特币，期待它在以后的日子里带我实现财务自由，想参与的伙伴们，点击链接注册https://www.huobi.br.com/zh-cn/topic/invited/?invite_code=2i9d3确认邀请码：2i9d3]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>bitcoin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018-06-19]]></title>
    <url>%2F2018%2F06%2F19%2FETL%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[大家好，好久没更新了，疲于工作和团队建设，都是一团糟，但是代码还是敲了一些，见我的github/ETL.git项目，写的是基本清洗工具类，点击查看详情。 https://github.com/chenzuoli/ETL.git该项目包括如下内容： ETL数据基本清洗包括以下分类： 1.日期时间；2.数值；3.字符串；4.字符；5.金钱；6.数据库（mysql、postgresql、mongodb、hbase、hdfs、memcached）；7.加解密（md5、sha、base64、aes、rsa）；8.文件；9.http服务；10.正则表达式；11.个人信息：身份证号、手机号、姓名清洗和扩展；后期会不断更新，望大家指正，多谢。]]></content>
      <categories>
        <category>工具类</category>
      </categories>
      <tags>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读取配置文件工具类]]></title>
    <url>%2F2018%2F04%2F03%2F%E8%AF%BB%E5%8F%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[我们在编程过程中，尤其是应用程序，需要经常更改的配置参数或者某些使用较多的固定值，我们可以把它提取出来，放到一个配置文件中，当我们需要修改这个值时，就可以做到不重新发布应用，或者不更改许多的代码，这样，即降低了程序代码的后期维护成本，也降低了程序代码的耦合性，这是我们每个合格的程序员应该具备的基本技能。下面来介绍一个读取配置文件的工具类。 maven项目引入依赖123456&lt;!-- https://mvnrepository.com/artifact/log4j/log4j --&gt;&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt;&lt;/dependency&gt; 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package com.payegis.czl.util;import org.apache.log4j.Logger;import java.io.File;import java.io.InputStreamReader;import java.util.Enumeration;import java.util.HashMap;import java.util.Map;import java.util.Properties;/** * User: chenzuoli * Date: 2018/3/20 * Time: 15:13 * Description: 读取配置文件工具类 * Ps: Properties */public class PropertiesUtils &#123; private static Logger logger = Logger.getLogger(PropertiesUtils.class); private static Properties props; private static String configHome = System.getenv(&quot;pesdk_home&quot;); private static String configFilePath = configHome + File.separator + &quot;conf&quot; + File.separator + &quot;db.properties&quot;; static &#123; readProperties(configFilePath); logger.info(&quot;配置文件加载成功。&quot;); &#125; public static void main(String[] args) &#123; logger.info(get(&quot;psqlPassword&quot;)); &#125; /** * 加载配置文件 * * @param fileName */ private static void readProperties(String fileName) &#123; try &#123; props = new Properties(); InputStreamReader inputStreamReader = new InputStreamReader(new FileInputStream(new File(fileName)), &quot;utf-8&quot;); props.load(inputStreamReader); &#125; catch (Exception e) &#123; logger.error(&quot;加载配置文件失败！&quot;); e.printStackTrace(); &#125; &#125; /** * 根据key读取对应的value * * @param key * @return */ public static String get(String key) &#123; return props.getProperty(key); &#125; /** * 得到所有的配置信息 * * @return */ public static Map&lt;?, ?&gt; getAll() &#123; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); Enumeration&lt;?&gt; enu = props.propertyNames(); while (enu.hasMoreElements()) &#123; String key = (String) enu.nextElement(); String value = props.getProperty(key); map.put(key, value); &#125; return map; &#125; 使用方法首先在本地环境变量中配置一个环境变量，名称为pesdk_home，当然你自己也可以随便定义，然后在该环境变量对应的路径下创建conf文件夹，再在conf文件夹下创建db.properties文件，你的配置项就可以添加到该配置文件中了，使用的时候，直接调用get方法，传入响应的key就可以获得value，赶紧试试吧。 ps如果大家在使用logger打印不出任何东西的时候，可能原因是你没有配置log4j的打印等级，这里就粘贴一下log4j的配置文件吧。这个配置文件的功能是error及fatal级日志打印到一个文件中，info及warn打印到另一个文件中，分日期打印。 123456789101112131415161718192021222324252627# Root logger optionlog4j.rootLogger=INFO, file, stdout # Direct log messages to a log filelog4j.appender.file=org.apache.log4j.RollingFileAppenderlog4j.appender.file.File=DFTSystemWeb2.loglog4j.appender.file.MaxFileSize=10MBlog4j.appender.file.MaxBackupIndex=1log4j.appender.file.layout=org.apache.log4j.PatternLayoutlog4j.appender.file.layout.ConversionPattern=[%d&#123;dd/MM/yy HH:mm:ss:sss z&#125;] %5p %c&#123;1&#125;:%L - %m%n# Direct log messages to stdoutlog4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.Target=System.outlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=[%d&#123;dd/MM/yy HH:mm:ss:sss z&#125;] %5p %c&#123;1&#125;:%L - %m%nlog4j.logger.org.eclipse.jetty=INFOlog4j.logger.org.springframework=INFOlog4j.logger.com.mchange=ERRORlog4j.logger.org.hibernate=INFO#log4j.logger.org.hibernate.type=tracelog4j.logger.com.tulando.common.filter.MethodProfileAspect=info,ProfileAspectlog4j.appender.ProfileAspect=org.apache.log4j.RollingFileAppenderlog4j.appender.ProfileAspect.File=api-profile.loglog4j.appender.ProfileAspect.MaxFileSize=1024KBlog4j.appender.ProfileAspect.MaxBackupIndex=5log4j.appender.ProfileAspect.Append=truelog4j.appender.ProfileAspect.layout=org.apache.log4j.PatternLayoutlog4j.appender.ProfileAspect.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; [%c]-[%p] %m%n 整个方式到这里就配置完成了，如果在使用的过程中，有什么问题，或者有值得优化的地方，请联系我chenzuoli709@gmail.com.]]></content>
      <categories>
        <category>工具类</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作mysql工具类]]></title>
    <url>%2F2018%2F04%2F02%2F%E6%93%8D%E4%BD%9Cmysql%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[下面介绍的是操作mysql的工具类，集成增删改查等功能方法，使用dbcp数据库连接池，让你的程序更高效。具体请看详情。 备注：代码环境jdk8（jdk7也可以） maven项目依赖12345678910111213141516&lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.41&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp2&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;version&gt;2.4.2&lt;/version&gt;&lt;/dependency&gt; 数据库连接配置文件配置文件jdbc.properties放置在项目resources目录下，配置如下： 123456789driverClassName=com.mysql.jdbc.Driverurl=jdbc:mysql://localhost:3306/zs1?useSSL=falseusername=rootpassword=rootinitialSize=10maxIdle=5minIdle=2autoReconnect=trueautoReconnectForPools=true 具体代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270import com.payegis.czl.model.QueryLogHistory;import org.apache.commons.dbcp2.BasicDataSourceFactory;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import javax.sql.DataSource;import java.io.IOException;import java.sql.*;import java.util.*;/** * User: 陈作立 * Date: 2018/2/2 * Time: 13:39 * Description: 操作mysql数据库工具类 * Ps: mysql */public class DBCPUtil &#123; private static Logger loger = LoggerFactory.getLogger(DBCPUtil.class); private static DataSource dataSource = null; static &#123; loger.info(&quot;---------开始初始化数据库连接池---------&quot;); Properties prop = new Properties(); try &#123; prop.load(DBCPUtil.class.getClassLoader().getResourceAsStream(&quot;jdbc.properties&quot;)); dataSource = BasicDataSourceFactory.createDataSource(prop); &#125; catch (IOException e) &#123; loger.error(&quot;---------加载[jdbc.properties]失败---------&quot;, e); &#125; catch (Exception e) &#123; loger.error(&quot;----------初始化数据库连接池异常失败---------&quot;, e); &#125; loger.info(&quot;---------数据库连接池初始化完成---------&quot;); &#125; /** * 获取数据库连接 * * @return */ public static Connection getConnection() &#123; Connection conn = null; if (conn != null) &#123; return conn; &#125; try &#123; conn = dataSource.getConnection(); &#125; catch (SQLException e) &#123; loger.error(&quot;---------数据库连接池获取连接异常---------&quot;, e); &#125; return conn; &#125; /** * 关闭数据库连接 * * @param connection 数据库连接 */ public static void close(Connection connection) &#123; if (connection != null) &#123; try &#123; connection.close(); &#125; catch (SQLException e) &#123; loger.error(&quot;---------关闭Connection异常---------&quot;, e); &#125; &#125; &#125; /** * 关闭数据库连接 * * @param conn 数据库连接 * @param stat 预编译 */ public static void close(Connection conn, Statement stat) &#123; try &#123; if (stat != null) &#123; stat.close(); &#125; &#125; catch (SQLException e) &#123; loger.error(&quot;---------关闭Connection、PreparedStatement异常---------&quot;, e); &#125; finally &#123; close(conn); &#125; &#125; /** * 关闭数据库连接 * * @param conn 数据库连接 * @param stat 预编译 * @param rs 结果集 */ public static void close(Connection conn, Statement stat, ResultSet rs) &#123; try &#123; if (rs != null) &#123; rs.close(); &#125; &#125; catch (SQLException e) &#123; loger.error(&quot;---------关闭ResultSet异常---------&quot;, e); &#125; finally &#123; close(conn, stat); &#125; &#125; /** * 执行查询 * * @param sql * @param params * @return */ public static List&lt;Map&lt;String, Object&gt;&gt; executeQuery(String sql, Object... params) &#123; List&lt;Map&lt;String, Object&gt;&gt; rowDataList = new ArrayList&lt;Map&lt;String, Object&gt;&gt;(); Connection conn = null; PreparedStatement stat = null; ResultSet resultSet = null; try &#123; conn = getConnection(); stat = conn.prepareStatement(sql); stat.setFetchSize(10000); setStatParams(stat, params); resultSet = stat.executeQuery(); rowDataList = getResultList(resultSet); &#125; catch (SQLException e) &#123; loger.error(&quot;---------数据查询异常[&quot; + sql + &quot;]---------&quot;, e); &#125; finally &#123; close(conn, stat, resultSet); &#125; return rowDataList; &#125; /** * 更新数据 * * @param sql sql语句 * @param params 参数 * @return 更新成功:true 更新失败:false */ public static boolean executeUpdate(String sql, Object... params) &#123; boolean isUpdated = false; Connection conn = null; PreparedStatement stat = null; try &#123; conn = getConnection(); conn.setAutoCommit(false); stat = conn.prepareStatement(sql); setStatParams(stat, params); int updatedNum = stat.executeUpdate(); isUpdated = updatedNum == 1; conn.commit(); &#125; catch (SQLException e) &#123; try &#123; conn.rollback(); &#125; catch (SQLException e1) &#123; e1.printStackTrace(); &#125; loger.error(&quot;---------更新失败! sql:[&quot; + sql + &quot;], params:[&quot; + Arrays.toString(params) + &quot;]---------&quot;, e); &#125; finally &#123; close(conn, stat); &#125; return isUpdated; &#125; /** * 执行批处理 * * @param sqlList sql语句集合 * @return */ public static boolean executeBatch(List&lt;String&gt; sqlList) &#123; if (sqlList == null || sqlList.isEmpty()) &#123; return true; &#125; Connection conn = null; Statement stat = null; try &#123; conn = getConnection(); conn.setAutoCommit(false); stat = conn.createStatement(); for (String sql : sqlList) &#123; stat.addBatch(sql); &#125; stat.executeBatch(); conn.commit(); return true; &#125; catch (SQLException e) &#123; try &#123; conn.rollback(); loger.error(&quot;---------批处理异常，执行回滚---------&quot;); &#125; catch (SQLException e1) &#123; loger.error(&quot;---------回滚异常---------&quot;, e1); &#125; loger.error(&quot;---------执行批处理异常---------&quot;); loger.error(&quot;---------批处理异常sql：&quot; + Arrays.toString(sqlList.toArray())); &#125; finally &#123; try &#123; if (conn != null) &#123; conn.setAutoCommit(true); &#125; &#125; catch (SQLException e) &#123; loger.error(&quot;---------设置自动提交异常---------&quot;, e); &#125; close(conn, stat); &#125; return false; &#125; /** * 获取列名及数据 * * @param rs 数据集 * @return */ private static List&lt;Map&lt;String, Object&gt;&gt; getResultList(ResultSet rs) throws SQLException &#123; List&lt;Map&lt;String, Object&gt;&gt; rowDataList = new ArrayList&lt;Map&lt;String, Object&gt;&gt;(); List&lt;String&gt; colNameList = getColumnName(rs); while (rs.next()) &#123; Map&lt;String, Object&gt; rowData = new HashMap&lt;String, Object&gt;(); for (String colName : colNameList) &#123; rowData.put(colName, rs.getObject(colName)); &#125; if (!rowData.isEmpty()) &#123; rowDataList.add(rowData); &#125; &#125; return rowDataList; &#125; /** * 获取列名 * * @param rs 数据集 * @return */ private static List&lt;String&gt; getColumnName(ResultSet rs) throws SQLException &#123; List&lt;String&gt; columnList = new ArrayList&lt;String&gt;(); try &#123; ResultSetMetaData metaData = rs.getMetaData(); int columnCount = metaData.getColumnCount(); for (int i = 1; i &lt;= columnCount; i++) &#123; columnList.add(metaData.getColumnName(i)); &#125; &#125; catch (SQLException e) &#123; loger.info(&quot;------获取表列表异常------&quot;, e); throw e; &#125; return columnList; &#125; /** * 设置参数 * * @param stat 预编译 * @param params 参数 */ private static void setStatParams(PreparedStatement stat, Object... params) throws SQLException &#123; if (stat != null &amp;&amp; params != null) &#123; try &#123; for (int len = params.length, i = 1; i &lt;= len; i++) &#123; stat.setObject(i, params[i - 1]); &#125; &#125; catch (SQLException e) &#123; loger.error(&quot;------设置sql参数异常---------&quot;); throw e; &#125; &#125; &#125;&#125; 好了，到这里就结束了，这个类基本可以满足操作mysql的需求了，大家放心使用吧，如果有什么问题，或者可以优化的地方，欢迎大家email我chenzuoli709@gmail.com]]></content>
      <categories>
        <category>工具类</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>utils</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[身份证号校验工具类IdentityUtil]]></title>
    <url>%2F2018%2F03%2F30%2F%E8%BA%AB%E4%BB%BD%E8%AF%81%E5%8F%B7%E6%A0%A1%E9%AA%8C%E5%B7%A5%E5%85%B7%E7%B1%BBIdentityUtil%2F</url>
    <content type="text"><![CDATA[一个人的身份证号，每个字符都有他独特的含义，前2位代表省、自治区、直辖市代码，3-4位代表地级市、盟、自治州代码，5-6位代表县、县级市、区代码，7-14位代表出生年月日，15-17位代表当天出生的顺序号，奇数代表男，偶数代表女，18位为校验码，由0-9、X组成，这个校验码的由来，是由前17位数字计算得来，具体计算方式，可以参考下述代码。 本代码介绍的是校验身份证的合法性工具类，具体如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128import java.util.Calendar;import java.util.GregorianCalendar;import java.util.HashMap;import java.util.Map;/** * 身份证验证的工具（支持5位或18位省份证） * 身份证号码结构： * 17位数字和1位校验码：6位地址码数字，8位生日数字，3位出生时间顺序号，1位校验码。 * 地址码（前6位）：表示对象常住户口所在县（市、镇、区）的行政区划代码，按GB/T2260的规定执行。 * 出生日期码，（第七位 至十四位）：表示编码对象出生年、月、日，按GB按GB/T7408的规定执行，年、月、日代码之间不用分隔符。 * 顺序码（第十五位至十七位）：表示在同一地址码所标示的区域范围内，对同年、同月、同日出生的人编订的顺序号， * 顺序码的奇数分配给男性，偶数分配给女性。 * 校验码（第十八位数）： * 十七位数字本体码加权求和公式 s = sum(Ai*Wi), i = 0,,16，先对前17位数字的权求和； * Ai:表示第i位置上的身份证号码数字值.Wi:表示第i位置上的加权因.Wi: 7 9 10 5 8 4 2 1 6 3 7 9 10 5 8 4 2； * 计算模 Y = mod(S, 11) * 通过模得到对应的校验码 Y: 0 1 2 3 4 5 6 7 8 9 10 校验码: 1 0 X 9 8 7 6 5 4 3 2 */public class IdentityUtil &#123; final static Map&lt;Integer, String&gt; zoneNum = new HashMap&lt;Integer, String&gt;(); static &#123; zoneNum.put(11, &quot;北京&quot;); zoneNum.put(12, &quot;天津&quot;); zoneNum.put(13, &quot;河北&quot;); zoneNum.put(14, &quot;山西&quot;); zoneNum.put(15, &quot;内蒙古&quot;); zoneNum.put(21, &quot;辽宁&quot;); zoneNum.put(22, &quot;吉林&quot;); zoneNum.put(23, &quot;黑龙江&quot;); zoneNum.put(31, &quot;上海&quot;); zoneNum.put(32, &quot;江苏&quot;); zoneNum.put(33, &quot;浙江&quot;); zoneNum.put(34, &quot;安徽&quot;); zoneNum.put(35, &quot;福建&quot;); zoneNum.put(36, &quot;江西&quot;); zoneNum.put(37, &quot;山东&quot;); zoneNum.put(41, &quot;河南&quot;); zoneNum.put(42, &quot;湖北&quot;); zoneNum.put(43, &quot;湖南&quot;); zoneNum.put(44, &quot;广东&quot;); zoneNum.put(45, &quot;广西&quot;); zoneNum.put(46, &quot;海南&quot;); zoneNum.put(50, &quot;重庆&quot;); zoneNum.put(51, &quot;四川&quot;); zoneNum.put(52, &quot;贵州&quot;); zoneNum.put(53, &quot;云南&quot;); zoneNum.put(54, &quot;西藏&quot;); zoneNum.put(61, &quot;陕西&quot;); zoneNum.put(62, &quot;甘肃&quot;); zoneNum.put(63, &quot;青海&quot;); zoneNum.put(64, &quot;宁夏&quot;); zoneNum.put(65, &quot;新疆&quot;); zoneNum.put(71, &quot;台湾&quot;); zoneNum.put(81, &quot;香港&quot;); zoneNum.put(82, &quot;澳门&quot;); zoneNum.put(91, &quot;外国&quot;); &#125; final static int[] PARITYBIT = &#123;&apos;1&apos;, &apos;0&apos;, &apos;X&apos;, &apos;9&apos;, &apos;8&apos;, &apos;7&apos;, &apos;6&apos;, &apos;5&apos;, &apos;4&apos;, &apos;3&apos;, &apos;2&apos;&#125;; final static int[] POWER_LIST = &#123; 7, 9, 10, 5, 8, 4, 2, 1, 6, 3, 7, 9, 10, 5, 8, 4, 2&#125;; /** * 身份证验证 *@param s 号码内容 *@return 是否有效 null和&quot;&quot; 都是false */ public static boolean checkIDCard(String certNo)&#123; if(certNo == null || (certNo.length() != 15 &amp;&amp; certNo.length() != 18)) return false; final char[] cs = certNo.toUpperCase().toCharArray(); //校验位数 int power = 0; for(int i=0; i&lt;cs.length; i++)&#123; if(i==cs.length-1 &amp;&amp; cs[i] == &apos;X&apos;) break;//最后一位可以 是X或x if(cs[i]&lt;&apos;0&apos; || cs[i]&gt;&apos;9&apos;) return false; if(i &lt; cs.length -1)&#123; power += (cs[i] - &apos;0&apos;) * POWER_LIST[i]; &#125; &#125; //校验区位码 if(!zoneNum.containsKey(Integer.valueOf(certNo.substring(0,2))))&#123; return false; &#125; //校验年份 String year = certNo.length() == 15 ? getIdcardCalendar() + certNo.substring(6,8) :certNo.substring(6, 10); final int iyear = Integer.parseInt(year); if(iyear &lt; 1900 || iyear &gt; Calendar.getInstance().get(Calendar.YEAR)) return false;//1900年的PASS，超过今年的PASS //校验月份 String month = certNo.length() == 15 ? certNo.substring(8, 10) : certNo.substring(10,12); final int imonth = Integer.parseInt(month); if(imonth &lt;1 || imonth &gt;12)&#123; return false; &#125; //校验天数 String day = certNo.length() ==15 ? certNo.substring(10, 12) : certNo.substring(12, 14); final int iday = Integer.parseInt(day); if(iday &lt; 1 || iday &gt; 31) return false; //校验&quot;校验码&quot; if(certNo.length() == 15) return true; return cs[cs.length -1 ] == PARITYBIT[power % 11]; &#125; private static int getIdcardCalendar() &#123; GregorianCalendar curDay = new GregorianCalendar(); int curYear = curDay.get(Calendar.YEAR); int year2bit = Integer.parseInt(String.valueOf(curYear).substring(2)); return year2bit; &#125; public static void main(String[] args) &#123; boolean mark = checkIDCard(&quot;650105195604040056&quot;); System.out.println(mark); &#125;&#125; 到这里就结束了，如有什么问题，请联系chenzuoli709@gmail.com]]></content>
      <categories>
        <category>工具类</category>
      </categories>
      <tags>
        <tag>utils</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java操作hbase工具类]]></title>
    <url>%2F2018%2F03%2F29%2Fjava%E6%93%8D%E4%BD%9Chbase%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[HBase是一个基于HDFS的数据库，拥有高可用、大量数据存储、列式存储等特点，在非结构化数据与半结构化数据存储方面，有很大的优势。我们一般测试时使用hbase shell命令行的方式来操作hbase数据库比较方便，但是在数据逻辑处理比较复杂时，那肯定是用它提供的API来操作更方便啦，下面就来给出一个java版操作hbase的工具类，提供给大家，我自己也一直使用这个类。 备注：本工具类使用的环境：hbase1.4.1 jdk1.8 hadoop3.0 maven项目添加依赖123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;!--hadoop/hbase都要依赖(RPC通信)，注意protobuf-java的版本，hbase1.4.1自带的protobuf-java版本是2.5.0的，所以如果你的程序是跑在服务器上的，需要跟服务器一致，不然会出现NoClsssFoundError--&gt;&lt;!--https://mvnrepository.com/artifact/com.google.protobuf/protobuf-java--&gt;&lt;dependency&gt; &lt;groupId&gt;com.google.protobuf&lt;/groupId&gt; &lt;artifactId&gt;protobuf-java&lt;/artifactId&gt; &lt;version&gt;3.5.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--hbase--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;$&#123;zookeeper.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt; &lt;artifactId&gt;hbase-client&lt;/artifactId&gt; &lt;version&gt;$&#123;hbase.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt; &lt;artifactId&gt;hbase-common&lt;/artifactId&gt; &lt;version&gt;$&#123;hbase.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.hbase/hbase --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt; &lt;artifactId&gt;hbase&lt;/artifactId&gt; &lt;version&gt;1.4.1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.hbase/hbase-spark --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt; &lt;artifactId&gt;hbase-spark&lt;/artifactId&gt; &lt;version&gt;1.2.0-cdh5.14.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.hbase/hbase-server --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt; &lt;artifactId&gt;hbase-server&lt;/artifactId&gt; &lt;version&gt;1.4.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/fastutil/fastutil 这里使用fastutil，对比javautil自带集合类，它的读写性能更优，尤其在大数据的情况下，所以当你写的mr或者spark程序，使用到fastutil，会提升一些性能--&gt;&lt;dependency&gt; &lt;groupId&gt;fastutil&lt;/groupId&gt; &lt;artifactId&gt;fastutil&lt;/artifactId&gt; &lt;version&gt;5.0.5&lt;/version&gt;&lt;/dependency&gt; 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474package com.payegis.czl.util;import it.unimi.dsi.fastutil.objects.ObjectArrayList;import net.sf.json.JSONObject;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.hbase.HBaseConfiguration;import org.apache.hadoop.hbase.HColumnDescriptor;import org.apache.hadoop.hbase.HTableDescriptor;import org.apache.hadoop.hbase.TableName;import org.apache.hadoop.hbase.client.*;import org.apache.hadoop.hbase.filter.*;import org.apache.hadoop.hbase.io.compress.Compression;import org.apache.hadoop.hbase.util.Bytes;import org.apache.log4j.Logger;import java.io.BufferedReader;import java.io.FileInputStream;import java.io.IOException;import java.io.InputStreamReader;import java.util.*;/** * User: chenzuoli * Date: 2018/3/29 * Time: 9:20 * Description: Java操作HBase工具类 * Ps: Java HBase */public class HBaseUtil &#123; public static Configuration conf; public static Connection connection; public static Admin admin; public static Table table; private static Logger logger = Logger.getLogger(HBaseUtil.class); static &#123; try &#123; conf = HBaseConfiguration.create(); conf.set(&quot;hbase.zookeeper.property.clientPort&quot;, &quot;2181&quot;); conf.set(&quot;hbase.zookeeper.quorum&quot;, &quot;dev11,dev13,dev14&quot;); connection = ConnectionFactory.createConnection(conf); admin = connection.getAdmin(); logger.info(&quot;初始化hbase连接成功！&quot;); &#125; catch (IOException e) &#123; logger.error(&quot;初始化hbase连接异常！&quot;); e.printStackTrace(); &#125; catch (Exception e) &#123; logger.error(&quot;初始化hbase连接异常！&quot;); e.printStackTrace(); &#125; &#125; /** * @Description: 建表，如果表存在，那么不创建。如果未指定列族名称，默认定义一个cf1 * @Param: [tableName, familyName] * @return: boolean * @Author: CHEN ZUOLI * @Date: 2018/3/29 * @Time: 9:24 */ public static boolean createTable(String tableName, String familyName) &#123; boolean flag = false; if (familyName == null || familyName.length() == 0) &#123; familyName = &quot;cf1&quot;; &#125; TableName tbl = TableName.valueOf(tableName); Admin admin = null; try &#123; admin = connection.getAdmin(); if (admin.tableExists(tbl)) &#123; logger.info(&quot;Table &quot; + tbl.getNameAsString() + &quot; is already exists!&quot;); return flag; &#125; HTableDescriptor tableDescriptor = new HTableDescriptor(tbl); tableDescriptor.addFamily(new HColumnDescriptor(familyName).setCompressionType(Compression.Algorithm.SNAPPY)); admin.createTable(tableDescriptor); logger.info(&quot;Create table &quot; + tbl.getNameAsString() + &quot; success!&quot;); flag = true; &#125; catch (IOException e) &#123; logger.error(&quot;Create table failed!&quot;); e.printStackTrace(); &#125; catch (Exception e) &#123; logger.error(&quot;Create table failed!&quot;); e.printStackTrace(); &#125; return flag; &#125; /** * @Description: 插入一条数据到hbase * @Param: [connection, tableName, rowkey, columnFamily, key, value] * @return: void * @Author: CHEN ZUOLI * @Date: 2018/3/28 * @Time: 14:06 */ public static void insertOne(String tableName, String rowkey, String columnFamily, String key, String value) &#123; Table table = null; try &#123; table = connection.getTable(TableName.valueOf(tableName)); Put put = new Put(Bytes.toBytes(rowkey)); put.addColumn(Bytes.toBytes(columnFamily), Bytes.toBytes(key), Bytes.toBytes(value)); table.put(put); &#125; catch (IOException e) &#123; logger.error(&quot;insert hbase failed: &quot; + rowkey + &quot;,&quot; + columnFamily + &quot;,&quot; + key + &quot;,&quot; + value); e.printStackTrace(); &#125; catch (Exception e) &#123; logger.error(&quot;insert hbase failed: &quot; + rowkey + &quot;,&quot; + columnFamily + &quot;,&quot; + key + &quot;,&quot; + value); e.printStackTrace(); &#125; finally &#123; closeTableAndResult(table, null); &#125; &#125; /** * @Description: 批量插入数据到hbase * @Param: [filePath, tableName, familyName] * @return: void * @Author: CHEN ZUOLI * @Date: 2018/3/30 * @Time: 13:31 */ public static void insertBatch(String filePath, String tableName, String familyName) &#123; ObjectArrayList&lt;Put&gt; puts = new ObjectArrayList&lt;&gt;(); Table table = null; FileInputStream fis = null; BufferedReader br = null; try &#123; table = connection.getTable(TableName.valueOf(tableName)); fis = new FileInputStream(filePath); br = new BufferedReader(new InputStreamReader(fis)); String line = br.readLine(); while (line != null) &#123; JSONObject lineJsonObject = JSONObject.fromObject(line); String rowkey = MD5Utils.strToMd5_16(UUID.randomUUID().toString()); Set&lt;String&gt; keys = lineJsonObject.keySet(); Put put = new Put(Bytes.toBytes(rowkey)); for (String key : keys) &#123; put.addColumn(Bytes.toBytes(familyName), Bytes.toBytes(key), Bytes.toBytes(lineJsonObject.optString(key))); puts.add(put); &#125; line = br.readLine(); &#125; table.put(puts); &#125; catch (IOException e) &#123; logger.error(&quot;insert batch data to hbase failed!&quot;); e.printStackTrace(); &#125; catch (Exception e) &#123; logger.error(&quot;insert batch data to hbase failed!&quot;); e.printStackTrace(); &#125; finally &#123; try &#123; if (table != null) table.close(); if (fis != null) fis.close(); if (br != null) br.close(); &#125; catch (IOException e) &#123; logger.error(&quot;close table or stream failed!&quot;); e.printStackTrace(); &#125; &#125; &#125; /** * @Description: 批量插入数据到hbase * @Param: [rows, tableName, familyName] * @return: void * @Author: CHEN ZUOLI * @Date: 2018/4/2 * @Time: 10:19 */ public static void insertBatch(List&lt;Map&lt;String, Object&gt;&gt; rows, String tableName, String familyName) &#123; ObjectArrayList&lt;Put&gt; puts = new ObjectArrayList&lt;&gt;(); Table table = null; try &#123; table = connection.getTable(TableName.valueOf(tableName)); for (Map&lt;String, Object&gt; row : rows) &#123; String rowkey = MD5Utils.strToMd5_16(UUID.randomUUID().toString()); Put put = new Put(Bytes.toBytes(rowkey)); for (Map.Entry&lt;String, Object&gt; kv : row.entrySet()) &#123; String key = kv.getKey(); Object value = kv.getValue(); if (value == null) &#123; put.addColumn(Bytes.toBytes(familyName), Bytes.toBytes(key), null); &#125; else &#123; put.addColumn(Bytes.toBytes(familyName), Bytes.toBytes(key), Bytes.toBytes(value.toString())); &#125; &#125; puts.add(put); &#125; table.put(puts); &#125; catch (IOException e) &#123; logger.error(&quot;insert batch data to hbase failed!&quot;); e.printStackTrace(); &#125; catch (Exception e) &#123; logger.error(&quot;insert batch data to hbase failed!&quot;); e.printStackTrace(); &#125; finally &#123; closeTableAndResult(table, null); &#125; &#125; /** * @Description: 删除一张表 * @Param: [tableName] * @return: boolean * @Author: CHEN ZUOLI * @Date: 2018/3/29 * @Time: 9:40 */ public static boolean dropTable(String tableName) &#123; boolean flag = false; try &#123; admin.disableTable(TableName.valueOf(tableName)); admin.deleteTable(TableName.valueOf(tableName)); flag = true; &#125; catch (IOException e) &#123; logger.error(&quot;delete &quot; + tableName + &quot; table failed!&quot;); e.printStackTrace(); &#125; catch (Exception e) &#123; logger.error(&quot;delete &quot; + tableName + &quot; table failed!&quot;); e.printStackTrace(); &#125; return flag; &#125; /** * @Description: 根据rowkey删除一条记录 * @Param: [tablename, rowkey] * @return: boolean * @Author: CHEN ZUOLI * @Date: 2018/3/29 * @Time: 9:40 */ public static boolean deleteOneRowByRowkey(String tablename, String rowkey) &#123; boolean flag = false; try &#123; Delete d = new Delete(rowkey.getBytes()); table.delete(d); logger.info(&quot;delete row &quot; + rowkey + &quot; success!&quot;); flag = true; &#125; catch (IOException e) &#123; logger.error(&quot;delete row &quot; + rowkey + &quot; failed!&quot;); e.printStackTrace(); &#125; catch (Exception e) &#123; logger.error(&quot;delete row &quot; + rowkey + &quot; failed!&quot;); e.printStackTrace(); &#125; return flag; &#125; /** * @Description: 批量删除rowkey * @Param: [tablename, rowkeyList] * @return: boolean * @Author: CHEN ZUOLI * @Date: 2018/3/29 * @Time: 9:47 */ public static boolean deleteBatchRowByRowkey(String tablename, List&lt;String&gt; rowkeyList) &#123; boolean flag = false; ObjectArrayList&lt;Delete&gt; listDelete = new ObjectArrayList&lt;&gt;(); try &#123; for (int i = 0; i &lt; rowkeyList.size(); i++) &#123; Delete delete = new Delete(rowkeyList.get(i).getBytes()); listDelete.add(delete); &#125; table.delete(listDelete); logger.info(&quot;delete row list &quot; + rowkeyList + &quot; success!&quot;); flag = true; &#125; catch (IOException e) &#123; logger.error(&quot;delete row &quot; + rowkeyList + &quot; failed!&quot;); e.printStackTrace(); &#125; catch (Exception e) &#123; logger.error(&quot;delete row &quot; + rowkeyList + &quot; failed!&quot;); e.printStackTrace(); &#125; return flag; &#125; /** * @Description: 查询表中所有数据 * @Param: [tableName] * @return: List&lt;HashMap&lt;String,HashMap&lt;String,String&gt;&gt;&gt; * @Author: CHEN ZUOLI * @Date: 2018/3/29 * @Time: 9:51 */ public static List&lt;HashMap&lt;String, HashMap&lt;String, String&gt;&gt;&gt; queryAll(String tableName) &#123; ObjectArrayList&lt;HashMap&lt;String, HashMap&lt;String, String&gt;&gt;&gt; rowMapList = new ObjectArrayList&lt;&gt;(); // &lt;familyName, &lt;columnName, columnValue&gt;&gt; Table table = null; ResultScanner rs = null; try &#123; table = connection.getTable(TableName.valueOf(tableName));// ResultScanner rs = table.getScanner(new Scan().setMaxVersions()); // 获取所有版本数据 rs = table.getScanner(new Scan()); for (Result r : rs) &#123; rowMapList.add(resolveResult(r)); &#125; &#125; catch (IOException e) &#123; logger.error(&quot;Get all table data failed!&quot;); e.printStackTrace(); &#125; finally &#123; closeTableAndResult(table, rs); &#125; return rowMapList; &#125; /** * @Description: 单条件查询, 根据rowkey查询唯一一条记录 * @Param: [tableName, rowKey] * @return: List&lt;HashMap&lt;String,HashMap&lt;String,String&gt;&gt;&gt; * @Author: CHEN ZUOLI * @Date: 2018/3/29 * @Time: 10:47 */ public static List&lt;HashMap&lt;String, HashMap&lt;String, String&gt;&gt;&gt; queryByCondition(String tableName, String rowKey) &#123; ObjectArrayList&lt;HashMap&lt;String, HashMap&lt;String, String&gt;&gt;&gt; rowMapList = new ObjectArrayList&lt;&gt;(); // &lt;familyName, &lt;columnName, columnValue&gt;&gt; Table table = null; try &#123; Get get = new Get(rowKey.getBytes());// get.setMaxVersions(); // 获取所有版本数据 table = connection.getTable(TableName.valueOf(tableName)); Result r = table.get(get); rowMapList.add(resolveResult(r)); logger.info(&quot;获得到rowkey: &quot; + new String(r.getRow())); &#125; catch (IOException e) &#123; logger.error(&quot;Get table one data failed!&quot;); e.printStackTrace(); &#125; finally &#123; closeTableAndResult(table, null); &#125; return rowMapList; &#125; /** * @Description: 单条件按查询，查询多条记录 * @Param: [tableName] * @return: List&lt;HashMap&lt;String,HashMap&lt;String,String&gt;&gt;&gt; * @Author: CHEN ZUOLI * @Date: 2018/3/29 * @Time: 13:16 */ public static List&lt;HashMap&lt;String, HashMap&lt;String, String&gt;&gt;&gt; queryByCondition(String tableName, String familyName, String columnName, String columnValue) &#123; ObjectArrayList&lt;HashMap&lt;String, HashMap&lt;String, String&gt;&gt;&gt; rowMapList = new ObjectArrayList&lt;&gt;(); // &lt;familyName, &lt;columnName, columnValue&gt;&gt; Table table = null; ResultScanner rs = null; try &#123; table = connection.getTable(TableName.valueOf(tableName)); Filter filter = new SingleColumnValueFilter(Bytes.toBytes(familyName), Bytes.toBytes(columnName), CompareFilter.CompareOp.EQUAL, Bytes.toBytes(columnValue)); // 当列columnName的值为columnValue时进行查询 Scan s = new Scan(); s.setFilter(filter); rs = table.getScanner(s); for (Result r : rs) &#123; rowMapList.add(resolveResult(r)); &#125; &#125; catch (Exception e) &#123; logger.error(&quot;query with one filter failed!&quot;); e.printStackTrace(); &#125; finally &#123; closeTableAndResult(table, rs); &#125; return rowMapList; &#125; /** * @Description: 组合条件查询 * @Param: [tableName] * @return: List&lt;HashMap&lt;String,HashMap&lt;String,String&gt;&gt;&gt; * @Author: CHEN ZUOLI * @Date: 2018/3/29 * @Time: 13:26 */ public static List&lt;HashMap&lt;String, HashMap&lt;String, String&gt;&gt;&gt; queryByCondition(String tableName, String familyName, HashMap&lt;String, String&gt; paramMap) &#123; ObjectArrayList&lt;HashMap&lt;String, HashMap&lt;String, String&gt;&gt;&gt; rowMapList = new ObjectArrayList&lt;&gt;(); // &lt;familyName, &lt;columnName, columnValue&gt;&gt; Table table = null; ResultScanner rs = null; try &#123; table = connection.getTable(TableName.valueOf(tableName)); FilterList filterList = new FilterList(); for (Map.Entry&lt;String, String&gt; entry : paramMap.entrySet()) &#123; Filter filter = new SingleColumnValueFilter(Bytes.toBytes(familyName), Bytes.toBytes(entry.getKey()), CompareFilter.CompareOp.EQUAL, Bytes.toBytes(entry.getValue())); filterList.addFilter(filter); &#125; Scan scan = new Scan(); scan.setFilter(filterList); rs = table.getScanner(scan); for (Result r : rs) &#123; rowMapList.add(resolveResult(r)); &#125; rs.close(); &#125; catch (Exception e) &#123; logger.error(&quot;query with more filter failed!&quot;); e.printStackTrace(); &#125; finally &#123; closeTableAndResult(table, rs); &#125; return rowMapList; &#125; /** * @Description: 查询hbase，匹配rowkey前缀为dianRong的行 * @Param: [tableName] * @return: java.util.List&lt;java.util.HashMap&lt;java.lang.String,java.util.HashMap&lt;java.lang.String,java.lang.String&gt;&gt;&gt; * @Author: CHEN ZUOLI * @Date: 2018/4/3 * @Time: 20:21 */ public static List&lt;HashMap&lt;String, HashMap&lt;String, String&gt;&gt;&gt; rowkeyFuzzyQuery(String tableName)&#123; ObjectArrayList&lt;HashMap&lt;String, HashMap&lt;String, String&gt;&gt;&gt; rowMapList = new ObjectArrayList&lt;&gt;(); Table table = null; ResultScanner rs = null; try &#123; table = connection.getTable(TableName.valueOf(tableName)); Scan scan = new Scan(); Filter filter = new RowFilter(CompareFilter.CompareOp.EQUAL, new RegexStringComparator(&quot;dianRong.*&quot;)); scan.setFilter(filter); rs = table.getScanner(scan); for (Result r : rs) &#123; rowMapList.add(resolveResult(r)); &#125; &#125; catch (Exception e) &#123; logger.error(&quot;query with more filter failed!&quot;); e.printStackTrace(); &#125; finally &#123; closeTableAndResult(table, rs); &#125; return rowMapList; &#125; /** * @Description: 解析查询hbase得到的结果，放入到HashMap中 * @Param: [result] * @return: java.util.HashMap&lt;String,HashMap&lt;String,String&gt;&gt; * @Author: CHEN ZUOLI * @Date: 2018/3/29 * @Time: 13:52 */ public static HashMap&lt;String, HashMap&lt;String, String&gt;&gt; resolveResult(Result result) &#123; HashMap&lt;String, HashMap&lt;String, String&gt;&gt; rowMap = new HashMap&lt;&gt;(); // &lt;familyName, &lt;columnName, columnValue&gt;&gt; HashMap&lt;String, String&gt; kvMap = new HashMap&lt;&gt;(); NavigableMap&lt;byte[], NavigableMap&lt;byte[], NavigableMap&lt;Long, byte[]&gt;&gt;&gt; map = result.getMap(); for (Map.Entry&lt;byte[], NavigableMap&lt;byte[], NavigableMap&lt;Long, byte[]&gt;&gt;&gt; entry : map.entrySet()) &#123; String familyName = new String(entry.getKey()); NavigableMap&lt;byte[], NavigableMap&lt;Long, byte[]&gt;&gt; valueInfoMap = entry.getValue(); for (Map.Entry&lt;byte[], NavigableMap&lt;Long, byte[]&gt;&gt; valueInfo : valueInfoMap.entrySet()) &#123; String key = new String(valueInfo.getKey()); NavigableMap&lt;Long, byte[]&gt; values = valueInfo.getValue(); Map.Entry&lt;Long, byte[]&gt; firstEntry = values.firstEntry(); Long timestampLastest = firstEntry.getKey(); String valueLastest = new String(firstEntry.getValue()); logger.info(&quot;familyName: &quot; + familyName + &quot;, key: &quot; + key + &quot;, value: &quot; + valueLastest + &quot;, timestamp: &quot; + timestampLastest);// for (Map.Entry&lt;Long, byte[]&gt; vals : values.entrySet()) &#123;// Long timestamp = vals.getKey();// String value = new String(vals.getValue());// &#125; kvMap.put(key, valueLastest); rowMap.put(familyName, kvMap); &#125; &#125; return rowMap; &#125; public static void closeTableAndResult(Table table, ResultScanner rs)&#123; try &#123; if (rs != null) rs.close(); if (table != null) table.close(); &#125; catch (IOException e) &#123; logger.error(&quot;close table failed!&quot;); e.printStackTrace(); &#125; &#125;&#125; 好了，文章到这里就结束了，如果大家在使用过程中，遇到什么问题，请联系我chenzuoli709@gmail.com。]]></content>
      <categories>
        <category>HBase</category>
      </categories>
      <tags>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark累加器的使用方法]]></title>
    <url>%2F2018%2F03%2F17%2FAccumulator%20must%20be%20registered%20before%20send%20to%20executor%2F</url>
    <content type="text"><![CDATA[运行spark程序，使用到了累加器Accumulator，目前使用的是spark2.3.0，累加器Accumulator的定义方法变了，具体查看详细内容。 之前spark1.6.0时，累加器的定义及使用方式为： 123456Accumulator&lt;Integer&gt; accum = sc.accumulator(0);sc.parallelize(Arrays.asList(1, 2, 3, 4)).foreach(x -&gt; accum.add(x));// ...// 10/09/29 18:41:08 INFO SparkContext: Tasks finished in 0.317106 saccum.value();// returns 10 在spark2.3.0中，累加器的定义方式应该为： 123456LongAccumulator accum = jsc.sc().longAccumulator();sc.parallelize(Arrays.asList(1, 2, 3, 4)).foreach(x -&gt; accum.add(x));// ...// 10/09/29 18:41:08 INFO SparkContext: Tasks finished in 0.317106 saccum.value();// returns 10 之前的方式已被标记为Deprecated。也可以如此，先定义，在注册到SparkConf： 1234LongAccumulator countDftResult = new LongAccumulator();LongAccumulator countFailed = new LongAccumulator();sc.register(countDftResult); // 注册累加器sc.register(countFailed); 如果不注册，会出现Accumulator must be registered before send to executor异常。到这里就基本可以使用累加器了，谢谢大家，如果有什么问题，请留言。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git服务器端配置详解]]></title>
    <url>%2F2018%2F03%2F10%2FGit%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[我们在公司中，一个项目在开发过程中必定要涉及到同事之间的协同作战，此时代码管理就必不可少了，程序员用的最多的就是git了吧，但是公司的代码是禁止上传到github上的，所以需要自己搭建一个内部的git server服务器供公司内部使用，下面来具体就介绍。 本安装教程适用于centos服务器，其他版本linux服务器步骤一样，运行命令会不相同，自己转换即可。配置git server，原理就是将客户端的公钥id_rsa.pub添加到服务端的密钥文件authorized_keys中，多个用户另起一行拼接到该文件中即可。下面介绍安装的两种方法： 方法一：yum安装安装git软件12yum install git -ygit --version git –version可以查看安装的git版本 12[git@hadoop3 gitrepo]$ git --versiongit version 1.8.3.1 系统是centos7，自带git版本太低，但可以使用。 添加git用户组和用户12groupadd gituseradd git -g git 创建登录证书1234su gitcdmkdir .ssh &amp;&amp; chmod 700 .sshtouch .ssh/authorized_keys &amp;&amp; chmod 600 .ssh/authorized_keys 这里注意，一定要设置authorized_keys文件的权限为600，权限太大或太小都会造成cannot access的问题，我就遇到过这个坑。 免秘钥复制客户端的公钥到服务端的authorized_keys文件中 初始化git仓库创建一个git仓库文件夹，专门存放项目的地方，并创建一个项目，初始化： 12345mkdir /srv/git -pcd /srv/gitmkdir project.gitcd project.gitgit init --bare bare的意思就是初始化一个裸仓库，并不存储用户push的数据，只存储元数据。 提交项目到git server下面的命令是在客户端（另一台机器，可以是windows，也可以是linux）上执行的： 12345678cd myprojectgit initgit config --global user.email “chenzuoli709@163.com”git config --global user.name “chenzuoli”git add .git commit -m “initial commit”git remote add origin git@gitserver:/srv/git/project.gitgit push origin master 注意：提交的时候需要将gitserver更换成自己的git服务器的ip或者映射域名。 克隆项目1git clone git@gitserver:/srv/git/project.git 也是要替换gitserver的。 方法二：自定义安装下载最新稳定版gitgit最新版下载 添加git用户组和用户12groupadd gituseradd git -g git 上传解压1234su gitcd $GIT_HOMExz -d git-2.9.5.tar.xztar xvf git-2.9.5.tar 环境准备1yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel perl-devel gcc -y 预编译、编译、安装123cd git-2.9.5./configure -prefix=$GIT_HOMEmake &amp;&amp; make install 其中GIT_HOME是自己指定的git安装目录。 配置配置跟方法一一样 添加链接上述步骤配置完成后，我们在push clone时会出现如下问题： 12345678bash: git-receive-pack: command not foundfatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists.bash: git-upload-pack: command not foundfatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists. 原因是自定义安装时git的执行文件不在/usr/bin下，添加链接即可： 12345ln -s /usr/local/gitserver/install/bin/git /usr/bin/gitln -s /usr/local/gitserver/install/bin/git-shell /usr/bin/git-shellln -s /usr/local/gitserver/install/bin/git-upload-archive /usr/bin/git-upload-archiveln -s /usr/local/gitserver/install/bin/git-upload-pack /usr/bin/git-upload-packln -s /usr/local/gitserver/install/bin/git-receive-pack /usr/bin/git-receive-pack 到这里配置就基本完成了，谢谢大家，如果有什么问题，请留言。]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ambari管理监控hadoop生态系统的环境安装及问题解答]]></title>
    <url>%2F2018%2F03%2F10%2Fambari%E7%AE%A1%E7%90%86%E7%9B%91%E6%8E%A7hadoop%E7%94%9F%E6%80%81%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E5%8F%8A%E9%97%AE%E9%A2%98%E8%A7%A3%E7%AD%94%2F</url>
    <content type="text"><![CDATA[首先来介绍下ambari，它是一个apache的一个顶级项目，hadoop生态组件的监控、管理工具，相比较于cloudera公司的CDH，它的特点是完全开源，一键部署安装、管理、监控大数据各组件，省时省力，下面就来介绍ambari环境是如何安装的。 本安装教程适用于操作系统centos7，在某一台服务器上安装，原理就是虚拟化该服务器成多个virtual box，然后启动ambari服务，管理这些虚拟机。 安装安装步骤可以参考官网：ambari.apache.org 环境准备1yum install lrzsz openssl openssh-clients git maven -y 下载安装VirtualBox、VagrantVirtualBox选择最新稳定版.rpm文件下载即可上传到服务器使用yum安装 下载ambari-vagrant123git clone https://github.com/u39kun/ambari-vagrant.gitcat ambari-vagrant/append-to-etc-hosts.txt &gt;&gt; /etc/hosts --配置ip、域名映射vagrant --生成密钥 启动VMs1cd ambari-vagrant 你可以看到在该文件夹下有许多centos的版本，官方说centos6.8对ambari的兼容性最好，我们就用centos6.8吧。 123cd centos6.8cp ~/.vagrant.d/insecure_private_key . --将密钥复制到当前文件夹，注意不要少了组后面的一个点，代表当前文件夹./up.sh 3 --启动3个virtual machine 正常的话，就启动了c6801 c6802 c6803这三台虚拟机 登录VMs12vagrant ssh c6801su - ssh没问题的话，说明安装是没问题的，下面来安装ambari-server，以root用户完成下面的操作。 安装ambari-server下载ambari的源，安装并启动ambari-server 1234wget -O /etc/yum.repos.d/ambari.repo http://public-repo-1.hortonworks.com/ambari/centos6/2.x/updates/2.5.1.0/ambari.repoyum install ambari-server -yambari-server setup -sambari-server start 启动成功后，我们可以访问ambari的web界面： http://c6801.ambari.apache.org:8080，初始的登录用户名和密码均为admin，以同样的方式可以访问c6802 c6803，然后我们就可以对着三台虚拟机进行安装hadoop生态的各个组件了。 问题安装过程中会出现各种问题，具体问题及解决方案如下： 启动虚拟盒的时候报错运行命令： 1./up.sh 3 错误日志如下： 1234There was an error while excuting &apos;VBoxMange&apos;, a CLI used by vagrant for controlling VirtualBox, The command and stderr is shown below.Command: [&quot;startvm&quot;, &quot;afb1736b-3bab-4d1a-a968-16aba764195a&quot;, &quot;--type&quot;, &quot;gui&quot;]Stderr: VBoxManage: error: The virtual machine &quot;centos68-c6801-1520048454672_80399&quot; has terminated upexpectedly during startup because of singal 6.VBoxManage: error: Details: code NS_ERROR_FAILURE (0x80004005), componnent MachineWrap, interface IMachine. 错误原因：linux系统中的kernel module与ambari需要使用的kernel模块版本不匹配，导致vboxdrv服务启动异常，可以使用命令查看vboxdrv服务的启动情况： 1systemctl status vboxdrv 解决办法：1.安装更新kernel 1yum install kernel -y 2.安装kernel-devel 1yum install kernel -y 3.重启服务器 1reboot 4.启动vboxdrv服务 12systemctl start vboxdrvsystemctl status vboxdrv --查看状态 到这里配置就基本完成了，谢谢大家，如果有什么问题，请留言。]]></content>
      <categories>
        <category>环境安装</category>
      </categories>
      <tags>
        <tag>ambari</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows下gvim打开文件中文乱码]]></title>
    <url>%2F2018%2F02%2F08%2Fwindows%E4%B8%8Bvim%E6%89%93%E5%BC%80%E6%96%87%E4%BB%B6%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%2F</url>
    <content type="text"><![CDATA[习惯了linux操作命令，突然有需要使用到windows cmd命令，例如安装某些软件时，需要用命令方式去安装： 1npm install hexo-cli 安装完成后，需要编辑一些配置文件，这个时候，去’计算机’中重新定位到该配置文件的位置时，是很不方便的，如果有个类似vim的工具多好，windows自带的文本编辑工具notepad打开后还不能像vim一样操作，很是不适，不过总有神一般的人物开发出好用的工具。windows下有类似linux下的vim工具gvim，但是gvim打开某些文件时，中文乱码，很是让人烦恼，下面就来介绍如何解决乱码的问题。 windows下默认vim打开是gbk格式的，所以中文乱码，需要进行设置vim打开时加载文件时的编码，参照如下设置： 打开gvim客户端 编辑_vimrc配置文件方式一： 方式二：直接编辑文件%VIM_HOME%_vimrc添加如下配置：12set enc=utf8 设置打开文件缓冲区编码set fencs=utf8,gbk,gb2312,gb18030,cp936 设置文件编码 设置后，再次打开ok。如果gvim菜单栏中文乱码编辑配置文件_vimrc，添加如下配置： 12source $VIMRUNTIME/delmenu.vim 设置gvim菜单文件编码source $VIMRUNTIME/menu.vim 设置gvim菜单文件编码]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>gvim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu防火墙操作]]></title>
    <url>%2F2018%2F02%2F07%2Fubuntu%E9%98%B2%E7%81%AB%E5%A2%99%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[使用过了centos的同胞们，听说ubuntu的交互性很不错，可视化界面也很炫酷，果断更换ubuntu系统，但是安装完成之后，感觉都不会使用linux系统了，于是各种google查询操作方法，下面来简单介绍ubuntu防火墙的操作。 使用ubuntu系统，配置防火墙稍微跟centos不太一样，有一样工具，叫做ufw，即uncomplicated firewall简单防火墙，刚开始用的时候不太习惯，记住这两个单词就行。ubuntu系统自带就有这个工具，可能版本的原因，你的ubuntu可能没有，不用担心，没有先来安装。 安装ufw工具1sudo apt install ufw -y 如果报错找不到包： 1234Reading package lists... DoneBuilding dependency tree Reading state information... DoneE: Unable to locate package ufw 更新一下依赖库就行： 1sudo apt-get update 然后继续安装ufw，安装完成后，我们来启动它1sudo ufw enable 此时防火墙就开启了，默认可以访问部分端口，不如22、443，想关闭所有外部ip对本机的端口访问的话，执行命令：1sudo ufw default deny 查看防火墙状态1sudo ufw status 启用或者禁用端口、服务允许外部访问端口12sudo ufw allow 22sudo ufw allow sshd 禁止外部访问端口12sudo ufw delete allow 80sudo ufw delete allow apache2 允许某个ip访问本机所有端口1sudo ufw allow from 192.168.1.1 OK，希望对大家有帮助，我们一起进步，有问题欢迎在下方留言，或者给我发邮件，邮件地址：chenzuoli709@gmail.com。]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c3p0数据库连接池的使用方法]]></title>
    <url>%2F2018%2F02%2F03%2Fc3p0%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[c3p0数据库连接池，一个jdbc连接池，封装了增删改查的各种方法，并为我们自动优化了数据库连接，提高程序的运行效率。 需要添加的依赖： 123456789101112&lt;!-- https://mvnrepository.com/artifact/c3p0/c3p0 --&gt;&lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/com.mchange/c3p0 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.mchange&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.5.2&lt;/version&gt;&lt;/dependency&gt; 项目src/resources下需要配置文件c3p0.properties 1234567891011c3p0.JDBC.url=jdbc:mysql://localhost:3306/ms_cms?characterEncoding=utf8 --jdbc连接urlc3p0.DriverClass=com.mysql.jdbc.Driver --数据库驱动c3p0.user=root --用户名c3p0.pwd=xxx --密码c3p0.acquireIncrement=3 --当连接池中的连接耗尽时，一次性获取的连接数c3p0.idleConnectionTestPeriod=60 --检查连接池中的空闲连接c3p0.initialPoolSize=10 --初始化连接数c3p0.maxIdleTime=60 --最大空闲时间c3p0.maxPoolSize=20 --连接池最大连接数c3p0.maxStatements=100 --最大会话数c3p0.minPoolSize=5 --连接池最小连接数 java代码使用方法： 1234567891011121314151617181920212223242526272829public Connection dd() throws FileNotFoundException, IOException, PropertyVetoException, SQLException&#123; Properties pr = new Properties(); String c3p0Properties = this.getClass().getClassLoader().getResource(&quot;c3p0.properties&quot;).getPath(); //获得src下的c3p0.properties的路径 c3p0Properties = URLDecoder.decode(c3p0Properties, &quot;utf-8&quot;); //路径的编码是UTF-8 java.io.File c3p0File = new java.io.File(c3p0Properties); //得到文件c3p0.properties文件 pr.load(new FileInputStream(c3p0File)); //读取c3p0文件的内容 // pr.save(new FileOutputStream(c3p0File), null); ComboPooledDataSource cpds = new ComboPooledDataSource(); //使用c3p0操作数据库 cpds.setDriverClass(pr.getProperty(&quot;c3p0DriverClass&quot;)); //加载数据驱动 cpds.setJdbcUrl(pr.getProperty(&quot;c3p0.JDBC.url&quot;)); //连接特定的数据库 cpds.setUser(pr.getProperty(&quot;c3p0.user&quot;)); //数据库用户名 cpds.setPassword(pr.getProperty(&quot;c3p0.pwd&quot;)); //数据库用户密码 Connection conn = cpds.getConnection(); //获得连接 return conn; &#125;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>c3p0</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows远程连接linux图形界面配置详解]]></title>
    <url>%2F2017%2F12%2F28%2FWindows%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux%E5%9B%BE%E5%BD%A2%E7%95%8C%E9%9D%A2%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Windows远程连接linux图形界面，利用VNC服务实现windows远程连接linux图形化界面，linux作为VNC Server，windows作为VNC Viewer。原理很简单，在vnc server端生成一个桌面号，在vnc client端去连接该桌面号即可。其中很神奇的地方在于，如果两个人同时连接上一个桌面号的话，一个人可以看到另一个人的操作。 安装步骤 mini版centos安装图形化界面如果已经安装了图形化界面，则此步骤可以省略。 安装X window1yum groupinstall &quot;X Window System&quot; 安装GNOME Desktop1yum groupinstall &quot;GNOME Desktop&quot; 如果是centos7以前的版本，则安装命令为 1yum groupinstall &quot;Desktop&quot; 如果找不到Desktop，那么试试： 1yum grouplist 查看可以安装的group，可能不同的版本group组的名字不同。 启动gnome1startx 切换到图形化界面 linux安装VNC Server安装1yum install vnc-server –y 配置12cp /lib/systemd/system/vncserver@.service /etc/systemd/system/cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service 编辑vim /etc/systemd/system/vncserver@:1.service将更换为root 设置开机自启动1systemctl enable vncserver@:1.service 添加防火墙信任规则12firewall-cmd --permanent --add-service vnc-serverfirewall-cmd –reload 重启服务器reboot启动vnc服务启动方式： 1vncserver :桌面号 注意：中间需留有空格，桌面号用数字表示，表示每个用户占用一个桌面连接。以上命令执行的过程中，因为是第一次执行，需要输入密码，密码被加密/root/.vnc/passwd中；同时在用户主目录下的.vnc子目录中为用户自动建立xstartup配置文件（/root/.vnc/xstartup），在每次启动VND服务时，都会读取该文件中的配置信息。 VNC服务使用的端口号与桌面号的关系 windows安装VNC Viewer安装测试输入ip:桌面号连接 其他修改vnc密码1vncpasswd 关闭vnc服务1vncserver -kill :1 防火墙添加信任12firewall-cmd --permanent --add-service vnc-serverfirewall-cmd --reload]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>windows</tag>
        <tag>vnc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建maven私服nexus]]></title>
    <url>%2F2017%2F12%2F26%2F%E6%90%AD%E5%BB%BAmaven%E7%A7%81%E6%9C%8Dnexus%2F</url>
    <content type="text"><![CDATA[maven私服搭建，目的就是我们在使用maven打包时，如果私服中有相对应的包时，可以直接拉取过来，而不需要去下载，仅仅第一次使用该包时才会下载，这样会减少很多的时间，提高效率。 安装配置nexus下载：nexus下载解压： 1$ tar zxvf nexus-3.6.1-02-unix.tar.gz nexus详解文档参考 修改启动用户1$ vim $NEXUS_HOME/bin/nexus.rc 修改默认端口1$ vim $NEXUS_HOME/ etc/nexus-default.properties 启动1$ ./bin/nexus run 访问浏览器访问8081端口，默认登陆：user: adminpassword: admin123 配置maven-central：maven中央库，默认从https://repo1.maven.org/maven2上拉取jar包；maven-releases：私库发行版jar，初次安装nexus请将Deployment policy设置成Allow redeploy；maven-snapshots：私库快照调试版本jar；maven-public：仓库分组，把上面三个仓库组合起来一起对外提供服务，在本地maven配置settings.xml中使用。 本地maven使用私服nexusmaven默认配置settings.xml1234567891011121314151617181920212223242526272829303132333435363738394041&lt;servers&gt; &lt;server&gt; &lt;id&gt;releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt;&lt;/servers&gt;&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;url&gt;http://123.207.66.156:8081/repository/maven-public/&lt;/url&gt; &lt;/mirror&gt;&lt;/mirrors&gt;&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;Nexus&lt;/id&gt; &lt;url&gt;http://123.207.66.156:8081/repository/maven-public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;/profile&gt;&lt;/profiles&gt;&lt;activeProfiles&gt; &lt;activeProfile&gt;dev&lt;/activeProfile&gt;&lt;/activeProfiles&gt; 修改工程pom.xml123456789101112&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;releases&lt;/id&gt; &lt;name&gt;Releases&lt;/name&gt; &lt;url&gt;http://123.207.66.156:8081/repository/maven-releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;name&gt;Snapshot&lt;/name&gt; &lt;url&gt;http://123.207.66.156:8081/repository/maven-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt;&lt;/distributionManagement&gt; 注意上面的repository的id值一定要跟settings.xml文件中配置的server一致。]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>nexus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spark基于zookeeper的高可用搭建]]></title>
    <url>%2F2017%2F12%2F26%2Fspark%E5%9F%BA%E4%BA%8Ezookeeper%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[spark提供服务时，master的角色非常的重要，它负责任务分发、任务调度，可谓任重道远啊，所以我们要对master做高可用，基于zookeeper的高可用，可以自动实现master挂掉后备用的master启动，堆外提供服务。 节点分布：zookeeper: node1 node2 node3spark: node1 node2 node3 node4 编辑SPARK_HOME/conf/spark-env.sh注释掉HADOOP_CONF_DIR，添加SPARK_DAEMON_JAVA_OPTS，其他配置不变。 1export SPARK_DAEMON_JAVA_OPTS=&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=node1:2181,node2:2181,node3:2181 -Dspark.deploy.zookeeper.dir=/spark20170302&quot; 同步该配置文件spark-env.sh到其他节点scp spark-env.sh root@node2:$SPARK_HOME/confscp spark-env.sh root@node3:$SPARK_HOME/confscp spark-env.sh root@node4:$SPARK_HOME/conf 在node2节点上编辑spark-env.sh，将SPARK_MASTER_HOST修改为node21SPARK_MASTER_HOST=node2 启动spark服务在node1节点上启动spark集群 1$ ./sbin/start-all.sh 启动另一个master在node2节点上只启动master 1$ ./sbin/start-master.sh 访问webUI查看启动情况如果配置正确，启动正常，那么master会有两个（node1， node2），一个为ACTIVE状态，一个为STANDBY状态。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>spark</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019年世界上最好的机场]]></title>
    <url>%2F2017%2F12%2F26%2F2019%E5%B9%B4%E4%B8%96%E7%95%8C%E4%B8%8A%E6%9C%80%E5%A5%BD%E7%9A%84%E6%9C%BA%E5%9C%BA%2F</url>
    <content type="text"><![CDATA[机场的好坏，决定因素：1.要看城市的经济规模，政治、文化聚集度；2.有强大的基地航空公司或者合作关系；3.地理位置；4.政治环境； 如下是综合评价得到的世界机场排名： 1.樟宜（新加坡）2.羽田（东京）3.仁川（首尔）4.哈马德（多哈）5.香港机场（中国）6.中部国际机场（日本）7.慕尼黑机场（德国）8.希思罗机场（伦敦）9.成田（东京）10.苏黎世机场（瑞士）]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>世界机场</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单台服务器安装spark、hadoop服务文档]]></title>
    <url>%2F2017%2F12%2F26%2F%E5%8D%95%E5%8F%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%89%E8%A3%85spark%E3%80%81hadoop%E6%9C%8D%E5%8A%A1%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[spark作为分布式计算引擎，如果内存足够，是需要很少的磁盘空间的，在shuffle可能用到，在reduce阶段一定会用到，它是基于hdfs作为存储介质的，所以在使用spark时，应该搭建一个hdfs。 安装JDK1.8安装并配置环境变量，步骤略。 安装scala2.11.8安装并配置环境变量，步骤略。 hadoop伪分布式搭建关闭防火墙配置本机对本机免秘钥登录ssh-keygen -t rsa -P ‘’ -f ~/.ssh/id_rsassh-copy-id ip其中ip为本机ipSsh ip首次本机ssh本机需要输入密码或者yes，输入即可，第二次或者以后就不需要输入参数了。 下载hadoop-2.7.4.tar.gz包解压修改配置文件HADOOP_HOME/etc/hadoop下Hadoop.env.sh修改JAVA_HOME为jdk路径； Core-site.xmlFs.defaltFS属性修改为namenode的ipHadoop.tmp.dir修改为自定义目录，并创建好该目录 123456789101112&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://192.168.109.235:9000&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/root/chen/hadoop/data/temp&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;fs.trash.interval&lt;/name&gt; &lt;value&gt;1440&lt;/value&gt;&lt;/property&gt; Hdfs-site.xml使用默认值即可 12345678&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt;&lt;/property&gt; Mapred-env.sh修改JAVA_HOME为jdk路径，其他默认。 Mapred-site.xml1234&lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt; yarn-env.sh修改JAVA_HOME为java安装路径 yarn-site.xml123456789101112131415161718yarn.resourcemanager.hostname属性指定为namenode的ip地址。&lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;description&gt;The hostname of the RM.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;192.168.109.235&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt; &lt;value&gt;2048&lt;/value&gt;&lt;/property&gt; 添加slaves文件在HADOOP_HOME/etc/hadoop文件夹下添加slaves文件，指定datanode节点添加localhost即可。 格式化namenode./bin/hdfs namenode –format 启动hdfs./sbin/start-all.sh jps查看节点服务的启动情况如果启动正常，那么应该有NamenodeSecondaryNamenodeResourcemanagerNodemanagerDataNode这5个角色 Web Ui访问：http://ip:50070Spark搭建下载并解压spark-2.1.0-bin-hadoop2.7.tgz修改配置文件cp slaves.template slavescp spark-env.sh.template spark-env.shcp spark-defaults.conf.template spark-defaults.confvi spark-env.sh增加参数 123456789SPARK_MASTER_HOST=修改为ipSPARK_MASTER_PORT=7077SPARK_WORKER_CORES=2SPARK_WORKER_MEMORY=4gSPARK_WORKER_INSTANCES=3HADOOP_CONF_DIR=/chen/hadoop2.7/hadoop-2.7.4/etc/hadoop修改为hadoop配置文件的位置SPARK_DRIVER_MEMORY=1024MJAVA_HOME=/chen/jdk8/jdk1.8.0_144修改为jdk的路径MAVEN_OPTS=&quot;-Xms1024m -Xmx4096m -XX:PermSize=1024m&quot; vi spark-deafults.conf其中需要修改hdfs的ip地址，并创建路径/user/spark/logs 启动spark./sbin/start-all.sh正常启动的话应该有：1个Master3个Worker两个角色Web Ui访问http://ip:8080]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>spark</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux高效编程]]></title>
    <url>%2F2017%2F12%2F25%2Flinux%E9%AB%98%E6%95%88%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[本文将介绍linux命令行经常使用到的一些快捷键、编辑命令，还有强大的vim编辑器，能让你在linux上编程更高效。作为一个程序员，会使用各种快捷键不也是更炫酷的一件事吗？ linux命令行光标移动1234567891011121314151617181920212223ctrl+a --- 把光标移到行首（ahead）ctrl+e --- 把光标移到行尾（end）ctrl+l --- 清除终端（clear）ctrl+u --- 删除当前字符到行首（带有剪切功能）ctrl+k --- 删除当前字符到行尾（带有剪切功能）ctrl+y --- 粘贴ctrl+f --- 向前移动一个字符（forward）ctrl+b --- 向后移动一个字符（back）ctrl+左右箭头 --- 把光标在单词之间左右移动ctrl+w --- 删除光标前面的单词cd ~ --- 进入home目录cd - --- 返回上一目录mkdir -p path/to/filealias cd3=”cd ../../../”rename ‘.java’ ‘.java.bak’ *.java --- 批量备份文件ctrl+r --- 查询历史命令history --- 历史命令执行历史命令方法 --- ！+ 命令序号ctrl+p --- 上一条命令（或者上下箭头） 查找进程12345678910进程 进程号 所占用端口号ps -ef显示所有进程信息，包括命令行，与grep配合使用，查找特定进程显示环境变量ps -aux显示所有进程信息，包括资源占用情况，与grep配合使用netstat -anp显示协议、端口、进程号、进程名称等信息 Vimvim与vi的区别：增加了新特性：语法高亮、可视化操作、多平台支持（windows、mac、terminal） 正常模式：浏览和修改文本内容1234567891011121314151617181920R --- 替换（覆盖）当前光标位置及后面的若干文本J --- 合并当前行及下一行为一行j --- 下k --- 上h --- 左l --- 右H --- 当前屏幕第一行M --- 当前屏幕中间行L --- 当前屏幕最后一行w --- 当前光标移至下一个单词词首b --- 当前光标移至上一个单词词首e --- 下一个单词词尾$ --- 当前光标移至行尾^ --- 当前光标移至行首u --- 撤销ctrl+r --- 恢复上一步被撤销的动作 复制123456yy --- 复制当前行5yy --- 复制当前行和后4行yw --- 当前字符到下一单词的起始位置y$ --- 当前字符到当前行末尾y0/y^ --- 当前字符到当前行行首yngg/ynG --- 复制当前行到文件第n行 粘贴1p 删除1234567dw --- 删除当前光标至单词末尾ndw --- 删除当前光标后的n个字符dd --- 删除当前行d$ --- 删除光标位置至行尾d^ --- 删除光标位置至行首dgg --- 删除首行至当前行dG --- 删除当前行至末行 编辑模式 — 编辑文本从正常模式进入编辑模式 123456a --- 在当前光标位置的右边添加文本A --- 在当前行的末尾位置添加文本i --- 在当前光标位置的左边添加文本I --- 在当前行的开始处添加文本(非空字符的行首)O --- 在当前行的上面新建一行o --- 在当前行的下面新建一行 可视模式：高亮选取文本后的正常模式1234v+hjkl --- 选中文本后y复制d剪切，p粘贴ctrl+v --- 以块为选取单位V --- 以行为选取单位行、块为选取单位的模式可以随意切换 命令行模式：操作文本文件123456w --- 保存wq --- 保存并退出q --- 退出q! --- 不保存退出/ --- 查询，n下一个匹配字符串，N上一个匹配字符串:set number --- 设置行号]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[以Hexo网页制作模板构建Github Pages个人网站]]></title>
    <url>%2F2017%2F12%2F19%2FcreateWebsiteHelp%2F</url>
    <content type="text"><![CDATA[个人网站制作过程，以Hexo为例，为大家讲解如何制作，如果有什么错误的地方，欢迎指正，如果有什么不懂的地方，可以email我：chenzuoli709@gmail.com。具体请看详细内容 —&gt; 1.准备环境Node.jsGit 2.安装Hexo1$ npm install -g hexo-cli 3.创建github pagesGithub官网项目名称为.github.io 4.配置Hexo123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install 初始化完成后，该目录下的文件结构如下： 1234567_config.yml --- 全局配置文件package.jsonscaffolds --- 模板source --- 文件仓库 _drafts --- 草稿 _posts --- 发布过的文件themes --- 主题 编辑_config.yml：指定项目部署的方式为git，上传到远程仓库repo的master分支上 1234deploy: type: git repo: https://github.com/chenzuoli/chenzuoli.github.io.git branch: master 5.部署12hexo generate --- 生成hexo deploy --- 部署到github 6.域名映射第一步：登录你购买域名服务商提供给你的域名管理中心，我购买的是腾讯云，域名为chenzuoli.com，首先绑定主域名映射到github.com所对应的ip地址，绑定完成后，隔几分钟测试，因为DNS解析先从你的域名提供商开始，然后到其他的域名提供商，再到国外： 1ping chenzuoli.com 看是否能够ping通，如果ping通，说明域名映射已经ok了第二步：登录github到.github.io项目，进入settings选项，设置自定义域名chenzuoli.com，save后，可以看到在该项目下会自动生成一个CNAME的文件，文件内容就是你设置的域名chenzuoli.com。稍等几分钟，就可以访问chenzuoli.com了。这里说明一下域名映射的流程：chenzuoli.com -&gt; github.com -&gt; chenzuoli.github.iochenzuoli.com映射到github.com，然后github.com会解析该请求寻找CNAME为chenzuoli.com的项目，然后就找到了chenzuoli.github.io，于是就可以访问了。大家赶紧试试吧。]]></content>
      <tags>
        <tag>hexo</tag>
        <tag>github pages</tag>
        <tag>blog</tag>
      </tags>
  </entry>
</search>
