<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[一致性共识算法PBFT简介]]></title>
    <url>%2F2019%2F10%2F07%2F%E4%B8%80%E8%87%B4%E6%80%A7%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95PBFT%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PBFT是Practical Byzantine Fault Tolerance的缩写，即：实用拜占庭容错算法。主要用于联盟链，下面来看下介绍吧。 摘要&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PBFT是Practical Byzantine Fault Tolerance的缩写，即：实用拜占庭容错算法。该算法是Miguel Castro（卡斯特罗）和Barbara Liskov（利斯科夫）在1999年提出来的，解决了原始拜占庭容错算法效率不高的问题，算法的时间复杂度是O(n^2)，使得在实际系统应用中可以解决拜占庭容错问题。该论文发表在1999年的操作系统设计与实现国际会议上（OSDI99）。其中Barbara Liskov就是提出了著名的里氏替换原则（LSP）的人，2008年图灵奖得主。以下拜占庭容错问题简称BFT。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;BFT是区块链共识算法中，需要解决的一个核心问题，以比特币和以太访为代表的POW，EOS为代表的DPOS，以及今后以太访逐渐替换的共识算法POS，这些都是公链算法，解决的是共识节点众多情况下的BFT。而PBFT是在联盟链共识节点较少的情况下BFT的一种解决方案。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;网上已经有很多关于PBFT算法的描述，但是写的都不是很明白，本文以一种更为清晰易懂的方法，彻底讲明白PBFT算法原理。下一篇文章将会结合fabric-0.6.0-preview 中的代码，讲解超级账本项目是如何实现PBFT算法的。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本文假设读者已经理解什么是BFT问题。 PBFT算法流程&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PBFT算法前提，采用密码学算法保证节点之间的消息传送是不可篡改的。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PBFT容忍无效或者恶意节点数：f，为了保障整个系统可以正常运转，需要有2f+1个正常节点，系统的总节点数为：|R| = 3f + 1。也就是说，PBFT算法可以容忍小于1/3个无效或者恶意节点，该部分的原理证明请参考PBFT论文，下文有链接地址。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PBFT是一种状态机副本复制算法，所有的副本在一个视图（view）轮换的过程中操作，主节点通过视图编号以及节点数集合来确定，即：主节点 p = v mod |R|。v：视图编号，|R|节点个数，p：主节点编号。 PBFT算法主体实现流程图如下： PBFT算法流程 以下详细说明，每个主体流程内容： REQUEST： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;客户端c向主节点p发送&lt;REQUEST, o, t, c&gt;请求。o: 请求的具体操作，t: 请求时客户端追加的时间戳，c：客户端标识。REQUEST: 包含消息内容m，以及消息摘要d(m)。客户端对请求进行签名。 PRE-PREPARE： 主节点收到客户端的请求，需要进行以下交验： a. 客户端请求消息签名是否正确。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;非法请求丢弃。正确请求，分配一个编号n，编号n主要用于对客户端的请求进行排序。然后广播一条&lt;&lt;PRE-PREPARE, v, n, d&gt;, m&gt;消息给其他副本节点。v：视图编号，d客户端消息摘要，m消息内容。&lt;PRE-PREPARE, v, n, d&gt;进行主节点签名。n是要在某一个范围区间内的[h, H]，具体原因参见垃圾回收章节。 PREPARE： 副本节点i收到主节点的PRE-PREPARE消息，需要进行以下交验： a. 主节点PRE-PREPARE消息签名是否正确。 b. 当前副本节点是否已经收到了一条在同一v下并且编号也是n，但是签名不同的PRE-PREPARE信息。 c. d与m的摘要是否一致。 d. n是否在区间[h, H]内。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;非法请求丢弃。正确请求，副本节点i向其他节点包括主节点发送一条&lt;PREPARE, v, n, d, i&gt;消息, v, n, d, m与上述PRE-PREPARE消息内容相同，i是当前副本节点编号。&lt;PREPARE, v, n, d, i&gt;进行副本节点i的签名。记录PRE-PREPARE和PREPARE消息到log中，用于View Change过程中恢复未完成的请求操作。 COMMIT： 主节点和副本节点收到PREPARE消息，需要进行以下交验： a. 副本节点PREPARE消息签名是否正确。 b. 当前副本节点是否已经收到了同一视图v下的n。 c. n是否在区间[h, H]内。 d. d是否和当前已收到PRE-PPREPARE中的d相同 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;非法请求丢弃。如果副本节点i收到了2f+1个验证通过的PREPARE消息，则向其他节点包括主节点发送一条&lt;COMMIT, v, n, d, i&gt;消息，v, n, d, i与上述PREPARE消息内容相同。&lt;COMMIT, v, n, d, i&gt;进行副本节点i的签名。记录COMMIT消息到日志中，用于View Change过程中恢复未完成的请求操作。记录其他副本节点发送的PREPARE消息到log中。 REPLY： 主节点和副本节点收到COMMIT消息，需要进行以下交验： a. 副本节点COMMIT消息签名是否正确。 b. 当前副本节点是否已经收到了同一视图v下的n。 c. d与m的摘要是否一致。 d. n是否在区间[h, H]内。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;非法请求丢弃。如果副本节点i收到了2f+1个验证通过的COMMIT消息，说明当前网络中的大部分节点已经达成共识，运行客户端的请求操作o，并返回&lt;REPLY, v, t, c, i, r&gt;给客户端，r：是请求操作结果，客户端如果收到f+1个相同的REPLY消息，说明客户端发起的请求已经达成全网共识，否则客户端需要判断是否重新发送请求给主节点。记录其他副本节点发送的COMMIT消息到log中。 总结&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PBFT算法由于每个副本节点都需要和其他节点进行P2P的共识同步，因此随着节点的增多，性能会下降的很快，但是在较少节点的情况下可以有不错的性能，并且分叉的几率很低。PBFT主要用于联盟链，但是如果能够结合类似DPOS这样的节点代表选举规则的话也可以应用于公链，并且可以在一个不可信的网络里解决拜占庭容错问题，TPS应该是远大于POW的。 参考拜占庭容错(Byzantine Fault Tolerance) WIKI: BFT-Wikipedia PBFT论文地址：PBFT论文 The shortest answer is doing.]]></content>
      <categories>
        <category>共识算法</category>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>共识算法</tag>
        <tag>PBFT</tag>
        <tag>区块链</tag>
        <tag>联盟链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[国庆假期回家之旅]]></title>
    <url>%2F2019%2F10%2F07%2F%E5%9B%BD%E5%BA%86%E5%81%87%E6%9C%9F%E5%9B%9E%E5%AE%B6%E4%B9%8B%E6%97%85%2F</url>
    <content type="text"><![CDATA[今年国庆回家了，以往都是出去浪了。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;去年带着爸妈弟弟去重庆了，享受了一家人的旅行时光，很不错，今年他们不去，也恰好我被辞了。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;带着一个电脑，一本技术类的书籍，一点都没碰。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第一天回家，跟堂哥堂姐表弟一起玩去了，中午表弟家团聚吃饭，晚饭我家一起吃饭，第二天中午堂哥家吃饭，时间过得很快，他们下午就回武汉了，为了赚钱。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第三天又去另一个表哥家过客了，喜得千金，很多人，很热闹，欢乐过后就在他家睡觉了，等待第二天的朋友相聚。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第四天，顺利与朋友寒暄，畅聊了3个小时，他妈弄了一大盘饺子吃，自己家手包的饺子就是非常地美味，so decilious. 但是天一直下雨☔️，变得很冷，无法回我老家，无法去我姥姥家，人算不如天算，计划被打乱，于是又回到表哥家过了一夜，期待明天天晴。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第五天果然天晴，一大早吃完早餐，与舅舅舅妈告别，急急忙忙骑着摩托车回家，天太冷，受罪了，冻得哆嗦。路上带着妈去姥姥家，天下着小雨，雾很大，幸亏有妈的指引，不然会迷路。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;姥姥85岁，身体好了点，比去年强多了，Thank God，愿亲人身体健康。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;急急忙忙吃完午饭，就赶忙与姥姥姥爷告别要赶高铁了，一路小雨微风，我上车了。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;回家的这几天，表哥喜得千金，过得很幸福；堂哥开车回家；堂姐带了男朋友回家；表弟辞职了，准备区深圳闯一闯；我呢还是他们以为的那个样子，很不错。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是也看到了亲人背后的无奈与压力，堂哥公司垮掉了，被迫要学习一些新的技能赚钱了。堂姐离婚后，为了赚钱，与她儿子分开，离开时候的不舍，估计只有她最懂。表弟的工作不赚钱，辞职了，为了能够与女朋友结婚，决定去深圳看看机会。表哥喜得千金，过客后又去工地跟着舅舅赚钱去了，工地很是辛苦，他们最懂。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我好像也好不到哪儿去，过完假要去找工作了。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10月7日早上到达北京，开始学习了。 All I know is that I should do my all effort to make my and my family’s life best.]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>工作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式一致性共识算法Paxos、Raft、ZAB、ETCD之间的关系]]></title>
    <url>%2F2019%2F10%2F01%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95Paxos%E3%80%81Raft%E3%80%81ZAB%E3%80%81ETCD%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在分布式系统中，多个节点之间达成共识成为最重要的组成部分，在发展过程中，出现许多类型的算法，他们从最基本的达成共识，到易于理解，更接近于实践应用等等方面，做到了极致，下面来看看Paxos、Raft、ZAB、Etcd之间的不同。 为了解决分布式系统中的一致性问题，科学家们首先提出了Paxos算法，但是Paxos流程太过繁杂，不易于理解，应用主要有Chubby、libpaxos； 斯坦福大学的2个人以易于理解为目标，又能实现Paxos所解决的问题，于是实现了Raft算法，到现在已经有了十多种语言的Raft算法实现框架，较为出名的有etcd，Google的Kubernetes也是用了etcd作为他的服务发现框架； Zab与Paxos不同，但是有些地方是从Paxos那里学习过来的，比如Leader发送心跳、议案、决定等给Follower；Leader在提交（commit）议案之前需要经过一定量的Follower的确认；算法实现最经典的应用为zookeeper； 但Etcd和Zab不适合分布式大数据存储，主要做分布式元数据的存储； when your ability don’t support your ambition, then you should learn down-to-earth.]]></content>
      <categories>
        <category>区块链</category>
        <category>共识算法</category>
      </categories>
      <tags>
        <tag>共识算法</tag>
        <tag>分布式</tag>
        <tag>Paxos</tag>
        <tag>Raft</tag>
        <tag>Zab</tag>
        <tag>Etcd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一致性共识算法ETCD解析]]></title>
    <url>%2F2019%2F10%2F01%2F%E4%B8%80%E8%87%B4%E6%80%A7%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95ETCD%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;前一段时间的项目里用到了 Etcd， 所以研究了一下它的源码以及实现。网上关于 Etcd 的使用介绍的文章不少，但分析具体架构实现的文章不多，同时 Etcd v3的文档也非常稀缺。本文通过分析 Etcd 的架构与实现，了解其优缺点以及瓶颈点，一方面可以学习分布式系统的架构，另外一方面也可以保证在业务中正确使用 Etcd，知其然同时知其所以然，避免误用。最后介绍 Etcd 周边的工具和一些使用注意事项。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;阅读对象：分布式系统爱好者，正在或者打算在项目中使用Etcd的开发人员。 Etcd 按照官方介绍1Etcd is a distributed, consistent key-value store for shared configuration and service discovery &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;是一个分布式的，一致的 key-value 存储，主要用途是共享配置和服务发现。Etcd 已经在很多分布式系统中得到广泛的使用，本文的架构与实现部分主要解答以下问题： Etcd是如何实现一致性的？ Etcd的存储是如何实现的？ Etcd的watch机制是如何实现的？ Etcd的key过期机制是如何实现的？ 为什么需要 Etcd ？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所有的分布式系统，都面临的一个问题是多个节点之间的数据共享问题，这个和团队协作的道理是一样的，成员可以分头干活，但总是需要共享一些必须的信息，比如谁是 leader， 都有哪些成员，依赖任务之间的顺序协调等。所以分布式系统要么自己实现一个可靠的共享存储来同步信息（比如 Elasticsearch ），要么依赖一个可靠的共享存储服务，而 Etcd 就是这样一个服务。 Etcd 提供什么能力？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Etcd 主要提供以下能力，已经熟悉 Etcd 的读者可以略过本段。 提供存储以及获取数据的接口，它通过协议保证 Etcd 集群中的多个节点数据的强一致性。用于存储元信息以及共享配置。 提供监听机制，客户端可以监听某个key或者某些key的变更（v2和v3的机制不同，参看后面文章）。用于监听和推送变更。 提供key的过期以及续约机制，客户端通过定时刷新来实现续约（v2和v3的实现机制也不一样）。用于集群监控以及服务注册发现。 提供原子的CAS（Compare-and-Swap）和 CAD（Compare-and-Delete）支持（v2通过接口参数实现，v3通过批量事务实现）。用于分布式锁以及leader选举。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;更详细的使用场景不在这里描述，有兴趣的可以参看文末infoq的一篇文章。 Etcd 如何实现一致性的？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;说到这个就不得不说起raft协议。但这篇文章不是专门分析raft的，篇幅所限，不能详细分析，有兴趣的建议看文末原始论文地址以及raft协议的一个动画。便于看后面的文章，我这里简单做个总结： raft通过对不同的场景（选主，日志复制）设计不同的机制，虽然降低了通用性（相对paxos），但同时也降低了复杂度，便于理解和实现。 raft内置的选主协议是给自己用的，用于选出主节点，理解raft的选主机制的关键在于理解raft的时钟周期以及超时机制。 理解 Etcd 的数据同步的关键在于理解raft的日志同步机制。 Etcd 实现raft的时候，充分利用了go语言CSP并发模型和chan的魔法，想更进行一步了解的可以去看源码，这里只简单分析下它的wal日志。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;wal日志是二进制的，解析出来后是以上数据结构LogEntry。其中第一个字段type，只有两种，一种是0表示Normal，1表示ConfChange（ConfChange表示 Etcd 本身的配置变更同步，比如有新的节点加入等）。第二个字段是term，每个term代表一个主节点的任期，每次主节点变更term就会变化。第三个字段是index，这个序号是严格有序递增的，代表变更序号。第四个字段是二进制的data，将raft request对象的pb结构整个保存下。Etcd 源码下有个tools/etcd-dump-logs，可以将wal日志dump成文本查看，可以协助分析raft协议。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;raft协议本身不关心应用数据，也就是data中的部分，一致性都通过同步wal日志来实现，每个节点将从主节点收到的data apply到本地的存储，raft只关心日志的同步状态，如果本地存储实现的有bug，比如没有正确的将data apply到本地，也可能会导致数据不一致。 Etcd v2 与 v3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Etcd v2 和 v3 本质上是共享同一套 raft 协议代码的两个独立的应用，接口不一样，存储不一样，数据互相隔离。也就是说如果从 Etcd v2 升级到 Etcd v3，原来v2 的数据还是只能用 v2 的接口访问，v3 的接口创建的数据也只能访问通过 v3 的接口访问。所以我们按照 v2 和 v3 分别分析。 Etcd v2 存储，Watch以及过期机制 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Etcd v2 是个纯内存的实现，并未实时将数据写入到磁盘，持久化机制很简单，就是将store整合序列化成json写入文件。数据在内存中是一个简单的树结构。比如以下数据存储到 Etcd 中的结构就如图所示。 12/nodes/1/name node1 /nodes/1/ip 192.168.1.1 store中有一个全局的currentIndex，每次变更，index会加1.然后每个event都会关联到currentIndex. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当客户端调用watch接口（参数中增加 wait参数）时，如果请求参数中有waitIndex，并且waitIndex 小于 currentIndex，则从 EventHistroy 表中查询index小于等于waitIndex，并且和watch key 匹配的 event，如果有数据，则直接返回。如果历史表中没有或者请求没有带 waitIndex，则放入WatchHub中，每个key会关联一个watcher列表。 当有变更操作时，变更生成的event会放入EventHistroy表中，同时通知和该key相关的watcher。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里有几个影响使用的细节问题： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;EventHistroy 是有长度限制的，最长1000。也就是说，如果你的客户端停了许久，然后重新watch的时候，可能和该waitIndex相关的event已经被淘汰了，这种情况下会丢失变更。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果通知watch的时候，出现了阻塞（每个watch的channel有100个缓冲空间），Etcd 会直接把watcher删除，也就是会导致wait请求的连接中断，客户端需要重新连接。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Etcd store的每个node中都保存了过期时间，通过定时机制进行清理。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从而可以看出，Etcd v2 的一些限制： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;过期时间只能设置到每个key上，如果多个key要保证生命周期一致则比较困难。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;watch只能watch某一个key以及其子节点（通过参数 recursive),不能进行多个watch。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;很难通过watch机制来实现完整的数据同步（有丢失变更的风险），所以当前的大多数使用方式是通过watch得知变更，然后通过get重新获取数据，并不完全依赖于watch的变更event。 Etcd v3 存储，Watch以及过期机制 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Etcd v3 将watch和store拆开实现，我们先分析下store的实现。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Etcd v3 store 分为两部分，一部分是内存中的索引，kvindex，是基于google开源的一个golang的btree实现的，另外一部分是后端存储。按照它的设计，backend可以对接多种存储，当前使用的boltdb。boltdb是一个单机的支持事务的kv存储，Etcd 的事务是基于boltdb的事务实现的。Etcd 在boltdb中存储的key是reversion，value是 Etcd 自己的key-value组合，也就是说 Etcd 会在boltdb中把每个版本都保存下，从而实现了多版本机制。 举个例子： 用etcdctl通过批量接口写入两条记录： 12345etcdctl txn &lt;&lt;&lt;&apos; put key1 &quot;v1&quot; put key2 &quot;v2&quot; &apos; 再通过批量接口更新这两条记录： 12345etcdctl txn &lt;&lt;&lt;&apos; put key1 &quot;v12&quot; put key2 &quot;v22&quot; &apos; boltdb中其实有了4条数据： 1234rev=&#123;3 0&#125;, key=key1, value=&quot;v1&quot; rev=&#123;3 1&#125;, key=key2, value=&quot;v2&quot; rev=&#123;4 0&#125;, key=key1, value=&quot;v12&quot; rev=&#123;4 1&#125;, key=key2, value=&quot;v22&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;reversion主要由两部分组成，第一部分main rev，每次事务进行加一，第二部分sub rev，同一个事务中的每次操作加一。如上示例，第一次操作的main rev是3，第二次是4。当然这种机制大家想到的第一个问题就是空间问题，所以 Etcd 提供了命令和设置选项来控制compact，同时支持put操作的参数来精确控制某个key的历史版本数。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;了解了 Etcd 的磁盘存储，可以看出如果要从boltdb中查询数据，必须通过reversion，但客户端都是通过key来查询value，所以 Etcd 的内存kvindex保存的就是key和reversion之前的映射关系，用来加速查询。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;然后我们再分析下watch机制的实现。Etcd v3 的watch机制支持watch某个固定的key，也支持watch一个范围（可以用于模拟目录的结构的watch），所以 watchGroup 包含两种watcher，一种是 key watchers，数据结构是每个key对应一组watcher，另外一种是 range watchers, 数据结构是一个 IntervalTree（不熟悉的参看文文末链接），方便通过区间查找到对应的watcher。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;同时，每个 WatchableStore 包含两种 watcherGroup，一种是synced，一种是unsynced，前者表示该group的watcher数据都已经同步完毕，在等待新的变更，后者表示该group的watcher数据同步落后于当前最新变更，还在追赶。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当 Etcd 收到客户端的watch请求，如果请求携带了revision参数，则比较请求的revision和store当前的revision，如果大于当前revision，则放入synced组中，否则放入unsynced组。同时 Etcd 会启动一个后台的goroutine持续同步unsynced的watcher，然后将其迁移到synced组。也就是这种机制下，Etcd v3 支持从任意版本开始watch，没有v2的1000条历史event表限制的问题（当然这是指没有compact的情况下）。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;另外我们前面提到的，Etcd v2在通知客户端时，如果网络不好或者客户端读取比较慢，发生了阻塞，则会直接关闭当前连接，客户端需要重新发起请求。Etcd v3为了解决这个问题，专门维护了一个推送时阻塞的watcher队列，在另外的goroutine里进行重试。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Etcd v3 对过期机制也做了改进，过期时间设置在lease上，然后key和lease关联。这样可以实现多个key关联同一个lease id，方便设置统一的过期时间，以及实现批量续约。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;相比Etcd v2, Etcd v3的一些主要变化： 接口通过grpc提供rpc接口，放弃了v2的http接口。优势是长连接效率提升明显，缺点是使用不如以前方便，尤其对不方便维护长连接的场景。 废弃了原来的目录结构，变成了纯粹的kv，用户可以通过前缀匹配模式模拟目录。 内存中不再保存value，同样的内存可以支持存储更多的key。 watch机制更稳定，基本上可以通过watch机制实现数据的完全同步。 提供了批量操作以及事务机制，用户可以通过批量事务请求来实现Etcd v2的CAS机制（批量事务支持if条件判断）。 Etcd，Zookeeper，Consul 比较&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这三个产品是经常被人拿来做选型比较的。 Etcd 和 Zookeeper 提供的能力非常相似，都是通用的一致性元信息存储，都提供watch机制用于变更通知和分发，也都被分布式系统用来作为共享信息存储，在软件生态中所处的位置也几乎是一样的，可以互相替代的。二者除了实现细节，语言，一致性协议上的区别，最大的区别在周边生态圈。Zookeeper 是apache下的，用java写的，提供rpc接口，最早从hadoop项目中孵化出来，在分布式系统中得到广泛使用（hadoop, solr, kafka, mesos 等）。Etcd 是coreos公司旗下的开源产品，比较新，以其简单好用的rest接口以及活跃的社区俘获了一批用户，在新的一些集群中得到使用（比如kubernetes）。虽然v3为了性能也改成二进制rpc接口了，但其易用性上比 Zookeeper 还是好一些。 而 Consul 的目标则更为具体一些，Etcd 和 Zookeeper 提供的是分布式一致性存储能力，具体的业务场景需要用户自己实现，比如服务发现，比如配置变更。而Consul 则以服务发现和配置变更为主要目标，同时附带了kv存储。 在软件生态中，越抽象的组件适用范围越广，但同时对具体业务场景需求的满足上肯定有不足之处。 Etcd 的周边工具Confd&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在分布式系统中，理想情况下是应用程序直接和 Etcd 这样的服务发现/配置中心交互，通过监听 Etcd 进行服务发现以及配置变更。但我们还有许多历史遗留的程序，服务发现以及配置大多都是通过变更配置文件进行的。Etcd 自己的定位是通用的kv存储，所以并没有像 Consul 那样提供实现配置变更的机制和工具，而 Confd 就是用来实现这个目标的工具。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Confd 通过watch机制监听 Etcd 的变更，然后将数据同步到自己的一个本地存储。用户可以通过配置定义自己关注那些key的变更，同时提供一个配置文件模板。Confd 一旦发现数据变更就使用最新数据渲染模板生成配置文件，如果新旧配置文件有变化，则进行替换，同时触发用户提供的reload脚本，让应用程序重新加载配置。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Confd 相当于实现了部分 Consul 的agent以及consul-template的功能，作者是kubernetes的Kelsey Hightower，但大神貌似很忙，没太多时间关注这个项目了，很久没有发布版本，我们着急用，所以fork了一份自己更新维护，主要增加了一些新的模板函数以及对metad后端的支持。confd Metad&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;服务注册的实现模式一般分为两种，一种是调度系统代为注册，一种是应用程序自己注册。调度系统代为注册的情况下，应用程序启动后需要有一种机制让应用程序知道『我是谁』，然后发现自己所在的集群以及自己的配置。Metad 提供这样一种机制，客户端请求 Metad 的一个固定的接口 /self，由 Metad 告知应用程序其所属的元信息，简化了客户端的服务发现和配置变更逻辑。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Metad 通过保存一个ip到元信息路径的映射关系来做到这一点，当前后端支持Etcd v3，提供简单好用的 http rest 接口。 它会把 Etcd 的数据通过watch机制同步到本地内存中，相当于 Etcd 的一个代理。所以也可以把它当做Etcd 的代理来使用，适用于不方便使用 Etcd v3的rpc接口或者想降低 Etcd 压力的场景。 metad Etcd 集群一键搭建脚本&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Etcd 官方那个一键搭建脚本有bug，我自己整理了一个脚本，通过docker的network功能，一键搭建一个本地的 Etcd 集群便于测试和试验。一键搭建脚本 Etcd 使用注意事项Etcd cluster 初始化的问题&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果集群第一次初始化启动的时候，有一台节点未启动，通过v3的接口访问的时候，会报告Error: Etcdserver: not capable 错误。这是为兼容性考虑，集群启动时默认的API版本是2.3，只有当集群中的所有节点都加入了，确认所有节点都支持v3接口时，才提升集群版本到v3。这个只有第一次初始化集群的时候会遇到，如果集群已经初始化完毕，再挂掉节点，或者集群关闭重启（关闭重启的时候会从持久化数据中加载集群API版本），都不会有影响。 Etcd 读请求的机制&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;v2 quorum=true 的时候，读取是通过raft进行的，通过cli请求，该参数默认为true。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;v3 –consistency=“l” 的时候（默认）通过raft读取，否则读取本地数据。sdk 代码里则是通过是否打开：WithSerializable option 来控制。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一致性读取的情况下，每次读取也需要走一次raft协议，能保证一致性，但性能有损失，如果出现网络分区，集群的少数节点是不能提供一致性读取的。但如果不设置该参数，则是直接从本地的store里读取，这样就损失了一致性。使用的时候需要注意根据应用场景设置这个参数，在一致性和可用性之间进行取舍。 Etcd 的 compact 机制&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Etcd 默认不会自动 compact，需要设置启动参数，或者通过命令进行compact，如果变更频繁建议设置，否则会导致空间和内存的浪费以及错误。Etcd v3 的默认的 backend quota 2GB，如果不 compact，boltdb 文件大小超过这个限制后，就会报错：”Error: etcdserver: mvcc: database space exceeded”，导致数据无法写入。 脑洞时间&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;自动上次 Elasticsearch 的文章之后，给自己安排了一个作业，每次分析源码后需要提出几个发散思维的想法，开个脑洞。 并发代码调用分析追踪工具&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当前IDE的代码调用分析追踪都是通过静态的代码分析来追踪方法调用链实现的，对阅读分析代码非常有用。但程序如果充分使用CSP或者Actor模型后，都通过消息进行调用，没有了明确的方法调用链，给阅读和理解代码带来了困难。如果语言或者IDE能支持这样的消息投递追踪分析，那应该非常有用。当然我这个只是脑洞，不考虑实现的可能性和复杂度。 实现一个通用的 multiple group raft库&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当前 Etcd 的raft实现保证了多个节点数据之间的同步，但明显的一个问题就是扩充节点不能解决容量问题。要想解决容量问题，只能进行分片，但分片后如何使用raft同步数据？只能实现一个 multiple group raft，每个分片的多个副本组成一个虚拟的raft group，通过raft实现数据同步。当前实现了multiple group raft的有 TiKV 和 Cockroachdb，但尚未一个独立通用的。理论上来说，如果有了这套 multiple group raft，后面挂个持久化的kv就是一个分布式kv存储，挂个内存kv就是分布式缓存，挂个lucene就是分布式搜索引擎。当然这只是理论上，要真实现复杂度还是不小。 Etcd 的开源产品启示&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Etcd在Zookeeper已经奠定江湖地位的情况下，硬是重新造了一个轮子，并且在生态圈中取得了一席之地。一方面可以看出是社区的形态在变化，沟通机制和对用户反馈的响应越来越重要，另外一方面也可以看出一个项目的易用的重要性有时候甚至高于稳定性和功能。新的算法，新的语言都会给重新制造轮子带来了机会。 gitchat交流群的问答问：业务使用的etcd v2 升级到 v3 会有什么问题呢，如何平滑过渡？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：v2的大多数功能，用v3都能实现，比如用prefix模拟原来的目录结构，用txn模拟CAS，一般不会有什么问题。但因为v2和v3的数据是互相隔离的，所以迁移起来略麻烦。建议先在业务中封装一层，将etcd v2,v3的差异封装起来，然后通过开关切换。 问：metad的watch是怎么实现的？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：metad的watch实现的比较简单，因为metad的watch返回的不是变更事件，而是最新的结果。所以metad只维护了一个全局版本号，只要发现客户端watch的版本小于等于全局版本号，就直接返回最新结果。 问：etcd和zk都是作为分布式配置管理的组件。均提供了watch功能，选主。作为初使用者，这两个之间的选取该如何？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：etcd和zk二者大多数情况下可以互相替代，都是通用的分布式一致性kv存储。二者之间选择建议选择自己的开发栈比较接近并且团队成员比较熟悉的，比如一种是按语言选择，go语言的项目用etcd，java的用zk，出问题要看源码也容易些。如果是新项目，纠结于二者，那可以分装一层lib，类似于docker/libkv，同时支持两种，有需要可以切换。 问：etcd和eureka、consul 的异同，以及各自的适用场景，以及选型原则。这个问题其实可以把zk也包括进来，这些都有相同之处。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：etcd和zk的选型前面讲到了，二者的定位都是通用的一致性kv存储，而eureka和consul的定位则是专做服务注册和发现。前二者的优势当然是通用性，应用广泛，部署运维的时候容易和已有的服务一起共用，而同时缺点也是太通用了，每个应用的服务注册都有自己的一套元数据格式，互相整合起来就比较麻烦了，比如想做个通用的api gateway就会遇到元数据格式兼容问题。这也成为后二者的优势。同时因为后二者的目标比较具体，所以可以做一些更高级的功能，比如consul的DNS支持，consul-template工具，eureka的事件订阅过滤机制。Eureka本身的实现是一个AP系统，也就是说牺牲了一致性，它认为在服务发现和配置中心这个场景下，可用性和分区容错比一致性更重要。 我个人其实更期待后二者的这种专门的解决方案，要是能形成服务注册标准，那以后应用之间互相交互就容易了。但也有个可能是这种标准由集群调度系统来形成事实标准。后二者我了解的也不深入，感觉可以另起一篇文章了。 问：接上面，etcd和zk各自都有哪些坑可能会被踩到，都有多坑。掉进去了如何爬起来？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个坑的概念比较太广泛了，更详细的可以翻bug列表。但使用中的大多数坑一般有几种： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;误用导致的坑。要先认识清楚etcd，zk的定位，它需要保存的是整个集群共享的信息，不能当存储用。比如有人在某个zk的某个数据节点下创建了大量的子节点，然后获取，导致zk报错，zk的buffer有个4mb的限制，超过就会报错。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;运维方面的坑。etcd，zk这种服务，一般都比较稳定，搭建好后都不用管，但万一某些节点出问题了，要增加节点恢复系统的时候，可能没有预案或者操作经验，导致弄坏集群。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;网络分区以及可用性设计的坑。设计系统的时候，要想清楚如果etcd或zk整个挂了，或者出现网络分区，应用的一部分节点只能连接到少数派的etcd/zk(少数派不可用)的时候，应用会有什么表现。这种情况下，应用的正确表现应该是服务正常运作，但不支持变更，等etcd/zk集群恢复后就自动恢复了。但如果设计不当，有自动化的一些行为，可能带来的故障就大了。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;想要少踩坑，一个办法就是我文中提到的，研究原理知其然同时知其所以然，另外一个问题就是多试验，出了问题有预案。 问：一个实验性质的硬件集群项目的几个问题 我们实现了基于Arm的分布式互联的硬件集群（方法参考的是https://edcashin.wordpress.com/2013/12/29/trying-etcd-on-android-mac-and-raspberry-pi/comment-page-1/ 将etcd跑在Arm开发板上），将Etcd当作一个分布式的数据库使用（但是Etcd本身运行在这些硬件之上），然后参考go-rpiohttps://github.com/stianeikeland/go-rpio 实现基于etcd的key-value同步硬件的信息，控制某些GPIO。 问题1：目前已知Etcd可以为别的服务提供服务发现，在这个场景下假设已经存在5个运行Etcd节点的硬件，当一个新的Etcd硬件节点被安装时，Etcd能否为自己提供服务发现服务，实现Etcd节点的自动发现与加入？ 问题2：随着硬件安装规模的增加，Etcd的极限是多少，raft是否会因为节点的变多，心跳包的往返而导致同步一次的等待时间变长？ 问题3：当规模足够大，发生网络分区时，是否分区较小的一批硬件之间的数据是无法完成同步的？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：这个案例挺有意思，我一个一个回答。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;etcd本来是做服务发现的，如果etcd集群也需要服务发现，那就再来一个etcd集群 ：）。你可以自己搭建一个etcd cluster或者用etcd官方提供的 discovery.etcd.io。详细参看：etcd 官方的 op-guide/clustering&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;etcd的机制是多节点一致的，所以它的极限有两部分，一是单机的容量限制，内存和磁盘。二是网络开销，每次raft操作需要所有节点参与，节点越多性能越低。所以扩展很多etcd节点是没有意义的，一般是 3，5，7，9。再多感觉就没意义了。如果你们不太在意一致性，建议读请求可以不通过一致性协议，直接读取节点本地数据。具体方式文中有说明。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;etcd网络分区时，少数派是不可用状态，不支持raft请求，但支持非一致性读请求。 问：如果跨机房部署服务，是部署两套ETCD吗？如果跨机房部署，如何部署及配置？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：这个要看跨机房的场景。如果是完全无关联需要公网连接的两个机房，服务之间一般也不需要共享数据吧？部署两套互不相干的etcd，各用各的比较合适。但如果是类似于aws的可用区的概念，两个机房内网互通，搭建两套集群为了避免机房故障，可以随时切换。这个etcd当前没有太好的解决办法，建议的办法是跨可用区部署一个etcd cluster，调整心跳以及选举超时时间，这个办法如果有3个可用区机房，每个机房3个节点，挂任何一个机房都不影响整个集群，但两个机房就比较尴尬。还有个办法是两个集群之间同步，这个etcdv3提供了一个mirror的工具，但还是不太完善，不过感觉用etcd的watch机制做一个同步工具也不难。这个机制consul倒是提供了，多数据中心的集群数据同步，互相不影响可用性。 问：在使用 etcd watch 过程中，有没有一些措施能帮助降低出现惊群（Herd Effect）？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：这个问题我也遇到了，但没发现太好的办法，除了在客户端做随机延迟。（注：这个问题后来和coreos的李响交流，他说etcd3.1会对有解决方案） 相关链接 raft官网 有论文地址以及相关资料。raft动画演示 看了这个动画就懂raft了。Interval_treeetcd：从应用场景到实现原理的全方位解读 这篇文章对使用场景描述的比较全面。confd 我们修改版的confd仓库地址。metad 仓库地址。etcd集群一键搭建脚本并发之痛 Thread，Goroutine，Actor 本人关于并发模型的一篇文章，有利于理解文章内提到的CSP模型。 Never forget to say “Thank you.”.]]></content>
      <categories>
        <category>分布式</category>
        <category>共识算法</category>
      </categories>
      <tags>
        <tag>共识算法</tag>
        <tag>分布式</tag>
        <tag>ETCD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper一致性共识算法ZAB详解]]></title>
    <url>%2F2019%2F10%2F01%2FZookeeper%E4%B8%80%E8%87%B4%E6%80%A7%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95ZAB%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zookeeper中一致性共识算法ZAB（Zookeeper Atomic Broadcast protocol）改进了Raft算法，提供一致性的元数据存储，多用在分布式系统中共享元数据信息。下面来看看具体细节。 1.ZAB介绍&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ZAB协议全称就是ZooKeeper Atomic Broadcast protocol，是ZooKeeper用来实现一致性的算法，分成如下4个阶段。 先来解释下部分名词: electionEpoch：每执行一次leader选举，electionEpoch就会自增，用来标记leader选举的轮次 peerEpoch：每次leader选举完成之后，都会选举出一个新的peerEpoch，用来标记事务请求所属的轮次 zxid：事务请求的唯一标记，由leader服务器负责进行分配。由2部分构成，高32位是上述的peerEpoch，低32位是请求的计数，从0开始。所以由zxid我们就可以知道该请求是哪个轮次的，并且是该轮次的第几个请求。 lastProcessedZxid：最后一次commit的事务请求的zxid Leader election: leader选举过程，electionEpoch自增，在选举的时候lastProcessedZxid越大，越有可能成为leader Discovery： 第一：leader收集follower的lastProcessedZxid，这个主要用来通过和leader的lastProcessedZxid对比来确认follower需要同步的数据范围第二：选举出一个新的peerEpoch，主要用于防止旧的leader来进行提交操作（旧leader向follower发送命令的时候，follower发现zxid所在的peerEpoch比现在的小，则直接拒绝，防止出现不一致性） Synchronization： follower中的事务日志和leader保持一致的过程，就是依据follower和leader之间的lastProcessedZxid进行，follower多的话则删除掉多余部分，follower少的话则补充，一旦对应不上则follower删除掉对不上的zxid及其之后的部分然后再从leader同步该部分之后的数据 Broadcast: 正常处理客户端请求的过程。leader针对客户端的事务请求，然后提出一个议案，发给所有的follower，一旦过半的follower回复OK的话，leader就可以将该议案进行提交了，向所有follower发送提交该议案的请求，leader同时返回OK响应给客户端 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上面简单的描述了上述4个过程，这4个过程的详细描述在zab的paper中可以找到，但是我看了之后基本和zab的源码实现上相差有点大，这里就不再提zab paper对上述4个过程的描述了，下面会详细的说明ZooKeeper源码中是具体怎么来实现的 2.ZAB协议源码实现先看下ZooKeeper整体的实现情况，如下图所示 上述实现中Recovery Phase包含了ZAB协议中的Discovery和Synchronization。 2.1 重要的数据介绍加上前面已经介绍的几个名词 long lastProcessedZxid：最后一次commit的事务请求的zxid LinkedList committedLog、long maxCommittedLog、long minCommittedLog：ZooKeeper会保存最近一段时间内执行的事务请求议案，个数限制默认为500个议案。上述committedLog就是用来保存议案的列表，上述maxCommittedLog表示最大议案的zxid,minCommittedLog表示committedLog中最小议案的zxid。 ConcurrentMap&lt;Long, Proposal&gt; outstandingProposalsLeader拥有的属性，每当提出一个议案，都会将该议案存放至outstandingProposals，一旦议案被过半认同了，就要提交该议案，则从outstandingProposals中删除该议案 ConcurrentLinkedQueue toBeAppliedLeader拥有的属性，每当准备提交一个议案，就会将该议案存放至该列表中，一旦议案应用到ZooKeeper的内存树中了，然后就可以将该议案从toBeApplied中删除 对于上述几个参数，整个Broadcast的处理过程可以描述为： leader针对客户端的事务请求（leader为该请求分配了zxid），创建出一个议案，并将zxid和该议案存放至leader的outstandingProposals中 leader开始向所有的follower发送该议案，如果过半的follower回复OK的话，则leader认为可以提交该议案，则将该议案从outstandingProposals中删除，然后存放到toBeApplied中 leader对该议案进行提交，会向所有的follower发送提交该议案的命令，leader自己也开始执行提交过程，会将该请求的内容应用到ZooKeeper的内存树中，然后更新lastProcessedZxid为该请求的zxid，同时将该请求的议案存放到上述committedLog，同时更新maxCommittedLog和minCommittedLog leader就开始向客户端进行回复，然后就会将该议案从toBeApplied中删除 2.2 Fast Leader Electionleader选举过程要关注的要点： 所有机器刚启动时进行leader选举过程 如果leader选举完成，刚启动起来的server怎么识别到leader选举已完成 投票过程有3个重要的数据: ServerState目前ZooKeeper机器所处的状态有4种，分别是 LOOKING：进入leader选举状态 FOLLOWING：leader选举结束，进入follower状态 LEADING：leader选举结束，进入leader状态 OBSERVING：处于观察者状态 HashMap&lt;Long, Vote&gt; recvset用于收集LOOKING、FOLLOWING、LEADING状态下的server的投票 HashMap&lt;Long, Vote&gt; outofelection用于收集FOLLOWING、LEADING状态下的server的投票（能够收集到这种状态下的投票，说明leader选举已经完成） 下面就来详细说明这个过程： 1. serverA首先将electionEpoch自增，然后为自己投票&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serverA会首先从快照日志和事务日志中加载数据，就可以得到本机器的内存树数据，以及lastProcessedZxid（这一部分后面再详细说明） &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;初始投票Vote的内容： proposedLeader：ZooKeeper Server中的myid值，初始为本机器的id proposedZxid：最大事务zxid，初始为本机器的lastProcessedZxid proposedEpoch:peerEpoch值，由上述的lastProcessedZxid的高32得到 然后该serverA向其他所有server发送通知，通知内容就是上述投票信息和electionEpoch信息 2. serverB接收到上述通知，然后进行投票PK&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果serverB收到的通知中的electionEpoch比自己的大，则serverB更新自己的electionEpoch为serverA的electionEpoch &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果该serverB收到的通知中的electionEpoch比自己的小，则serverB向serverA发送一个通知，将serverB自己的投票以及electionEpoch发送给serverA，serverA收到后就会更新自己的electionEpoch &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在electionEpoch达成一致后，就开始进行投票之间的pk，规则如下： 1234567891011/* * We return true if one of the following three cases hold: * 1- New epoch is higher * 2- New epoch is the same as current epoch, but new zxid is higher * 3- New epoch is the same as current epoch, new zxid is the same * as current zxid, but server id is higher. */return ((newEpoch &gt; curEpoch) || ((newEpoch == curEpoch) &amp;&amp; ((newZxid &gt; curZxid) || ((newZxid == curZxid) &amp;&amp; (newId &gt; curId))))); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;就是优先比较proposedEpoch，然后优先比较proposedZxid，最后优先比较proposedLeader &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pk完毕后，如果本机器投票被pk掉，则更新投票信息为对方投票信息，同时重新发送该投票信息给所有的server。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果本机器投票没有被pk掉，则看下面的过半判断过程 3. 根据server的状态来判定leader&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果当前发来的投票的server的状态是LOOKING状态，则只需要判断本机器的投票是否在recvset中过半了，如果过半了则说明leader选举就算成功了，如果当前server的id等于上述过半投票的proposedLeader,则说明自己将成为了leader，否则自己将成为了follower &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果当前发来的投票的server的状态是FOLLOWING、LEADING状态，则说明leader选举过程已经完成了，则发过来的投票就是leader的信息，这里就需要判断发过来的投票是否在recvset或者outofelection中过半了 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;同时还要检查leader是否给自己发送过投票信息，从投票信息中确认该leader是不是LEADING状态。这个解释如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因为目前leader和follower都是各自检测是否进入leader选举过程。leader检测到未过半的server的ping回复，则leader会进入LOOKING状态，但是follower有自己的检测，感知这一事件，还需要一定时间，在此期间，如果其他server加入到该集群，可能会收到其他follower的过半的对之前leader的投票，但是此时该leader已经不处于LEADING状态了，所以需要这么一个检查来排除这种情况。 2.3 Recovery Phase&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一旦leader选举完成，就开始进入恢复阶段，就是follower要同步leader上的数据信息 1 通信初始化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;leader会创建一个ServerSocket，接收follower的连接，leader会为每一个连接会用一个LearnerHandler线程来进行服务 2 重新为peerEpoch选举出一个新的peerEpochf&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ollower会向leader发送一个Leader.FOLLOWERINFO信息，包含自己的peerEpoch信息 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;leader的LearnerHandler会获取到上述peerEpoch信息，leader从中选出一个最大的peerEpoch，然后加1作为新的peerEpoch。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;然后leader的所有LearnerHandler会向各自的follower发送一个Leader.LEADERINFO信息，包含上述新的peerEpoch &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;follower会使用上述peerEpoch来更新自己的peerEpoch，同时将自己的lastProcessedZxid发给leader &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;leader的所有LearnerHandler会记录上述各自follower的lastProcessedZxid，然后根据这个lastProcessedZxid和leader的lastProcessedZxid之间的差异进行同步 3 已经处理的事务议案的同步&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;判断LearnerHandler中的lastProcessedZxid是否在minCommittedLog和maxCommittedLog之间 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LearnerHandler中的lastProcessedZxid和leader的lastProcessedZxid一致，则说明已经保持同步了 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果lastProcessedZxid在minCommittedLog和maxCommittedLog之间 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从lastProcessedZxid开始到maxCommittedLog结束的这部分议案，重新发送给该LearnerHandler对应的follower，同时发送对应议案的commit命令 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上述可能存在一个问题：即lastProcessedZxid虽然在他们之间，但是并没有找到lastProcessedZxid对应的议案，即这个zxid是leader所没有的，此时的策略就是完全按照leader来同步，删除该follower这一部分的事务日志，然后重新发送这一部分的议案，并提交这些议案 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果lastProcessedZxid大于maxCommittedLog &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;则删除该follower大于部分的事务日志 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果lastProcessedZxid小于minCommittedLog &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;则直接采用快照的方式来恢复 4 未处理的事务议案的同步&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LearnerHandler还会从leader的toBeApplied数据中将大于该LearnerHandler中的lastProcessedZxid的议案进行发送和提交（toBeApplied是已经被确认为提交的） &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LearnerHandler还会从leader的outstandingProposals中大于该LearnerHandler中的lastProcessedZxid的议案进行发送，但是不提交（outstandingProposals是还没被被确认为提交的） 5 将LearnerHandler加入到正式follower列表中&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;意味着该LearnerHandler正式接受请求。即此时leader可能正在处理客户端请求，leader针对该请求发出一个议案，然后对该正式follower列表才会进行执行发送工作。这里有一个地方就是： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上述我们在比较lastProcessedZxid和minCommittedLog和maxCommittedLog差异的时候，必须要获取leader内存数据的读锁，即在此期间不能执行修改操作，当欠缺的数据包已经补上之后（先放置在一个队列中，异步发送），才能加入到正式的follower列表，否则就会出现顺序错乱的问题 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;同时也说明了，一旦一个follower在和leader进行同步的过程（这个同步过程仅仅是确认要发送的议案，先放置到队列中即可等待异步发送，并不是说必须要发送过去），该leader是暂时阻塞一切写操作的。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于快照方式的同步，则是直接同步写入的，写入期间对数据的改动会放在上述队列中的，然后当同步写入完成之后，再启动对该队列的异步写入。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上述的要理解的关键点就是：既要不能漏掉，又要保证顺序 6 LearnerHandler发送Leader.NEWLEADER以及Leader.UPTODATE命令&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;该命令是在同步结束之后发的，follower收到该命令之后会执行一次版本快照等初始化操作，如果收到该命令的ACK则说明follower都已经完成同步了并完成了初始化 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;leader开始进入心跳检测过程，不断向follower发送心跳命令，不断检是否有过半机器进行了心跳回复，如果没有过半，则执行关闭操作，开始进入leader选举状态 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LearnerHandler向对应的follower发送Leader.UPTODATE，follower接收到之后，开始和leader进入Broadcast处理过程 2.4 Broadcast Phase前面其实已经说过了，参见2.1中的内容 3 特殊情况的注意点3.1 事务日志和快照日志的持久化和恢复先来看看持久化过程： Broadcast过程的持久化leader针对每次事务请求都会生成一个议案，然后向所有的follower发送该议案follower接收到该议案后，所做的操作就是将该议案记录到事务日志中，每当记满100000个（默认），则事务日志执行flush操作，同时开启一个新的文件来记录事务日志同时会执行内存树的快照，snapshot.[lastProcessedZxid]作为文件名创建一个新文件，快照内容保存到该文件中 leader shutdown过程的持久化一旦leader过半的心跳检测失败，则执行shutdown方法，在该shutdown中会对事务日志进行flush操作 再来说说恢复： 事务快照的恢复第一：会在事务快照文件目录下找到最近的100个快照文件，并排序，最新的在前第二：对上述快照文件依次进行恢复和验证，一旦验证成功则退出，否则利用下一个快照文件进行恢复。恢复完成更新最新的lastProcessedZxid 事务日志的恢复第一：从事务日志文件目录下找到zxid大于等于上述lastProcessedZxid的事务日志第二：然后对上述事务日志进行遍历，应用到ZooKeeper的内存树中，同时更新lastProcessedZxid第三：同时将上述事务日志存储到committedLog中，并更新maxCommittedLog、minCommittedLog 由此我们可以看到，在初始化恢复的时候，是会将所有最新的事务日志作为已经commit的事务来处理的 也就是说这里面可能会有部分事务日志还没真实提交，而这里全部当做已提交来处理。这个处理简单粗暴了一些，而raft对老数据的恢复则控制的更加严谨一些。 3.2 follower挂了之后又重启的恢复过程&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一旦leader挂了，上述leader的2个集合 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ConcurrentMap&lt;Long, Proposal&gt; outstandingProposals&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ConcurrentLinkedQueue toBeApplied&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;就无效了。他们并不在leader恢复的时候起作用，而是在系统正常执行，而某个follower挂了又恢复的时候起作用。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们可以看到在上述2.3的恢复过程中，会首先进行快照日志和事务日志的恢复，然后再补充leader的上述2个数据中的内容。 3.3 同步follower失败的情况&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;目前leader和follower之间的同步是通过BIO方式来进行的，一旦该链路出现异常则会关闭该链路，重新与leader建立连接，重新同步最新的数据 3.4 对client端是否一致&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;客户端收到OK回复，会不会丢失数据？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;客户端没有收到OK回复，会不会多存储数据？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;客户端如果收到OK回复，说明已经过半复制了，则在leader选举中肯定会包含该请求对应的事务日志，则不会丢失该数据 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;客户端连接的leader或者follower挂了，客户端没有收到OK回复，目前是可能丢失也可能没丢失，因为服务器端的处理也很简单粗暴，对于未来leader上的事务日志都会当做提交来处理的，即都会被应用到内存树中。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;同时目前ZooKeeper的原生客户端也没有进行重试，服务器端也没有对重试进行检查。这一部分到下一篇再详细探讨与raft的区别 4 未完待续本文有很多细节，难免可能疏漏，还请指正。 4.1 问题&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里留个问题供大家思考下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;raft每次执行AppendEntries RPC的时候，都会带上当前leader的新term，来防止旧的leader的旧term来执行相关操作，而ZooKeeper的peerEpoch呢？达到防止旧leader的效果了吗？它的作用是干什么呢？ Suffering is the best teacher of life.]]></content>
      <categories>
        <category>分布式</category>
        <category>共识算法</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
        <tag>共识算法</tag>
        <tag>分布式</tag>
        <tag>ZAB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据仓库基本结构]]></title>
    <url>%2F2019%2F09%2F29%2F%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库是一个面向主题的、集成的、稳定的、反映历史变化的数据集合，用于支持决策管理，下面来看看它的组成部分。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里有讲解数据仓库各个特点的具体详情，数据仓库特点详解 根据仓库特点我们可以大致猜到，他的结构大概是什么样子的： 面向主题的、集成的&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;集成的数据仓库，数据是从不同的业务主题数据源处经过清洗、整合、统一规范入库，那么仓库中就会有数据准备区(data staging层)缓存业务数据，然后清洗，得到的一致性数据ODS层，另外需要提供数据查询工具、数据可视化工具、数据建模工具、OLAP分析工具进行数据展示和分析，来更好地提供决策支持。 稳定的、反映历史变化的&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;仓库中的数据是定期按时从源数据端拉取过来，不会经常做更新操作，拉取更新操作需要用到抽取工具、任务调度工具，而且可以查询到历史数据状态，那么就需要管理数据的元数据管理工具，了解仓库中到底有哪些数据，这些数据目前的状况是怎样的。 一、概念结构 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从数据仓库的概念结构看，一般来说，数据仓库系统要包含数据源、数据准备区、数据仓库数据库、数据集市/知识挖掘库及各种管理工具和应用工具，如图 3-10 所示。数据仓库建立之后，首先要从数据源中抽取相关的数据到数据准备区，在数据准备区中经过净化处理后再加载到数据仓库数据库，最后根据用户的需求将数据导入数据集市和知识挖掘库中。当用户使用数据仓库时，可以利用包括 OLAP（On-Line Analysis Processing，联机分析处理）在内的多种数据仓库应用工具向数据集市/知识挖掘库或数据仓库进行决策查询分析或知识挖掘。数据仓库的创建、应用可以利用各种数据仓库管理工具辅助完成。 二、层次框架&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库框架由数据仓库基本功能层、数据仓库管理层和数据仓库环境支持层组成。 数据仓库基本功能层: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库的基本功能层部分包含数据源、数据准备区、数据仓库结构、数据集市或知识挖掘库，以及存取和使用部分。 数据仓库管理层: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库管理层由数据仓库的数据管理和数据仓库的元数据管理组成。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库的数据管理层包含数据抽取、新数据需求与查询管理，数据加载、存储、刷新和更新系统，安全性与用户授权管理系统及数据归档、恢复及净化系统等四部分。 数据仓库的环境支持层: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库的环境支持层由数据仓库数据传输层和数据仓库基础层组成。 三、架构图 you must do what you like.]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>数据仓库</tag>
        <tag>OLAP</tag>
        <tag>ODS</tag>
        <tag>Data Market</tag>
        <tag>Data Source</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一致性共识算法Raft图文详解]]></title>
    <url>%2F2019%2F09%2F29%2F%E4%B8%80%E8%87%B4%E6%80%A7%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95Raft%E5%9B%BE%E6%96%87%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;熟悉或了解分布式系统的开发者都知道一致性算法的重要性，Paxos一致性算法提出至今已经有二十几年了，而Paxos流程太过于繁杂，实现起来比较复杂，因此Raft应运而生，它是比Paxos更简单而又能实现Paxos所解决的问题的一致性算法。 Raft动图展示详解 Death is like the wind, always by my side.]]></content>
      <categories>
        <category>区块链</category>
        <category>共识算法</category>
      </categories>
      <tags>
        <tag>一致性协议</tag>
        <tag>raft</tag>
        <tag>共识算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[事实表、维度、度量、指标之间的关系]]></title>
    <url>%2F2019%2F09%2F29%2F%E4%BA%8B%E5%AE%9E%E8%A1%A8%E3%80%81%E7%BB%B4%E5%BA%A6%E3%80%81%E5%BA%A6%E9%87%8F%E3%80%81%E6%8C%87%E6%A0%87%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[数据仓库中有许多概念，比如事实表、维度、度量、指标，下面来看看他们是什么意思，这几个概念之间有什么关系？ 事实表：每个数据仓库都包含一个或多个事实数据表。事实数据表可能包含业务销售数据，如销售商品所产生的数据，与软件中实际表概念一样。 维度：说明数据，维度是指可指定不同值的对象的描述性属性或特征。例如，地理位置的维度可以描述为 “经度”、“纬度”或“城市名称”，“城市名称”维度的值可以为“旧金山”、“柏林”或“新加坡”。 指标：衡量数据，指标是指可以按照总数或者比值进行衡量的具体维度元素，例如，“城市”维度可以关联“人口”指标，其值为具体城市的总人口数。 维度和指标的关系：虽然维度和指标可以独立使用，但是一般会结合使用。维度和指标的值以及这些值之间的关系，使你的数据具有的意义。为了挖掘尽可能多的深层次信息，维度通常和一个或多个指标关联在一起。例如，维度“城市”可以与指标“人口”、“面积”相关联，有了这些数据，系统还可以创建“人口密度”等比值指标，带来有关这些城市更详细的深入信息。 度量：事实表和维度交叉汇聚的点，度量和维度构成OLAP的主要概念。这里面对于在事实表或一个多维立方体里面存放的数值型的、连续的字段，就是度量。这符合上面的意思，有标准，一个度量字段肯定是统一单位，例如元、人数。如果一个度量字段，其中的度量值可能是美元，可能是欧元，那这个度量可没法汇总。在统一计量单位下，对不同维度的描述。 指标与度量的关系：这就得说到指标，我愿意表述为“它是表示某种相对程度的值”。区别于上面的度量的概念，那是一种绝对值，尺子量出来的结果，汇总出来的数量等。而指标至少需要2个度量之间的计算才能得到，例如收入增长率，用本月收入比上上月收入。当然指标的计算可能需要两个以上的度量。 Learn to make friends with yourself: do something funny together, learn something together, and catch up with each other.]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>事实表</tag>
        <tag>维度</tag>
        <tag>度量</tag>
        <tag>指标</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式一致性算法Raft]]></title>
    <url>%2F2019%2F09%2F28%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95Raft%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;熟悉或了解分布式系统的开发者都知道一致性算法的重要性，Paxos一致性算法提出至今已经有二十几年了，而Paxos流程太过于繁杂，实现起来比较复杂，因此Raft应运而生，它是比Paxos更简单而又能实现Paxos所解决的问题的一致性算法。 Raft动图展示详解 一、背景&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;熟悉或了解分布性系统的开发者都字段一致性算法的重要性，Paxos一致性算法从90年提出到现在已经有二十几年了，而Paxos流程太过于繁杂实现起来也比较复杂，可能也是以为过于复杂 现在我听说过比较出名使用到Paxos的也就只是Chubby、libpaxos，搜了下发现Keyspace、BerkeleyDB数据库中也使用了该算法作为数据的一致性同步，虽然现在很广泛使用的Zookeeper也是基于Paxos算法来实现，但是Zookeeper使用的ZAB（Zookeeper Atomic Broadcast）协议对Paxos进行了很多的改进与优化，算法复杂我想会是制约他发展的一个重要原因；说了这么多只是为了要引出本篇文章的主角Raft一致性算法，没错Raft就是在这个背景下诞生的，文章开头也说到了Paxos最大的问题就是复杂，Raft一致性算法就是比Paxos简单又能实现Paxos所解决的问题的一致性算法。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Raft是斯坦福的Diego Ongaro、John Ousterhout两个人以易懂（Understandability）为目标设计的一致性算法，在2013年发布了论文：《In Search of an Understandable Consensus Algorithm》从2013年发布到现在不过只有两年，到现在已经有了十多种语言的Raft算法实现框架，较为出名的有etcd，Google的Kubernetes也是用了etcd作为他的服务发现框架；由此可见易懂性是多么的重要。 二、Raft概述&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;与Paxos不同Raft强调的是易懂（Understandability），Raft和Paxos一样只要保证n/2+1节点正常就能够提供服务；众所周知但问题较为复杂时可以把问题分解为几个小问题来处理，Raft也使用了分而治之的思想把算法流程分为三个子问题：选举（Leader election）、日志复制（Log replication）、安全性（Safety）三个子问题；这里先简单介绍下Raft的流程;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Raft开始时在集群中选举出Leader负责日志复制的管理，Leader接受来自客户端的事务请求（日志），并将它们复制给集群的其他节点，然后负责通知集群中其他节点提交日志，Leader负责保证其他节点与他的日志同步，当Leader宕掉后集群其他节点会发起选举选出新的Leader； 三、Raft详解1、角色&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Raft把集群中的节点分为三种状态：Leader、 Follower 、Candidate，理所当然每种状态负责的任务也是不一样的，Raft运行时提供服务的时候只存在Leader与Follower两种状态； Leader（领导者）：负责日志的同步管理，处理来自客户端的请求，与Follower保持这heartBeat的联系；Follower（追随者）：刚启动时所有节点为Follower状态，响应Leader的日志同步请求，响应Candidate的请求，把请求到Follower的事务转发给Leader；Candidate（候选者）：负责选举投票，Raft刚启动时由一个节点从Follower转为Candidate发起选举，选举出Leader后从Candidate转为Leader状态； 2、Term&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Raft中使用了一个可以理解为周期（第几届、任期）的概念，用Term作为一个周期，每个Term都是一个连续递增的编号，每一轮选举都是一个Term周期，在一个Term中只能产生一个Leader；先简单描述下Term的变化流程： Raft开始时所有Follower的Term为1，其中一个Follower逻辑时钟到期后转换为Candidate，Term加1这是Term为2（任期），然后开始选举，这时候有几种情况会使Term发生改变： 如果当前Term为2的任期内没有选举出Leader或出现异常，则Term递增，开始新一任期选举 当这轮Term为2的周期选举出Leader后，过后Leader宕掉了，然后其他Follower转为Candidate，Term递增，开始新一任期选举 当Leader或Candidate发现自己的Term比别的Follower小时Leader或Candidate将转为Follower，Term递增 当Follower的Term比别的Term小时Follower也将更新Term保持与其他Follower一致； &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以说每次Term的递增都将发生新一轮的选举，Raft保证一个Term只有一个Leader，在Raft正常运转中所有的节点的Term都是一致的，如果节点不发生故障一个Term（任期）会一直保持下去，当某节点收到的请求中Term比当前Term小时则拒绝该请求； 3、选举（Election）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Raft的选举由定时器来触发，每个节点的选举定时器时间都是不一样的，开始时状态都为Follower某个节点定时器触发选举后Term递增，状态由Follower转为Candidate，向其他节点发起RequestVote RPC请求，这时候有三种可能的情况发生： 该RequestVote请求接收到n/2+1（过半数）个节点的投票，从Candidate转为Leader，向其他节点发送heartBeat以保持Leader的正常运转 在此期间如果收到其他节点发送过来的AppendEntries RPC请求，如该节点的Term大则当前节点转为Follower，否则保持Candidate拒绝该请求 Election timeout发生则Term递增，重新发起选举 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在一个Term期间每个节点只能投票一次，所以当有多个Candidate存在时就会出现每个Candidate发起的选举都存在接收到的投票数都不过半的问题，这时每个Candidate都将Term递增、重启定时器并重新发起选举，由于每个节点中定时器的时间都是随机的，所以就不会多次存在有多个Candidate同时发起投票的问题。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有这么几种情况会发起选举，1：Raft初次启动，不存在Leader，发起选举；2：Leader宕机或Follower没有接收到Leader的heartBeat，发生election timeout从而发起选举; 4、日志复制（Log Replication）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;日志复制（Log Replication）主要作用是用于保证节点的一致性，这阶段所做的操作也是为了保证一致性与高可用性；当Leader选举出来后便开始负责客户端的请求，所有事务（更新操作）请求都必须先经过Leader处理，这些事务请求或说成命令也就是这里说的日志，我们都知道要保证节点的一致性就要保证每个节点都按顺序执行相同的操作序列，日志复制（Log Replication）就是为了保证执行相同的操作序列所做的工作；在Raft中当接收到客户端的日志（事务请求）后先把该日志追加到本地的Log中，然后通过heartbeat把该Entry同步给其他Follower，Follower接收到日志后记录日志然后向Leader发送ACK，当Leader收到大多数（n/2+1）Follower的ACK信息后将该日志设置为已提交并追加到本地磁盘中，通知客户端并在下个heartbeat中Leader将通知所有的Follower将该日志存储在自己的本地磁盘中。 5、安全性（Safety）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;安全性是用于保证每个节点都执行相同序列的安全机制，如当某个Follower在当前Leader commit Log时变得不可用了，稍后可能该Follower又会倍选举为Leader，这时新Leader可能会用新的Log覆盖先前已committed的Log，这就是导致节点执行不同序列；Safety就是用于保证选举出来的Leader一定包含先前 commited Log的机制： 选举安全性（Election Safety） 每个Term只能选举出一个Leader Leader完整性（Leader Completeness） &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里所说的完整性是指Leader日志的完整性，当Log在Term1被Commit后，那么以后Term2、Term3…等的Leader必须包含该Log；Raft在选举阶段就使用Term的判断用于保证完整性：当请求投票的该Candidate的Term较大或Term相同Index更大则投票，否则拒绝该请求。 keep exercising, keep learning english, keep learning blockchain.]]></content>
      <categories>
        <category>区块链</category>
        <category>共识算法</category>
      </categories>
      <tags>
        <tag>一致性协议</tag>
        <tag>raft</tag>
        <tag>共识算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式一致性协议Paxos]]></title>
    <url>%2F2019%2F09%2F27%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AEPaxos%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Basic-Paxos算法(可以先看后面的实际例子再看前面的具体介绍部分）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;多个节点并发操纵数据，如何保证在读写过程中数据的一致性，并且解决方案要能适应分布式环境下的不可靠性，由此，Paxos共识算法应运而生。 一、Paxos算法的目的&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Paxos算法的目的是为了解决分布式环境下一致性的问题。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;多个节点并发操纵数据，如何保证在读写过程中数据的一致性，并且解决方案要能适应分布式环境下的不可靠性（系统如何就一个值达到统一） 二、Paxos的两个组件1.Proposer &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;提议发起者，处理客户端请求，将客户端的请求发送到集群中，以便决定这个值是否可以被批准。 2.Acceptor &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;提议批准者，负责处理接收到的提议，他们的回复就是一次投票。会存储一些状态来决定是否接收一个值 三、Paxos有两个原则1).安全原则—保证不能做错的事 a） 针对某个实例的表决只能有一个值被批准，不能出现一个被批准的值被另一个值覆盖的情况；(假设有一个值被多数Acceptor批准了，那么这个值就只能被学习)b） 每个节点只能学习到已经被批准的值，不能学习没有被批准的值。 2).存活原则—只要有多数服务器存活并且彼此间可以通信，最终都要做到的下列事情： a）最终会批准某个被提议的值；b）一个值被批准了，其他服务器最终会学习到这个值。 四、Paxos具体流程图 1.第一阶段（prepare）1).获取一个proposal number, n； 2).提议者向所有节点广播prepare(n)请求； 3).接收者（Acceptors比较善变，如果还没最终认可一个值，它就会不断认同提案号最大的那个方案）比较n和minProposal，如果n&gt;minProposal,表示有更新的提议minProposal=n；如果此时该接受者并没有认可一个最终值，那么认可这个提案，返回OK。如果此时已经有一个accptedValue, 将返回(acceptedProposal,acceptedValue)； 4).提议者接收到过半数请求后，如果发现有acceptedValue返回，表示有认可的提议，保存最高acceptedProposal编号的acceptedValue到本地 2.第二阶段(Accept)5）广播accept(n,value)到所有节点； 6).接收者比较n和minProposal，如果n&gt;=minProposal,则acceptedProposal=minProposal=n，acceptedValue=value，本地持久化后，返回；否则，拒绝并且返回minProposal 7).提议者接收到过半数请求后，如果发现有返回值&gt;n，表示有更新的提议，跳转1（重新发起提议）；否则value达成一致。 三、Paxos议案ID生成算法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Google的Chubby论文中给出了这样一种方法：假设有n个proposer，每个编号为ir(0&lt;=ir&lt;n)，proposal编号的任何值s都应该大于它已知的最大值，并且满足： 1s %n = ir =&gt; s = m*n + ir &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;proposer已知的最大值来自两部分：proposer自己对编号自增后的值和接收到acceptor的拒绝后所得到的值。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;例：以3个proposer P1、P2、P3为例，开始m=0,编号分别为0，1，2。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1） P1提交的时候发现了P2已经提交，P2编号为1 &gt;P1的0，因此P1重新计算编号：new P1 = 1*3+1 = 4； &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2） P3以编号2提交，发现小于P1的4，因此P3重新编号：new P3 = 1*3+2 = 5。 四、Paxos原理&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;任意两个法定集合，必定存在一个公共的成员。该性质是Paxos有效的基本保障 五、活锁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当某一proposer提交的proposal被拒绝时，可能是因为acceptor 承诺返回了更大编号的proposal，因此proposer提高编号继续提交。 如果2个proposer都发现自己的编号过低转而提出更高编号的proposal，会导致死循环，这种情况也称为活锁。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;比如说当此时的 proposer1提案是3, proposer2提案是4, 但acceptor承诺的编号是5，那么此时proposer1,proposer2 都将提高编号假设分别为6,7，并试图与accceptor连接，假设7被接受了，那么提案5和提案6就要重新编号提交，从而不断死循环。 六、异常情况——持久存储&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在算法执行的过程中会产生很多的异常情况：proposer宕机，acceptor在接收proposal后宕机，proposer接收消息后宕机，acceptor在accept后宕机，learn宕机，存储失败，等等。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为保证paxos算法的正确性，proposer、aceptor、learn都实现持久存储，以做到server恢复后仍能正确参与paxos处理。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;propose存储已提交的最大proposal编号、决议编号（instance id）。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;acceptor存储已承诺（promise）的最大编号、已接受（accept）的最大编号和value、决议编号。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;learn存储已学习过的决议和编号。 七、具体实例：1.假设的3军问题1） 1支红军在山谷里扎营，在周围的山坡上驻扎着3支蓝军； 2） 红军比任意1支蓝军都要强大；如果1支蓝军单独作战，红军胜；如果2支或以上蓝军同时进攻，蓝军胜； 3） 三支蓝军需要同步他们的进攻时间；但他们惟一的通信媒介是派通信兵步行进入山谷，在那里他们可能被俘虏，从而将信息丢失；或者为了避免被俘虏，可能在山谷停留很长时间； 4） 每支军队有1个参谋负责提议进攻时间；每支军队也有1个将军批准参谋提出的进攻时间；很明显，1个参谋提出的进攻时间需要获得至少2个将军的批准才有意义； 5） 问题：是否存在一个协议，能够使得蓝军同步他们的进攻时间？ 2.接下来以两个假设的场景来演绎BasicPaxos；参谋和将军需要遵循一些基本的规则1） 参谋以两阶段提交（prepare/commit）的方式来发起提议，在prepare阶段需要给出一个编号； 2） 在prepare阶段产生冲突，将军以编号大小来裁决，编号大的参谋胜出； 3） 参谋在prepare阶段如果收到了将军返回的已接受进攻时间，在commit阶段必须使用这个返回的进攻时间； 2.1 两个参谋先后提议的场景 1） 参谋1发起提议，派通信兵带信给3个将军，内容为（编号1）； 2） 3个将军收到参谋1的提议，由于之前还没有保存任何编号，因此把（编号1）保存下来，避免遗忘；同时让通信兵带信回去，内容为（ok）； 3） 参谋1收到至少2个将军的回复，再次派通信兵带信给3个将军，内容为（编号1，进攻时间1）； 4） 3个将军收到参谋1的时间，把（编号1，进攻时间1）保存下来，避免遗忘；同时让通信兵带信回去，内容为（Accepted）； 5） 参谋1收到至少2个将军的（Accepted）内容，确认进攻时间已经被大家接收； 6） 参谋2发起提议，派通信兵带信给3个将军，内容为（编号2）； 7） 3个将军收到参谋2的提议，由于（编号2）比（编号1）大，因此把（编号2）保存下来，避免遗忘；又由于之前已经接受参谋1的提议，因此让通信兵带信回去，内容为（编号1，进攻时间1）； 8） 参谋2收到至少2个将军的回复，由于回复中带来了已接受的参谋1的提议内容，参谋2因此不再提出新的进攻时间，接受参谋1提出的时间； 2.2 两个参谋交叉提议的场景 1） 参谋1发起提议，派通信兵带信给3个将军，内容为（编号1）； 2） 3个将军的情况如下 a) 将军1和将军2收到参谋1的提议，将军1和将军2把（编号1）记录下来，如果有其他参谋提出更小的编号，将被拒绝；同时让通信兵带信回去，内容为（ok）；b) 负责通知将军3的通信兵被抓，因此将军3没收到参谋1的提议； 3） 参谋2在同一时间也发起了提议，派通信兵带信给3个将军，内容为（编号2）； 4） 3个将军的情况如下 a) 将军2和将军3收到参谋2的提议，将军2和将军3把（编号2）记录下来，如果有其他参谋提出更小的编号，将被拒绝；同时让通信兵带信回去，内容为（ok）；b) 负责通知将军1的通信兵被抓，因此将军1没收到参谋2的提议； 5） 参谋1收到至少2个将军的回复，再次派通信兵带信给有答复的2个将军，内容为（编号1，进攻时间1）； 6） 2个将军的情况如下 a) 将军1收到了（编号1，进攻时间1），和自己保存的编号相同，因此把（编号1，进攻时间1）保存下来；同时让通信兵带信回去，内容为（Accepted）；b) 将军2收到了（编号1，进攻时间1），由于（编号1）小于已经保存的（编号2），因此让通信兵带信回去，内容为（Rejected，编号2）； 7） 参谋2收到至少2个将军的回复，再次派通信兵带信给有答复的2个将军，内容为（编号2，进攻时间2）； 8） 将军2和将军3收到了（编号2，进攻时间2），和自己保存的编号相同，因此把（编号2，进攻时间2）保存下来，同时让通信兵带信回去，内容为（Accepted）； 9） 参谋2收到至少2个将军的（Accepted）内容，确认进攻时间已经被多数派接受； 10） 参谋1只收到了1个将军的（Accepted）内容，同时收到一个（Rejected，编号2）；参谋1重新发起提议，派通信兵带信给3个将军，内容为（编号3）； 11） 3个将军的情况如下 a) 将军1收到参谋1的提议，由于（编号3）大于之前保存的（编号1），因此把（编号3）保存下来；由于将军1已经接受参谋1前一次的提议，因此让通信兵带信回去，内容为（编号1，进攻时间1）；b) 将军2收到参谋1的提议，由于（编号3）大于之前保存的（编号2），因此把（编号3）保存下来；由于将军2已经接受参谋2的提议，因此让通信兵带信回去，内容为（编号2，进攻时间2）；c) 负责通知将军3的通信兵被抓，因此将军3没收到参谋1的提议； 12） 参谋1收到了至少2个将军的回复，比较两个回复的编号大小，选择大编号对应的进攻时间作为最新的提议；参谋1再次派通信兵带信给有答复的2个将军，内容为（编号3，进攻时间2）； 13） 将军1和将军2收到了（编号3，进攻时间2），和自己保存的编号相同，因此保存（编号3，进攻时间2），同时让通信兵带信回去，内容为（Accepted）； 14） 参谋1收到了至少2个将军的（accepted）内容，确认进攻时间已经被多数派接受； Interest is the best guider.]]></content>
      <categories>
        <category>区块链</category>
        <category>共识算法</category>
      </categories>
      <tags>
        <tag>一致性协议</tag>
        <tag>共识算法</tag>
        <tag>paxos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据仓库维度建模中星型模型与❄雪花❄️模型的选择]]></title>
    <url>%2F2019%2F09%2F26%2F%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E7%BB%B4%E5%BA%A6%E5%BB%BA%E6%A8%A1%E4%B8%AD%E6%98%9F%E5%9E%8B%E6%A8%A1%E5%9E%8B%E4%B8%8E%E2%9D%84%E9%9B%AA%E8%8A%B1%E2%9D%84%EF%B8%8F%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%80%89%E6%8B%A9%2F</url>
    <content type="text"><![CDATA[维度建模中包含2种设计方式： 星型模式； 雪花模式；下面从多个角度来比较一下这2中模式的利弊吧。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从查询性能角度来看，在OLTP-DW环节，由于雪花型要做多个表联接，性能会低于星型架构；但从DW-OLAP环节，由于雪花型架构更有利于度量值的聚合，因此性能要高于星型架构。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从模型复杂度来看，星型架构更简单。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从层次概念来看，雪花型架构更加贴近OLTP系统的结构，比较符合业务逻辑，层次比较清晰。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从存储空间角度来看，雪花型架构具有关系数据模型的所有优点，不会产生冗余数据，而相比之下星型架构会产生数据冗余。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据我们的项目经验，一般建议使用星型架构。因为我们在实际项目中，往往最关注的是查询性能问题，至于磁盘空间一般都不是问题。 当然，在维度表数据量极大，需要节省存储空间的情况下，或者是业务逻辑比较复杂、必须要体现清晰的层次概念情况下，可以使用雪花型维度。 一、概念：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们先了解下星型模式和雪花模式的概念： 星型模式：一种使用关系数据库实现多维分析空间的模式，称为星型模式。星型模式的基本形式必须实现多维空间（常常被称为方块），以使用关系数据库的基本功能。雪花模式：不管什么原因，当星型模式的维度需要进行规范化时，星型模式就演进为雪花模式。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;那么我们怎么样来理解 多维分析空间 呢 ？ 几何学中的方块是指一个三维空间，其中每个维度的尺寸都相同。想象一个立方体，每个维度都有三个单元，我们即得到相同结构的33＝27个单元。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;多维分析空间（或者数据仓库方块）与几何空间中的方块仅仅存在细节上的差异。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;维度不限于 3 维。不过，处理很多维度的立方体也不是件轻松的事情，这会导致大多数的实现被限制于 6 或者 7 维。不要期盼使用图形可以很好地表示超过 4 的维度。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;维度并不具有相同的规模和单元。规模从几个单元到几百万个单元，差别巨大。单元可以是一天、一位顾客、部门等。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据立方体需要很大的内存以存储所有事实。无论是否包含事实，都必须要预留单元。这就是为什么使用关系数据库和星型模式的原因。使用它们能够优化存储并且保持数据结构的灵活性。 二、星型模式&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;星型模式的基本思想就是保持立方体的多维功能，同时也增加了小规模数据存储的灵活性。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在图中，星型模式使用事实 Flight 表示了一个 4 维方块（Passenger、Menu、Flight Schedulet 和 Time）。基本上，事实必须指定一个维度，以将其放入立方体的单元中。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;每个维度根据一个对象进行描述，对象可以用类表示，这些类就是有关业务主题的名称。这一点对于成功建立数据仓库来说是很重要的，因为仓库的用户（经理、分析员、市场）对于信息技术的术语并不是很熟悉。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;事实本身就是商业智能的另一个对象，仍然通过类进行表示。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;事实指每个维度。事实与维度的关联常常是一对任意，这也就意味着每个事实都与单个维度的一个单元准确对应，而维度的每个单元（每个Passenger、Time等）可以与任意数量的事实发生关联（包括0个事实）。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在星型模式中切片和切块是对维度的限制（选择）。这是一个运行时问题，而不是建模问题，但是模型必须分辨其需要。 三、雪花模式&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基本的星型模式并不能满足数据挖掘的所有需要。我们需要更复杂的维度，例如时间。分析员希望根据周、月、季度等识别模式。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;维度必须进行规范化。我们不需要冗余的维度表，这只会使数据切片变得更加复杂。这种过程中我们得到的模式被称为雪花模式。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们来看一个简单的雪花模式例子。我们将时间维度规范化为周、月和季度。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们希望能够使用附加的规范化维度将立方体切片：周、月和季度。在本例中，我们假定季度是月的平行层次，这也就意味着我们不能将季度假定为若干月的聚合。由于这个原因，我们将使用一张范化表（是对 OLAP 查询的一项简单附加）预先选择时间维度。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最终雪花模式添加了规范化维度。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当然，所有的维度都可以像时间例子那样进行规范化，这就导致了比较复杂的数据集市模式的出现。 吾之初心，永世不忘。]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>数据仓库</tag>
        <tag>维度建模</tag>
        <tag>星型模型</tag>
        <tag>雪花模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据仓库工程师一般面试题]]></title>
    <url>%2F2019%2F09%2F25%2F%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%B7%A5%E7%A8%8B%E5%B8%88%E4%B8%80%E8%88%AC%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于高级数据仓库工程师的问题更侧重于各种工具的细枝末节。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于数据仓库架构师的问题更侧重于数据仓库的架构和总体认识。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于数据仓库项目经理的问题除了以上的问题外，就是一般项目管理的技能了吧。 一、什么叫数据仓库？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库是一个面向主题的、集成的、相对稳定的、反映历史变化的数据集合，用于支持管理决策。 面向主题：数据仓库是为了提供决策服务的，会建立不同的主题，而主题是进行决策时重点关注的部分； 集成：数据仓库可以整合来自不同数据源的数据，将这个数据入库、清洗、整合成统一的标准化数据，同时上文中提到的一个主题往往与多个系统相关，集成的数据很好地满足了主题构建的数据需求。数据仓库对原有的分散的数据库、文件进行数据抽取、清理的基础上经过系统加工、整理得到，清除原数据中的不一致性（面向事务的数据库往往单独存放单个系统的数据，且不同数据库相互独立，且是异构的）； 相对稳定：数据仓库中的数据是面向决策的，这就表明了仓库中的数据进入之后一般会长期保留，主要面对的是查询，更新和删除操作很少，一般是定期地加载、更新； 反映历史变化：仓库中会保留各个时间节点的数据，以满足不断变化的业务需求。 二、数据仓库与数据库的区别？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据库：按照数据结构来组织、存储、管理数据，建立在计算机存储设备上面的仓库，一般适用于操作系统，因为符合范式的设计模式，所以数据的一致性较好。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库：面向主题的、集成的、稳定的（不是时时刻刻变化）、反映历史变化的数据集合，可以包含多个数据库。 三、什么是OLAP？用途是什么？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;OLAP：联机分析处理（online analytical processing），是数据仓库的主要应用，支持复杂的分析操作，侧重决策支持，并提供直观易懂的查询结果。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;联机分析处理（OLAP）的概念最早由关系型数据库之父E.F.Codd于1993年提出，当时引起了很大的反响，同联机事务处理（OLTP）明显地区分开来。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当今的数据处理大致可以分为两大类：OLTP和OLAP，OLTP是传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，比如银行交易。OLAP是数据仓库系统的主要应用，支持复杂的分析操作，侧重决策支持，并提供直观易懂的查询结果。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;另一种解释是： 联机分析处理（On-Line Analytical Processing, OLAP）是基于数据仓库的在线多维统计分析。它允许用户在线地从多个维度观察某个度量值，从而为决策提供支持。 四、什么叫维度和度量值？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一个是出发点，一个是观察值 五、数据仓库的基本架构是什么？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据源，ETL，data stage，ODS，data warehouse,datamart,OLAP等等，可能为针对每一个结构进行发问啊。 六、什么叫缓慢维度变化？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了表现和记录基础数据变化情况在数据仓库中的记录，包括三大类维度处理方式，缓慢变化维包括三小类。 七、什么叫查找表，为什么使用替代键？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其实目的和上面一样，从基础表到缓慢维度表的过程中的一种实现途径。 八、如何实现增量抽取？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;主要采用时间戳方式，提供数据抽取和处理的性能。 九、用过什么ETL工具？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;informatica，ssis，owb，datastage，以及该工具简单讲述特点。 十、ETL都包括那些组成部分？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;工作流和数据流,数据流包括若干组件处理ETL的各个环节。 十一、用过什么报表工具？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bo,hyperion,congo,reporting servce，以及该工具基本特点。 十二、数据仓库项目最重要或需要注意的是什么，以及如何处理？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一般答数据质量，主要是数据源数据质量分析，数据清洗转换，当然也可以定量分析。 十三、关于数据库部分的面试题(不是要DBA的，但是还是要具备DBA的部分知识结构) 用过什么数据库(SQLServer,Oracle)，并能够讲述其物理和逻辑结构，以Oracle为主 能够写基本的SQL语句，分组函数和关联，通常会给几个例子的 如何进行性能优化，只要能答索引的基本原理以及各种索引的区别就行了 总之，事实上数据仓库和DBA或者其他技术不同，没有什么绝对的答案，只要能表达和描述清楚自己的观点就行了。 我的命运，由我做主。]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>数据仓库</tag>
        <tag>面试题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库三大设计范式]]></title>
    <url>%2F2019%2F09%2F22%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%89%E5%A4%A7%E8%AE%BE%E8%AE%A1%E8%8C%83%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;什么是数据库设计范式：简言之，就是在关系型数据库表设计的过程中所遵循的一种规范，如何设计使数据库表结构，来对数据的存储、查询、使用的性能更优。 第一范式（1NF）无重复的列&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所谓第一范式（1NF）是指数据库表的每一列都是不可分割的基本数据项，同一列中不能有多个值，即实体中的某个属性不能有多个值或者不能有重复的属性。如果出现重复的属性，就可能需要定义一个新的实体，新的实体由重复的属性构成，新实体与原实体之间为一对多关系。在第一范式（1NF）中表的每一行只包含一个实例的信息。简而言之，第一范式就是无重复的列。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1NF的定义为：符合1NF的关系中的每个属性都不可再分 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下表所示情况，便不符合1NF的要求： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;说明：在任何一个关系数据库中，第一范式（1NF）是对关系模式的基本要求，不满足第一范式（1NF）的数据库就不是关系数据库。 第二范式（2NF）属性完全依赖于主键&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第二范式（2NF）是在第一范式（1NF）的基础上建立起来的，即满足第二范式（2NF）必须先满足第一范式（1NF）。第二范式（2NF）要求数据库表中的每个实例或行必须可以被惟一地区分。为实现区分通常需要为表加上一个列，以存储各个实例的惟一标识。例如员工信息表中加上了员工编号（emp_id）列，因为每个员工的员工编号是惟一的，因此每个员工可以被惟一区分。这个惟一属性列被称为主关键字或主键、主码。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第二范式（2NF）要求实体的属性完全依赖于主关键字。所谓完全依赖是指不能存在仅依赖主关键字一部分的属性，如果存在，那么这个属性和主关键字的这一部分应该分离出来形成一个新的实体，新实体与原实体之间是一对多的关系。为实现区分通常需要为表加上一个列，以存储各个实例的惟一标识。简而言之，第二范式就是属性完全依赖于主键。 第三范式（3NF）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;满足第三范式（3NF）必须先满足第二范式（2NF）。简而言之，第三范式（3NF）要求一个数据库表中不包含已在其它表中已包含的非主关键字信息。例如，存在一个部门信息表，其中每个部门有部门编号（dept_id）、部门名称、部门简介等信息。那么在的员工信息表中列出部门编号后就不能再将部门名称、部门简介等与部门有关的信息再加入员工信息表中。如果不存在部门信息表，则根据第三范式（3NF）也应该构建它，否则就会有大量的数据冗余。简而言之，第三范式就是属性不依赖于其它非主属性。 也就是说， 如果存在非主属性对于码的传递函数依赖，则不符合3NF的要求。 I only need one partner: myself.]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>三大范式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈数据仓库建设中的数据建模方法]]></title>
    <url>%2F2019%2F09%2F22%2F%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%BB%BA%E8%AE%BE%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所谓水无定势，兵无常法。不同的行业，有不同行业的特点，因此，从业务角度看，其相应的数据模型是千差万别的。目前业界较为主流的是数据仓库厂商主要是 IBM 和 NCR，这两家公司的除了能够提供较为强大的数据仓库平台之外，也有各自的针对某个行业的数据模型。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;例如，在银行业，IBM 有自己的 BDWM(Banking data warehouse model)，而 NCR 有自己的 FS-LDM 模型。在电信业，IBM 有 TDWM（Telecom Data warehouse model），而 NCR 有自己的 TS-LDM 模型。因此，我们看到，不同的公司有自己针对某个行业的理解，因此会有不同的公司针对某个行业的模型。而对于不同的行业，同一个公司也会有不同的模型，这主要取决于不同行业的不同业务特点。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;举例来说，IBM 的 TDWM 的模型总共包含了以下 9 个概念，如下图： 图 1. IBM 的 TDWM 概念模型 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可能很多人要问，为什么你们的模型是 9 个概念而不是 10 个，11 个呢？你们的数据仓库模型的依据又是什么？其实这是我们在给客户介绍我们的数据模型时，经常被问到的一个问题，我希望读者在读完本文时，能够找到自己的答案。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然每个行业有自己的模型，但是，我们发现，不同行业的数据模型，在数据建模的方法上，却都有着共通的基本特点。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本文的主要目的之一，就是希望读者能够通过对本文的阅读，同时，结合自己对数据仓库建设的经验，在建设数据仓库的时候能够总结出一套适合自己的建模方法，能够更好的帮助客户去发挥数据仓库的作用。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本文主要的主线就是回答下面三个问题： 什么是数据模型? 为什么需要数据模型? 如何建设数据模型? &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最后，我们在本文的结尾给大家介绍了一个具体的数据仓库建模的样例，帮助大家来了解整个数据建模的过程。 一、什么是数据模型&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据模型是抽象描述现实世界的一种工具和方法，是通过抽象的实体及实体之间联系的形式，来表示现实世界中事务的相互关系的一种映射。在这里，数据模型表现的抽象的是实体和实体之间的关系，通过对实体和实体之间关系的定义和描述，来表达实际的业务中具体的业务关系。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库模型是数据模型中针对特定的数据仓库应用系统的一种特定的数据模型，一般的来说，我们数据仓库模型分为几下几个层次，如图 1 所示。 图 2. 数据仓库模型 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过上面的图形，我们能够很容易的看出在整个数据仓库的建模过程中，我们需要经历一般四个过程： - 业务建模，生成业务模型，主要解决业务层面的分解和程序化。 - 领域建模，生成领域模型，主要是对业务模型进行抽象处理，生成领域概念模型。 - 逻辑建模，生成逻辑模型，主要是将领域模型的概念实体以及实体之间的关系进行数据库层次的逻辑化。 - 物理建模，生成物理模型，主要解决，逻辑模型针对不同关系型数据库的物理化以及性能等一些具体的技术问题。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因此，在整个数据仓库的模型的设计和架构中，既涉及到业务知识，也涉及到了具体的技术，我们既需要了解丰富的行业经验，同时，也需要一定的信息技术来帮助我们实现我们的数据模型，最重要的是，我们还需要一个非常适用的方法论，来指导我们自己针对我们的业务进行抽象，处理，生成各个阶段的模型。 二、为什么需要数据模型&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在数据仓库的建设中，我们一再强调需要数据模型，那么数据模型究竟为什么这么重要呢？首先我们需要了解整个数据仓库的建设的发展史。 数据仓库的发展大致经历了这样的三个过程： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;简单报表阶段：这个阶段，系统的主要目标是解决一些日常的工作中业务人员需要的报表，以及生成一些简单的能够帮助领导进行决策所需要的汇总数据。这个阶段的大部分表现形式为数据库和前端报表工具。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据集市阶段：这个阶段，主要是根据某个业务部门的需要，进行一定的数据的采集，整理，按照业务人员的需要，进行多维报表的展现，能够提供对特定业务指导的数据，并且能够提供特定的领导决策数据。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库阶段：这个阶段，主要是按照一定的数据模型，对整个企业的数据进行采集，整理，并且能够按照各个业务部门的需要，提供跨部门的，完全一致的业务报表数据，能够通过数据仓库生成对业务具有指导性的数据，同时，为领导决策提供全面的数据支持。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过数据仓库建设的发展阶段，我们能够看出，数据仓库的建设和数据集市的建设的重要区别就在于数据模型的支持。因此，数据模型的建设，对于我们数据仓库的建设，有着决定性的意义。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一般来说，数据模型的建设主要能够帮助我们解决以下的一些问题： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;进行全面的业务梳理，改进业务流程。在业务模型建设的阶段，能够帮助我们的企业或者是管理机关对本单位的业务进行全面的梳理。通过业务模型的建设，我们应该能够全面了解该单位的业务架构图和整个业务的运行情况，能够将业务按照特定的规律进行分门别类和程序化，同时，帮助我们进一步的改进业务的流程，提高业务效率，指导我们的业务部门的生产。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;建立全方位的数据视角，消灭信息孤岛和数据差异。通过数据仓库的模型建设，能够为企业提供一个整体的数据视角，不再是各个部门只是关注自己的数据，而且通过模型的建设，勾勒出了部门之间内在的联系，帮助消灭各个部门之间的信息孤岛的问题，更为重要的是，通过数据模型的建设，能够保证整个企业的数据的一致性，各个部门之间数据的差异将会得到有效解决。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;解决业务的变动和数据仓库的灵活性。通过数据模型的建设，能够很好的分离出底层技术的实现和上层业务的展现。当上层业务发生变化时，通过数据模型，底层的技术实现可以非常轻松的完成业务的变动，从而达到整个数据仓库系统的灵活性。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;帮助数据仓库系统本身的建设。通过数据仓库的模型建设，开发人员和业务人员能够很容易的达成系统建设范围的界定，以及长期目标的规划，从而能够使整个项目组明确当前的任务，加快整个系统建设的速度。 三、如何建设数据模型&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;建设数据模型既然是整个数据仓库建设中一个非常重要的关键部分，那么，怎么建设我们的数据仓库模型就是我们需要解决的一个问题。这里我们将要详细介绍如何创建适合自己的数据模型。 数据仓库数据模型架构&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库的数据模型的架构和数据仓库的整体架构是紧密关联在一起的，我们首先来了解一下整个数据仓库的数据模型应该包含的几个部分。从下图我们可以很清楚地看到，整个数据模型的架构分成 5 大部分，每个部分其实都有其独特的功能。 图 3. 数据仓库数据模型架构 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从上图我们可以看出，整个数据仓库的数据模型可以分为大概 5 大部分： 系统记录域（System of Record）：这部分是主要的数据仓库业务数据存储区，数据模型在这里保证了数据的一致性。 内部管理域（Housekeeping）：这部分主要存储数据仓库用于内部管理的元数据，数据模型在这里能够帮助进行统一的元数据的管理。 汇总域（Summary of Area）：这部分数据来自于系统记录域的汇总，数据模型在这里保证了分析域的主题分析的性能，满足了部分的报表查询。 分析域（Analysis Area）：这部分数据模型主要用于各个业务部分的具体的主题业务分析。这部分数据模型可以单独存储在相应的数据集市中。 反馈域（Feedback Area）：可选项，这部分数据模型主要用于相应前端的反馈数据，数据仓库可以视业务的需要设置这一区域。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过对整个数据仓库模型的数据区域的划分，我们可以了解到，一个好的数据模型，不仅仅是对业务进行抽象划分，而且对实现技术也进行具体的指导，它应该涵盖了从业务到实现技术的各个部分。 数据仓库建模阶段划分&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们前面介绍了数据仓库模型的几个层次，下面我们讲一下，针对这几个层次的不同阶段的数据建模的工作的主要内容： 图 4. 数据仓库建模阶段划分 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从上图我们可以清楚地看出，数据仓库的数据建模大致分为四个阶段： 业务建模，这部分建模工作，主要包含以下几个部分： 划分整个单位的业务，一般按照业务部门的划分，进行各个部分之间业务工作的界定，理清各业务部门之间的关系。 深入了解各个业务部门的内具体业务流程并将其程序化。 提出修改和改进业务部门工作流程的方法并程序化。 数据建模的范围界定，整个数据仓库项目的目标和阶段划分。 领域概念建模，这部分的建模工作，主要包含以下几个部分： 抽取关键业务概念，并将之抽象化。 将业务概念分组，按照业务主线聚合类似的分组概念。 细化分组概念，理清分组概念内的业务流程并抽象化。 理清分组概念之间的关联，形成完整的领域概念模型。 逻辑建模，这部分的建模工作，主要包含以下几个部分： 业务概念实体化，并考虑其具体的属性 事件实体化，并考虑其属性内容 说明实体化，并考虑其属性内容 物理建模，这部分的建模工作，主要包含以下几个部分： 针对特定物理化平台，做出相应的技术调整 针对模型的性能考虑，对特定平台作出相应的调整 针对管理的需要，结合特定的平台，做出相应的调整 生成最后的执行脚本，并完善之。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从我们上面对数据仓库的数据建模阶段的各个阶段的划分，我们能够了解到整个数据仓库建模的主要工作和工作量，希望能够对我们在实际的项目建设能够有所帮助。 数据仓库建模方法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大千世界，表面看五彩缤纷，实质上，万物都遵循其自有的法则。数据仓库的建模方法同样也有很多种，每一种建模方法其实代表了哲学上的一个观点，代表了一种归纳，概括世界的一种方法。目前业界较为流行的数据仓库的建模方法非常多，这里主要介绍范式建模法，维度建模法，实体建模法等几种方法，每种方法其实从本质上讲就是从不同的角度看我们业务中的问题，不管从技术层面还是业务层面，其实代表的是哲学上的一种世界观。我们下面给大家详细介绍一下这些建模方法。 范式建模法（Third Normal Form，3NF） &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;范式建模法其实是我们在构建数据模型常用的一个方法，该方法的主要由 Inmon 所提倡，主要解决关系型数据库的数据存储，利用的一种技术层面上的方法。目前，我们在关系型数据库中的建模方法，大部分采用的是三范式建模法。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;范式是数据库逻辑模型设计的基本理论，一个关系模型可以从第一范式到第五范式进行无损分解，这个过程也可称为规范化。在数据仓库的模型设计中目前一般采用第三范式，它有着严格的数学定义。从其表达的含义来看，一个符合第三范式的关系必须具有以下三个条件 : 每个属性值唯一，不具有多义性 ; 每个非主属性必须完全依赖于整个主键，而非主键的一部分 ; 每个非主属性不能依赖于其他关系中的属性，因为这样的话，这种属性应该归到其他关系中去。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于范式是基于整个关系型数据库的理论基础之上发展而来的，因此，本人在这里不多做介绍，有兴趣的读者可以通过阅读相应的材料来获得这方面的知识。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据 Inmon 的观点，数据仓库模型的建设方法和业务系统的企业数据模型类似。在业务系统中，企业数据模型决定了数据的来源，而企业数据模型也分为两个层次，即主题域模型和逻辑模型。同样，主题域模型可以看成是业务模型的概念模型，而逻辑模型则是域模型在关系型数据库上的实例化。 图 5. 范式建模法 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从业务数据模型转向数据仓库模型时，同样也需要有数据仓库的域模型，即概念模型，同时也存在域模型的逻辑模型。这里，业务模型中的数据模型和数据仓库的模型稍微有一些不同。主要区别在于： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库的域模型应该包含企业数据模型的域模型之间的关系，以及各主题域定义。数据仓库的域模型的概念应该比业务系统的主题域模型范围更加广。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在数据仓库的逻辑模型需要从业务系统的数据模型中的逻辑模型中抽象实体，实体的属性，实体的子类，以及实体的关系等。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以笔者的观点来看，Inmon 的范式建模法的最大优点就是从关系型数据库的角度出发，结合了业务系统的数据模型，能够比较方便的实现数据仓库的建模。但其缺点也是明显的，由于建模方法限定在关系型数据库之上，在某些时候反而限制了整个数据仓库模型的灵活性，性能等，特别是考虑到数据仓库的底层数据向数据集市的数据进行汇总时，需要进行一定的变通才能满足相应的需求。因此，笔者建议读者们在实际的使用中，参考使用这一建模方式。 维度建模法 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;维度建模法，Kimball 最先提出这一概念。其最简单的描述就是，按照事实表，维表来构建数据仓库，数据集市。这种方法的最被人广泛知晓的名字就是星型模式（Star-schema）。 图 6. 维度建模法 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上图的这个架构中是典型的星型架构。星型模式之所以广泛被使用，在于针对各个维作了大量的预处理，如按照维进行预先的统计、分类、排序等。通过这些预处理，能够极大的提升数据仓库的处理能力。特别是针对 3NF 的建模方法，星型模式在性能上占据明显的优势。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;同时，维度建模法的另外一个优点是，维度建模非常直观，紧紧围绕着业务模型，可以直观的反映出业务模型中的业务问题。不需要经过特别的抽象处理，即可以完成维度建模。这一点也是维度建模的优势。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是，维度建模法的缺点也是非常明显的，由于在构建星型模式之前需要进行大量的数据预处理，因此会导致大量的数据处理工作。而且，当业务发生变化，需要重新进行维度的定义时，往往需要重新进行维度数据的预处理。而在这些与处理过程中，往往会导致大量的数据冗余。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;另外一个维度建模法的缺点就是，如果只是依靠单纯的维度建模，不能保证数据来源的一致性和准确性，而且在数据仓库的底层，不是特别适用于维度建模的方法。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因此以笔者的观点看，维度建模的领域主要适用与数据集市层，它的最大的作用其实是为了解决数据仓库建模中的性能问题。维度建模很难能够提供一个完整地描述真实业务实体之间的复杂关系的抽象方法。 实体建模法 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;实体建模法并不是数据仓库建模中常见的一个方法，它来源于哲学的一个流派。从哲学的意义上说，客观世界应该是可以细分的，客观世界应该可以分成由一个个实体，以及实体与实体之间的关系组成。那么我们在数据仓库的建模过程中完全可以引入这个抽象的方法，将整个业务也可以划分成一个个的实体，而每个实体之间的关系，以及针对这些关系的说明就是我们数据建模需要做的工作。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然实体法粗看起来好像有一些抽象，其实理解起来很容易。即我们可以将任何一个业务过程划分成 3 个部分，实体，事件和说明，如下图所示： 图 7. 实体建模法 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上图表述的是一个抽象的含义，如果我们描述一个简单的事实：“小明开车去学校上学”。以这个业务事实为例，我们可以把“小明”，“学校”看成是一个实体，“上学”描述的是一个业务过程，我们在这里可以抽象为一个具体“事件”，而“开车去”则可以看成是事件“上学”的一个说明。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从上面的举例我们可以了解，我们使用的抽象归纳方法其实很简单，任何业务可以看成 3 个部分： 实体，主要指领域模型中特定的概念主体，指发生业务关系的对象。 事件，主要指概念主体之间完成一次业务流程的过程，特指特定的业务过程。 说明，主要是针对实体和事件的特殊说明。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于实体建模法，能够很轻松的实现业务模型的划分，因此，在业务建模阶段和领域概念建模阶段，实体建模法有着广泛的应用。从笔者的经验来看，在没有现成的行业模型的情况下，我们可以采用实体建模的方法，和客户一起理清整个业务的模型，进行领域概念模型的划分，抽象出具体的业务概念，结合客户的使用特点，完全可以创建出一个符合自己需要的数据仓库模型来。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是，实体建模法也有着自己先天的缺陷，由于实体说明法只是一种抽象客观世界的方法，因此，注定了该建模方法只能局限在业务建模和领域概念建模阶段。因此，到了逻辑建模阶段和物理建模阶段，则是范式建模和维度建模发挥长处的阶段。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因此，笔者建议读者在创建自己的数据仓库模型的时候，可以参考使用上述的三种数据仓库的建模方法，在各个不同阶段采用不同的方法，从而能够保证整个数据仓库建模的质量。 四、数据仓库建模样例&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上面介绍的是一些抽象的建模方法和理论，可能理解起来相对有些难度，因此，笔者在这里举一个例子，读者可以跟着我们的这个样例，来初步了解整个数据仓库建模的大概过程。 背景介绍&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;熟悉社保行业的读者可以知道，目前我们国家的社保主要分为养老，失业，工伤，生育，医疗保险和劳动力市场这 6 大块主要业务领域。在这 6 大业务领域中，目前的状况养老和事业的系统已经基本完善，已经有一部分数据开始联网检测。而对于工伤，生育，医疗和劳动力市场这一块业务，有些地方发展的比较成熟，而有些地方还不够成熟。 业务建模阶段&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基于以上的背景介绍，我们在业务建模阶段，就很容易来划分相应的业务。因此，在业务建模阶段，我们基本上确定我们本次数据仓库建设的目标，建设的方法，以及长远规划等。如下图： 图 8. 业务建模阶段 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这里，我们将整个业务很清楚地划分成了几个大的业务主线，例如：养老，失业，工伤，生育，医疗，劳动力等着几个大的部分，然后我们可以根据这些大的模块，在每个业务主线内，考虑具体的业务主线内需要分析的业务主题。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因此，业务建模阶段其实是一次和业务人员梳理业务的过程，在这个过程中，不仅能帮助我们技术人员更好的理解业务，另一方面，也能够发现业务流程中的一些不合理的环节，加以改善和改进。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;同时，业务建模阶段的另一个重要工作就是确定我们数据建模的范围，例如：在某些数据准备不够充分的业务模块内，我们可以考虑先不建设相应的数据模型。等到条件充分成熟的情况下，我们可以再来考虑数据建模的问题。 领域概念建模阶段&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;领域概念建模阶段是数据仓库数据建模的一个重要阶段，由于我们在业务建模阶段已经完全理清相应的业务范围和流程，因此，我们在这个领域概念建模阶段的最主要的工作就是进行概念的抽象，整个领域概念建模的工作层次如下图所示： 图 9. 领域概念建模阶段 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从上图我们可以清楚地看到，领域概念建模就是运用了实体建模法，从纷繁的业务表象背后通过实体建模法，抽象出实体，事件，说明等抽象的实体，从而找出业务表象后抽象实体间的相互的关联性，保证了我们数据仓库数据按照数据模型所能达到的一致性和关联性。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从图上看，我们可以把整个抽象过程分为四个层次，分别为： 抽象方法层，整个数据模型的核心方法，领域概念建模的实体的划分通过这种抽象方法来实现。 领域概念层，这是我们整个数据模型的核心部分，因为不同程度的抽象方法，决定了我们领域概念的不同。例如：在这里，我们可以使用“参与方”这个概念，同时，你也可以把他分成三个概念：“个人”，“公司”，和“经办机构”这三个概念。而我们在构建自己的模型的时候，可以参考业务的状况以及我们自己模型的需要，选择抽象程度高的概念或者是抽象程度低的概念。相对来说，抽象程度高的概念，理解起来较为复杂，需要专业的建模专家才能理解，而抽象程度低的概念，较适合于一般业务人员的理解，使用起来比较方便。笔者在这里建议读者可以选用抽象概念较低的实体，以方便业务人员和技术人员之间的交流和沟通。 具体业务层，主要是解决具体的业务问题，从这张图我们可以看出，具体的业务层，其实只是领域概念模型中实体之间的一些不同组合而已。因此，完整的数据仓库的数据模型应该能够相应灵活多变的前端业务的需求，而其本身的模型架构具有很强的灵活性。这也是数据仓库模型所具备的功能之一。 业务主线层，这个层次主要划分大的业务领域，一般在业务建模阶段即已经完成这方面的划分。我们一般通过这种大的业务主线来划分整个业务模型大的框架。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过领域概念建模，数据仓库的模型已经被抽象成一个个的实体，模型的框架已经搭建完毕，下面的工作就是给这些框架注入有效的肌体。 逻辑建模阶段&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过领域概念建模之后，虽然模型的框架已经完成，但是还有很多细致的工作需要完成。一般在这个阶段，我们还需要做非常多的工作，主要包括：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;实例化每一个抽象的实体，例如：在上面的概念模型之后，我们需要对“人”和“公司”等这些抽象实体进行实例化。主要是，我们需要考虑“人”的属性包括那些，在业务模块中，用到的所有跟“人”相关的属性是哪些，我们都需要将这些属性附着在我们数据模型的“人”这个实体上，例如“人”的年龄，性别，受教育程度等等。同理，我们对其他属性同样需要做这个工作。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;找出抽象实体间的联系，并将其实例化。这里，我们主要考虑是“事件”这个抽象概念的实例化，例如：对于养老金征缴这个“事件”的属性的考虑，对于失业劳动者培训这个“事件”的属性的考虑等等。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;找出抽象事件的关系，并对其进行说明。在这里我们主要是要针对“事件”进行完善的“说明”。例如：对于“事件”中的地域，事件等因素的考量等等。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;总而言之，在逻辑建模阶段，我们主要考虑的是抽象实体的一些细致的属性。通过逻辑建模阶段，我们才能够将整个概念模型完整串联成一个有机的实体，才能够完整的表达出业务之间的关联性。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这个阶段，笔者建议大家可以参考 3NF 的建模方法，表达出实体的属性，以及实体与实体之间的联系。例如：在这个阶段，我们可以通过采用 ERWIN 等建模工具等作出符合 3NF 的关系型数据模型来。 物理建模阶段&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;物理建模阶段是整个数据建模的最后一个过程，这个过程其实是将前面的逻辑数据模型落地的一个过程。考虑到数据仓库平台的不同，因此，数据模型的物理建模过程可能会稍微有一些不同，在这个阶段我们主要的工作是： 生成创建表的脚本。不同的数据仓库平台可能生成不同的脚本。 针对不同的数据仓库平台，进行一些相应的优化工作，例如对于 DB2 数据仓库来说，创建一些 MQT 表（数据库中的视图view的概念，不过MQT会将数据存储起来，而不是直接查询源表），来加速报表的生成等等。 针对数据集市的需要，按照维度建模的方法，生成一些事实表，维表等工作。 针对数据仓库的 ETL 车和元数据管理的需要，生成一些数据仓库维护的表，例如：日志表等。 经过物理建模阶段，整个数据仓库的模型已经全部完成，我们可以按照自己的设计来针对当前的行业创建满足自己需要的数据模型来。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里，笔者通过一个数据建模的样例，希望能够给读者一个关于数据仓库建模的感性的认识。希望读者在利用这些数据仓库的建模方法创建自己的数据模型的时候，可以根据业务实际的需要和自己对抽象能力的把握来创建适合自己的数据模型。 参考资料： 用 Rational Data Architect 简化数据建模和集成设计。 通过访问 IM 和 Rational 集成应用开发专栏 获得更多建模方面的文章、教程和多媒体课件等的技术资源。 通过访问 developerWorks IM 专区 获得更多文章、教程和多媒体课件等的技术资源。 通过参与 developerWorks blog 加入 developerWorks 社区。 原文链接：数据仓库模型建设 Work, do your one hundred percent,eat, eat,laugh, laugh]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>数据仓库</tag>
        <tag>模型设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据仓库元数据管理系统]]></title>
    <url>%2F2019%2F09%2F21%2F%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%85%83%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;相信很多朋友都是第一次听说元数据管理系统这个名词，当然，从事非数据仓库工作的人，很少会接触到这个系统，即使是正在从事这方面工作的朋友，可能仍然对它不是很了解，那么今天我来聊一聊元数据管理系统。本文大部分观点与图片汇总字网络，如有不同观点，欢迎留言交流～～ . 一、元数据的定义&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;按照传统的定义，元数据（Metadata）是关于数据的数据。在数据仓库系统中，元数据可以帮助数据仓库管理员和数据仓库的开发人员非常方便地找到他们所关心的数据；元数据是描述数据仓库内数据的结构和建立方法的数据，可将其按用途的不同分为两类：技术元数据（Technical Metadata）和业务元数据（Business Metadata）。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;技术元数据是存储关于数据仓库系统技术细节的数据，是用于开发和管理数据仓库使用的数据，它主要包括以下信息： 数据仓库结构的描述，包括仓库模式、视图、维、层次结构和导出数据的定义，以及数据集市的位置和内容； 业务系统、数据仓库和数据集市的体系结构和模式； 汇总用的算法，包括度量和维定义算法，数据粒度、主题领域、聚集、汇总、预定义的查询与报告； 由操作环境到数据仓库环境的映射，包括源数据和它们的内容、数据分割、数据提取、清理、转换规则和数据刷新规则、安全（用户授权和存取控制）。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;业务元数据从业务角度描述了数据仓库中的数据，它提供了介于使用者和实际系统之间的语义层，使得不懂计算机技术的业务人员也能够“读懂”数据仓库中的数据。业务元数据主要包括以下信息：使用者的业务术语所表达的数据模型、对象名和属性名；访问数据的原则和数据的来源；系统所提供的分析方法以及公式和报表的信息；具体包括以下信息： 企业概念模型：这是业务元数据所应提供的重要的信息，它表示企业数据模型的高层信息、整个企业的业务概念和相互关系。以这个企业模型为基础，不懂数据库技术和SQL语句的业务人员对数据仓库中的数据也能做到心中有数。 多维数据模型：这是企业概念模型的重要组成部分，它告诉业务分析人员在数据集市当中有哪些维、维的类别、数据立方体以及数据集市中的聚合规则。这里的数据立方体表示某主题领域业务事实表和维表的多维组织形式。 业务概念模型和物理数据之间的依赖：以上提到的业务元数据只是表示出了数据的业务视图，这些业务视图与实际的数据仓库或数据库、多维数据库中的表、字段、维、层次等之间的对应关系也应该在元数据知识库中有所体现。 二、元数据的作用&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;与其说数据仓库是软件开发项目，还不如说是系统集成项目，因为它的主要工作是把所需的数据仓库工具集成在一起，完成数据的抽取、转换和加载，OLAP分析和数据挖掘等。如下图所示，它的典型结构由操作环境层、数据仓库层和业务层等组成。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中，第一层（操作环境层）是指整个企业内有关业务的OLTP系统和一些外部数据源；第二层是通过把第一层的相关数据抽取到一个中心区而组成的数据仓库层；第三层是为了完成对业务数据的分析而由各种工具组成的业务层。图中左边的部分是元数据管理，它起到了承上启下的作用，具体体现在以下几个方面： 1.元数据是进行数据集成所必需的&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库最大的特点就是它的集成性。这一特点不仅体现在它所包含的数据上，还体现在实施数据仓库项目的过程当中。一方面，从各个数据源中抽取的数据要按照一定的模式存入数据仓库中，这些数据源与数据仓库中数据的对应关系及转换规则都要存储在元数据知识库中；另一方面，在数据仓库项目实施过程中，直接建立数据仓库往往费时、费力，因此在实践当中，人们可能会按照统一的数据模型，首先建设数据集市，然后在各个数据集市的基础上再建设数据仓库。不过，当数据集市数量增多时很容易形成“蜘蛛网”现象，而元数据管理是解决“蜘蛛网”的关键。如果在建立数据集市的过程中，注意了元数据管理，在集成到数据仓库中时就会比较顺利；相反，如果在建设数据集市的过程中忽视了元数据管理，那么最后的集成过程就会很困难，甚至不可能实现。 2.元数据定义的语义层可以帮助用户理解数据仓库中的数据&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最终用户不可能象数据仓库系统管理员或开发人员那样熟悉数据库技术，因此迫切需要有一个“翻译”，能够使他们清晰地理解数据仓库中数据的含意。元数据可以实现业务模型与数据模型之间的映射，因而可以把数据以用户需要的方式“翻译”出来，从而帮助最终用户理解和使用数据。 3.元数据是保证数据质量的关键&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库或数据集市建立好以后，使用者在使用的时候，常常会产生对数据的怀疑。这些怀疑往往是由于底层的数据对于用户来说是不“透明”的，使用者很自然地对结果产生怀疑。而借助元数据管理系统，最终的使用者对各个数据的来龙去脉以及数据抽取和转换的规则都会很方便地得到，这样他们自然会对数据具有信心；当然也可便捷地发现数据所存在的质量问题。甚至国外有学者还在元数据模型的基础上引入质量维，从更高的角度上来解决这一问题。 4.元数据可以支持需求变化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;随着信息技术的发展和企业职能的变化，企业的需求也在不断地改变。如何构造一个随着需求改变而平滑变化的软件系统，是软件工程领域中的一个重要问题。传统的信息系统往往是通过文档来适应需求变化，但是仅仅依靠文档还是远远不够的。成功的元数据管理系统可以把整个业务的工作流、数据流和信息流有效地管理起来，使得系统不依赖特定的开发人员，从而提高系统的可扩展性。 三、元数据管理功能 1.数据地图&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据地图展现是以拓扑图的形式对数据系统的各类数据实体、数据处理过程元数据进行分层次的图形化展现，并通过不同层次的图形展现粒度控制，满足开发、运维或者业务上不同应用场景的图形查询和辅助分析需要。 2.元数据分析2.1 血缘分析&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;血缘分析（也称血统分析）是指从某一实体出发，往回追溯其处理过程，直到数据系统的数据源接口。对于不同类型的实体，其涉及的转换过程可能有不同类型，如：对于底层仓库实体，涉及的是ETL处理过程；而对于仓库汇总表，可能既涉及ETL处理过程，又涉及仓库汇总处理过程；而对于指标，则除了上面的处理过程，还涉及指标生成的处理过程。数据源接口实体由源系统提供，作为数据系统的数据输入，其它的数据实体都经过了一个或多个不同类型的处理过程。血缘分析正是提供了这样一种功能，可以让使用者根据需要了解不同的处理过程，每个处理过程具体做什么，需要什么样的输入，又产生什么样的输出。 2.2 影响分析&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;影响分析是指从某一实体出发，寻找依赖该实体的处理过程实体或其他实体。如果需要可以采用递归方式寻找所有的依赖过程实体或其他实体。该功能支持当某些实体发生变化或者需要修改时，评估实体影响范围。 2.3 实体关联分析&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;实体关联分析是从某一实体关联的其它实体和其参与的处理过程两个角度来查看具体数据的使用情况，形成一张实体和所参与处理过程的网络，从而进一步了解该实体的重要程度。本功能可以用来支撑需求变更影响评估的应用。 2.4 实体差异分析&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;实体差异分析是对元数据的不同实体进行检查，用图形和表格的形式展现它们之间的差异，包括名字、属性及数据血缘和对系统其他部分影响的差异等,在数据系统中存在许多类似的实体。这些实体（如数据表）可能只有名字上或者是在属性中存在微小的差异，甚至有部分属性名字都相同，但处于不同的应用中。由于各种原因，这些微小的差异直接影响了数据统计结果，数据系统需要清楚了解这些差异。本功能有助于进一步统一统计口径，评估近似实体的差异 2.5 指标一致性分析&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;指标一致性分析是指用图形化的方式来分析比较两个指标的数据流图是否一致，从而了解指标计算过程是否一致。该功能是指标血缘分析的一种具体应用。指标一致性分析可以帮助用户清楚地了解到将要比较的两个指标在经营分析数据流图中各阶段所涉及的数据对象和转换关系是否一致，帮助用户更好地了解指标的来龙去脉，清楚理解分布在不同部门且名称相同的指标之间的差异，从而提高用户对指标值的信任。 3.辅助应用优化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;元数据对数据系统的数据、数据加工过程以及数据间的关系提供了准确的描述，利用血缘分析、影响分析和实体关联分析等元数据分析功能，可以识别与系统应用相关的技术资源，结合应用生命周期管理过程，辅助进行数据系统的应用优化. 4.辅助安全管理&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;企业数据平台所存储的数据和提供的各类分析应用，涉及到公司经营方面的各类敏感信息。因此在数据系统建设过程中，须采用全面的安全管理机制和措施来保障系统的数据安全。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据系统安全管理模块负责数据系统的数据敏感度、客户隐私信息和各环节审计日志记录管理，对数据系统的数据访问和功能使用进行有效监控。为实现数据系统对敏感数据和客户隐私信息的访问控制，进一步实现权限细化，安全管理模块应以元数据为依据，由元数据管理模块提供敏感数据定义和客户隐私信息定义，辅助安全管理模块完成相关安全管控操作。 5.基于元数据的开发管理&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据系统项目开发的主要环节包括：需求分析、设计、开发、测试和上线。开发管理应用可以提供相应的功能，对以上各环节的工作流程、相关资源、规则约束、输入输出信息等提供管理和支持。 End～ I will be your side till the day i die.]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>数据仓库</tag>
        <tag>元数据管理系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[P2P（PeerToPeer）网络原理]]></title>
    <url>%2F2019%2F09%2F18%2FP2P%EF%BC%88PeerToPeer%EF%BC%89%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最近在研究P2P技术，奈何相关资料不多，自己琢磨了一下，分享一下学习P2P的一些原理, 以及如何打造一个P2P聊天应用。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里指的P2P是指peer to peer， 点对点的技术， 每个客户端都是服务端，没有中心服务器，不是websocket针对某个connection推送消息。 一、技术要点 udp协议 节点之间的建立，连接和广播 内网穿透，如何能让两个处在内网的节点，相互发现自己的存在，并且建立通信 二、原理&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先解决的是内网穿透的问题，常见的底层协议tcp，udp，他们各自有优缺点，简单说明一下。 tcp：需要处理粘包问题，双工流通道，是可靠的链接。 udp： 每次发送的都是数据包，没有粘包问题，但是连接不可靠，只能传输少量数据。更加详细的请Google &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里选择udp协议，简单一些。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;再下来是内网穿透，先说结论： 两个处于不同内部网络的节点，永远无法发现他们之间的相互存在，你就算是想顺着网线过去打他都不行。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所有的内网穿透原理无外乎需要一个有公网ip的中介服务器，包括虚拟货币像比特币之类的，所以首先要有一个创世节点 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在NodeJS中，创建udp服务也很简单 123const dgram = require(&quot;dgram&quot;);const udp = dgram.createSocket(&quot;udp4&quot;);udp.bind(1090, callback) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;把服务部署要公网，那么其他所有的节点都能访问，通过中转服务器，能够使得两个节点可以建立连接 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们是要建立这样的P2P网络 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假如现在只有3个节点： 创世节点, B节点, C节点， 创世节点有公网IP &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我用对话的形式，阐述他们建立链接的过程: B节点: hey，创世节点，我要加入到P2P网络里面，告诉其他兄弟，我来了 创世节点: 兄弟们，刚刚有个叫做B的节点加入网络了，你们也去告诉其他节点 其他节点: 刚刚收到来自 “创世节点”的通知，有个fresh meet加入网络了，叫做 “B” … 至此，所有人都知道了B节点加入了网络，里面记载着B节点的相关信息，包括IP地址，包括udp端口号 此时C节点也要加入网络，并且想要和B节点对话: C节点: hey，创世节点，我要加入到P2P网络里面，并且我要和B对话 创世节点: 兄弟们，刚刚有个叫做B的节点加入网络了，你们也去告诉其他节点，顺便看看有没有B这个节点 其他节点: 刚刚收到来自 “创世节点”的通知，有个fresh meet加入网络了，叫做 “C”，你们也看看有没有B这个节点 其他节点2: 收到通知，听说一个叫做C的节点在找一个B节点，我这里有它的信息，ip是xxxx.xxxx.xxx.xxxx, 端口10086 B节点: 有个C的家伙(ip: xxxx.xxxx.xxxx.xxxx, 端口1000)要找我 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;到这里，B获取到了C的信息，包括IP和端口，C也拿到了B的信息. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;于是，他们两个就可以建立通信。消息流: B &lt;—-&gt; C. 中间不经过任何服务器 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;用一张图来形容: 三、总结&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在设计中，每个节点的功能都是一样的。如果需要加入到网络中，不一定跟创世节点链接 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设已存在的节点: 创世节点，A、B、C节点，此时有个D节点想要加入到网络。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;那么D节点不一定非得链接到创世节点，可以链接到A、B、C中的任意一个节点，然后该节点再广播给其他节点说”Hey, 有个新人叫做D的加入了网络”。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这样所有人都知道，有个叫做D的节点存在，你可以和它通信，同时D节点和会同步已存在的节点。这样D节点也知道了其他节点的存在了。 找到自己感兴趣的事情，然后100%投入。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>P2P网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据仓库模型设计]]></title>
    <url>%2F2019%2F09%2F17%2F%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大千世界，万物都有其遵循的自有法则，数据仓库也不例外，根据业务场景，选择不同的设计模式，解决不同的业务问题。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下面来看看数据仓库的三种设计模式。 一、范式建模法（Third Normal Form，3NF）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;范式建模法其实是我们在构建数据模型常用的一个方法，该方法的主要由 Inmon 所提倡，主要解决关系型数据库得数据存储，利用的一种技术层面上的方法。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;目前，我们在关系型数据库中的建模方法，大部分采用的是三范式建模法。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;范式是数据库逻辑模型设计的基本理论，一个关系模型可以从第一范式到第五范式进行无损分解，这个过程也可称为规范化。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在数据仓库的模型设计中目前一般采用第三范式，它有着严格的数学定义。从其表达的含义来看，一个符合第三范式的关系必须具有以下三个条件 : 1.每个属性值唯一，不具有多义性 ;2.每个非主属性必须完全依赖于整个主键，而非主键的一部分 ;3.每个非主属性不能依赖于其他关系中的属性，因为这样的话，这种属性应该归到其他关系中去。 优点： 从关系型数据库的角度出发，结合了业务系统的数据模型，能够比较方便的实现数据仓库的建模。 缺点： 由于建模方法限定在关系型数据库之上，在某些时候反而限制了整个数据仓库模型的灵活性，性能等，特别是考虑到数据仓库的底层数据向数据集市的数据进行汇总时，需要进行一定的变通才能满足相应的需求。 二、维度建模法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;维度建模法，Kimball 最先提出这一概念。其最简单的描述就是，按照事实表，维表来构建数据仓库，数据集市。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;事实表是用来记录具体事件的，包含了每个事件的具体要素，以及具体发生的事情；维表则是对事实表中事件的要素的描述信息。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;比如一个事件会包含时间、地点、人物、事件，事实表记录了整个事件的信息，但对时间、地点和人物等要素只记录了一些关键标记，比如事件的主角叫“Michael”，那么Michael到底“长什么样”，就需要到相应的维表里面去查询“Michael”的具体描述信息了。 优点: 1.维度建模非常直观，紧紧围绕着业务模型，可以直观的反映出业务模型中的业务问题。2.不需要经过特别的抽象处理，即可以完成维度建模。这一点也是维度建模的优势。 缺点: 1.由于在构建星型模式之前需要进行大量的数据预处理，因此会导致大量的数据处理工作。2.而且，当业务发生变化，需要重新进行维度的定义时，往往需要重新进行维度数据的预处理。而在这些与处理过程中，往往会导致大量的数据冗余。3.如果只是依靠单纯的维度建模，不能保证数据来源的一致性和准确性，而且在数据仓库的底层，不是特别适用于维度建模的方法。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因此以笔者的观点看，维度建模的领域主要适用与数据集市层，它的最大的作用其实是为了解决数据仓库建模中的性能问题。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;维度建模很难能够提供一个完整地描述真实业务实体之间的复杂关系的抽象方法。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基于事实表和维表就可以构建出多种多维模型，包括星形模型、雪花模型和星座模型。 1.星型模式（Star-schema）。星型模式的核心是一个大的中心表（事实表），一组小的附属表（维表）。星型模式示例如下所示： 可以看出，星形模式的维度建模由一个事实表和一组维表成，且具有以下特点： a. 维表只和事实表关联，维表之间没有关联；b. 每个维表的主码为单列，且该主码放置在事实表中，作为两边连接的外码；c. 以事实表为核心，维表围绕核心呈星形分布； 2.雪花模型&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;雪花模式是星型模式的扩展，其中某些维表被规范化，进一步分解到附加表（维表）中。雪花模式示例如下图所示： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从图中我们可以看到地址表被进一步细分出了城市（city）维。supplier_type表被进一步细分出来supplier维。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;星形模式中的维表相对雪花模式来说要大，而且不满足规范化设计。雪花模型相当于将星形模式的大维表拆分成小维表，满足了规范化设计。然而这种模式在实际应用中很少见，因为这样做会导致开发难度增大，而数据冗余问题在数据仓库里并不严重。 3.星座模型&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库由多个主题构成，包含多个事实表，而维表是公共的，可以共享，这种模式可以看做星型模式的汇集，因而称作星系模式或者事实星座模式。本模式示例如下图所示： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如上图所示，事实星座模式包含两个事实表：sales和shipping，二者共享维表。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;事实星座模式是数据仓库最常使用的数据模式，尤其是企业级数据仓库（EDW）。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;前面介绍的两种维度建模方法都是多维表对应单事实表，但在很多时候维度空间内的事实表不止一个，而一个维表也可能被多个事实表用到。在业务发展后期，绝大部分维度建模都采用的是星座模式。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这也是数据仓库区别于数据集市的一个典型的特征，从根本上而言，数据仓库数据模型的模式更多是为了避免冗余和数据复用，套用现成的模式，是设计数据仓库最合理的选择。 4.三种模式对比 三、实体建模法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;实体建模法并不是数据仓库建模中常见的一个方法，它来源于哲学的一个流派。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;那么我们在数据仓库的建模过程中完全可以引入这个抽象的方法，将整个业务也可以划分成一个个的实体，而每个实体之间的关系，以及针对这些关系的说明就是我们数据建模需要做的工作。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;即我们可以将任何一个业务过程划分成 3 个部分，实体，事件和说明。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;例如我们描述一个简单的事实：“小明开车去学校上学”。以这个业务事实为例，我们可以把“小明”，“学校”看成是一个实体，“上学”描述的是一个业务过程，我们在这里可以抽象为一个具体“事件”，而“开车去”则可以看成是事件“上学”的一个说明。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从上面的举例我们可以了解，我们使用的抽象归纳方法其实很简单，任何业务可以看成 3 个部分： 1.实体，主要指领域模型中特定的概念主体，指发生业务关系的对象。2.事件，主要指概念主体之间完成一次业务流程的过程，特指特定的业务过程。3.说明，主要是针对实体和事件的特殊说明。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于实体建模法，能够很轻松的实现业务模型的划分，因此，在业务建模阶段和领域概念建模阶段，实体建模法有着广泛的应用。从笔者的经验来看，再没有现成的行业模型的情况下，我们可以采用实体建模的方法，和客户一起理清整个业务的模型，进行领域概念模型的划分，抽象出具体的业务概念，结合客户的使用特点，完全可以创建出一个符合自己需要的数据仓库模型来。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但是，实体建模法也有着自己先天的缺陷，由于实体说明法只是一种抽象客观世界的方法，因此，注定了该建模方法只能局限在业务建模和领域概念建模阶段。因此，到了逻辑建模阶段和物理建模阶段，则是范式建模和维度建模发挥长处的阶段。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因此，笔者建议读者在创建自己的数据仓库模型的时候，可以参考使用上述的三种数据仓库得建模方法，在各个不同阶段采用不同的方法，从而能够保证整个数据仓库建模的质量。 实践才是检验真理的唯一标准]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>数据仓库模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库、数据仓库、数据集市的区别与联系]]></title>
    <url>%2F2019%2F09%2F17%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E3%80%81%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E3%80%81%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B8%82%E7%9A%84%E5%8C%BA%E5%88%AB%E4%B8%8E%E8%81%94%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据库（Database）：按照数据结构来组织、存储、管理数据，建立在计算机存储设备上面的仓库。数据库一般适用于操作型系统。因为符合三范式的设置，数据的一致性较好。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库(Data Warehouse) 是一个面向主题的(SubjectOri2ented) 、集成的(Integrate) 、相对稳定的(Non -Volatile) 、反映历史变化(TimeVariant) 的数据集合用于支持管理决策。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据集市（Data Market）：数据集市不同于数据仓库，一般是服务于某几个部门。数据仓库向各个数据集市提供数据，且一般来讲，数据仓库的表设计符合规范化设计，而数据集市一般使用维度建模。 一、数据库&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;按照数据结构来组织、存储、管理数据的建立在计算机存储设备上面的仓库。数据库一般适用于操作型系统。因为符合三范式的设置，数据的一致性较好。 二、数据仓库&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库(Data Warehouse) 是一个面向主题的(SubjectOri2ented) 、集成的( Integrate ) 、相对稳定的(Non -Volatile ) 、反映历史变化( TimeVariant) 的数据集合用于支持管理决策。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个定义比较系统地阐述了数据仓库的特点，下面我们一一解读。 1. 面向主题的&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库是为了提供决策服务的，会建立不同的主题，而主题是进行决策时需要重点关注的部分。 2. 集成的&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库可以整合来自不同数据源的数据，将这个数据入库、清洗整合成统一的标准化数据。同时上文中提到的一个主题往往与多个系统相关，集成的数据很好的满足了主题构建的数据需求。数据仓库对原有的分散的数据库进行数据抽取、清理的基础上经过系统加工、汇总整理得到，清除原数据中的不一致性（面向事务的数据库往往单独存放单个系统的数据，且不同数据库相互独立，且是异构的）。 3. 相对稳定的&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库的数据面向决策，这就表明了仓库中的数据进入之后就会长期保留，主要面对的是查询， 修改与删除操作比较少，一般是定期的加载、更新。 4. 反映历史变化的&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据仓库中会保存各个日期节点的数据，以满足不断变化的业务的需求。 三、数据集市&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据集市不同于数据仓库，一般是服务于某几个部门。数据仓库向各个数据集市提供数据，且一般来讲，数据仓库的表设计符合规范化设计，而数据集市一般使用维度建模。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;请看下图： 四、总结&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于操作型系统，我们希望数据便于修改、满足一致性，因此产生了三范式数据库；在面对企业级决策需求的数据支撑时，我们希望系统可以集成不同的数据源的数据、数据稳定、结构统一、保存历史数据，可以满足不同部门的不断变化的数据系统，因此产生了数据仓库；对于不同的部门来讲，进行决策时如果直接访问数据仓库，得到信息需要多张表进行关联，访问压力大，且主题繁多不易于管理。因此需要建立数据集市，从数据仓库中直接取数，对数据进行汇总整理以满足特定部门的需求。 仰望星空，脚踏实地]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>数据仓库</tag>
        <tag>数据集市</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[零知识证明]]></title>
    <url>%2F2019%2F09%2F16%2F%E9%9B%B6%E7%9F%A5%E8%AF%86%E8%AF%81%E6%98%8E%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;零知识证明（Zero-Knowledge Proof）或零知识协议是一种基于概率的验证方法，包括两部分：宣称某一命题为真的证明者（prover）和确认该命题确实为真的验证者（verifier）。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;零知识证明指的是证明者能够在不向验证者提供任何有用的信息的情况下，使验证者相信某个论断是正确的，在密码学中非常有用。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;顾名思义，零知识证明就是既能充分证明自己是某种权益的合法拥有者，又不把有关的信息泄漏出去，即给外界的 “知识” 为“零”。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;“能够在不知道用户是谁，或者他们有多少钱的情况下判断‘一个用户是否有足够的钱发送给另一个用户’的问题，是零知识证明在区块链中的主要应用之一。”——Demiro Massessi 1.为何零知识证明如此重要？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据隐私是当今社会最重要的课题之一。保护与个人身份有关的个人资料 (出生日期、银行月结单、交易记录、学历) 极为重要，并会不断增加其重要性。在科技时代，我们正在生成前所未有的海量数据，而我们不断创造的关于我们自己的数据也在不断被获取。像谷歌和 Facebook 这样的大公司已经利用我们的数据成为了今天主宰世界的科技巨头。然而，最近密码学的突破和区块链的兴起使一种新的方法能够帮助保护我们的数据和身份，甚至保护我们与之交互的组织。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;零知识证明可能就是如何保护数据隐私的答案。 2.零知识证明的原则&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;零知识证明是麻省理工学院研究人员在 20 世纪 80 年代提出的一种加密方案。零知识证明协议是一方 (证明者) 向另一方证明 (验证者) 某件事情是真实的一种方法。除了该特定声明是真实的以外，没有披露任何其他信息。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;例如，当前网站将用户密码的哈希值存储在其 web 服务器中。为了验证客户端是否真的知道密码，大多数网站目前使用的方法是对客户端输入的密码进行哈希值计算，并将其与存储的结果进行比较。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;零知识证明可以保护用户的帐号信息不被泄露。如果零知识证明可以实现，那么在客户的密码是未知的情况下，仍然可以在客户端登录进行身份验证。当服务器受到攻击时，用户的帐户仍然是安全的，因为客户的密码没有存储在 web 服务器中。 3.交互式零知识证明&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;零知识证明协议的基础是交互式的。它要求验证者不断地提出一系列关于证明者所知道的 “知识” 的问题。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;例如，如果有人声称知道九宫格谜题的答案，零知识证明就是验证者随机指定按列、行或九个正方形进行验证。每个测试不需要知道具体的答案，只需要检测数字 “1” 到“9”是否包含在其内。只要验证的次数足够多，就有可能判断证明者是否知道九宫格谜题的答案。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;然而，这种简单的验证方式并不能使人们相信证明者和验证者都未做伪证。在九宫格游戏中，两者可能会事先串通，以便证明者在不知道答案的情况下通过验证。如果他们想说服第三方相信这个结果，验证者还必须证明验证过程是随机的，并且它不会将答案泄露给证明者。因此，第三方很难验证交互零知识证明的结果，需要第三方的参与，等额外的努力和成本才能向多人证明某件事是真实的。 4.非交互式零知识证明&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;非交互式零知识证明，顾名思义，不需要交互式过程，避免了验证者和证明者串通的可能性，但可能需要第三方机器和程序来确定验证的顺序。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;例如，在九宫格游戏中，由第三方程序决定要验证哪一列或哪一行。验证序列必须保密，否则验证者可能在不知道真实 “知识” 的情况下通过验证序列。 5.零知识证明在区块链中的应用&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;比特币和以太坊网络都使用公共地址来代替验证者和证明者的真实身份，使得交易部分匿名; 只有发送和接收地址，以及交易数量是公众知道的。但是，通过区块链上提供的各种信息，如交互记录等，可以发现地址的真实身份，存在隐私暴露的隐患。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;用了零知识证明之后，发送方、接收方和第三方的细节信息可以保持匿名，同时保证交易有效。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最早使用零知识证明技巧的区块链叫做 Zcash，实际的作法叫做 Zk-Snarks，这是许多零知识证明的做法之一，也是最有名的一个。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zk-Snarks 是 “零知识简洁无交互知识认证” 的简称，是一种在无需泄露数据本身情况下证明某些数据运算的一种零知识证明。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zk-Snarks 技术缩减了证明所需的时间和验证它们所需的计算量。它能够证明有效交易的条件已经满足，而不需要透露交易所涉及的地址或交易量的任何关键信息。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zcash 可以将交易纪录上的汇款者、收款者和金额都经过加密隐藏起来，因此矿工无从得知这些交易上的细节，但仍然可以验证交易。不过，目前多数使用者在 Zcash 上的交易，还是选择未经加密的作法，因为花费的成本比较高。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;另外，以太坊（Ethereum）上的智能合约目前也已经可以运用 Zk-Snarks 这套零知识证明的作法。但以太坊不完全是从隐私的角度切入，而是从节省运算成本的角度应用零知识证明。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;透过 Zk-Snarks，以太坊矿工可以不用再重新执行交易的运算，而是只要对方提得出证明即可。大概就像我不需要真的知道你会高一到高三的数学，而只要看到高中毕业证就能确定你懂高中数学。不过，这只有在制作证明的成本，远低于实际运算成本的情况下才划算。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zk-Snarks 将需要验证的交易内容转化为两个多项式乘积相等的证明，并结合同态加密等高级技术，在执行事务验证的同时保护隐藏的事务量。其过程可简单描述为: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将代码分解为可验证的逻辑验证步骤，然后将这些步骤分解为由加减乘除组成的计算流程。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;进行一系列变换，将待验证代码转换为多项式方程，如 t(x)h(x)= w(x)v(x)。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;为了使证明更加简洁，验证者事先随机选择几个检查点 s，检查这些点上的方程是否为真。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过同态编码或加密，验证者在计算方程时不知道实际输入值，但仍然可以验证。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在等式的左右两边，乘以一个不等于 0 的密值 k。当验证 (t(s)h(s)k) = (w(s)v(s)k) 时，具体的 t(s)、h(s)、w(s)、v(s)是不可知的，可以对信息进行保护。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当前履行 Zk-Snarks 算法的一个缺陷是需要在 advanced 中内置参数。如果这些参数泄露，整个网络将面临毁灭性的破坏。因此，用户必须信任在使用这些网络时不会泄露的信息。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可能的解决方案包括使用现代的“可信执行环境”，如 Intel SGX 和 ARM TrustZone。对于 Intel 的 SGX 技术，即使应用程序、操作系统、BIOS 或 VMM 受到威胁，私钥也是安全的。此外，最近的一份白皮书揭示了它在零知识密码学中的创新：Zk-Snarkss(零知识可伸缩透明知识参数)。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据 Zk-Snarks 白皮书，Zk-Snarks 是第一个不依赖任何信任设置实现区块链验证的系统，而随着计算数据数量的增加，计算速度呈指数增长。它不依赖于公钥加密系统，而且更简单的假设使它在理论上更安全，因为它唯一的加密假设是哈希函数 (如 SHA2) 是不可预测的。零知识证明和 Zk-S(T|N)ARK 等技术的测试和采用需要时间。 知道一点东西，并不能说明你会写应用，完整的应用是需要经验积累的。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>零知识证明</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MVC设计模式]]></title>
    <url>%2F2019%2F09%2F15%2FMVC%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[总结一下MVC(Model, View, Controller)设计模式：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MVC (Model View Controler)本来是存在于Desktop程序中的，M是指数据模型，V是指用户界面，C则是控制器。使用MVC的目的是将M和V的实现代码分离，从而使同一个程序可以使用不同的表现形式。比如一批统计数据你可以分别用柱状图、饼图来表示。C存在的目的则是确保M和V的同步，一旦M改变，V应该同步更新。 1.视图&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;视图是用户看到并与之交互的界面（它可以包括一些可以显示数据信息的页面，或者展示形式。例如jsp，html，asp，php）。对老式的Web应用程序来说，视图就是由HTML元素组成的界面，在新式的Web应用程序中，HTML依旧在视图中扮演着重要的角色，但一些新的技术已层出不穷，它们包括Macromedia Flash和象XHTML，XML/XSL，WML等一些标识语言和Web services. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如何处理应用程序的界面变得越来越有挑战性。MVC一个大的好处是它能为你的应用程序处理很多不同的视图。在视图中其实没有真正的处理发生，不管这些数据是联机存储的还是一个雇员列表，作为视图来讲，它只是作为一种输出数据并允许用户操纵的方式。 2.模型&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;模型表示企业数据和业务规则（可以说就是后端接口，用于业务处理）。在MVC的三个部件中，模型拥有最多的处理任务。例如它可能用象EJBs和ColdFusion Components这样的构件对象来处理数据库。被模型返回的数据是中立的，就是说模型与数据格式无关，这样一个模型能为多个视图提供数据。由于应用于模型的代码只需写一次就可以被多个视图重用，所以减少了代码的重复性。 3.控制器&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;控制器接受用户的输入并调用模型和视图去完成用户的需求（接受客户发送的请求，根据请求调用所对应的接口，然后模型业务处理后返回的数据，由控制器决定调用那个View展示）。所以当单击Web页面中的超链接和发送HTML表单时，控制器本身不输出任何东西和做任何处理。它只是接收请求并决定调用哪个模型构件去处理请求，然后用确定用哪个视图来显示模型处理返回的数据。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;现在我们总结MVC的处理过程，首先控制器接收用户的请求，并决定应该调用哪个模型来进行处理，然后模型用业务逻辑来处理用户的请求并返回数据，最后控制器用相应的视图格式化模型返回的数据，并通过表示层呈现给用户。 Making English as your working language.]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>MVC</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单排序]]></title>
    <url>%2F2019%2F09%2F15%2F%E7%AE%80%E5%8D%95%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[简单排序，包括冒泡、选择、插入，他们的时间复杂度都很高，为 O(N^2) 但是相对来说 插入比选择快，选择比冒泡快，下面来看看如何操作。 1.冒泡排序&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;源代码在这里 2.选择排序&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;源代码在这里 3.插入排序&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;源代码在这里 All experience comes from mistakes.]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>冒泡排序</tag>
        <tag>选择排序</tag>
        <tag>插入排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大O表示法（时间复杂度）]]></title>
    <url>%2F2019%2F09%2F15%2F%E5%A4%A7O%E8%A1%A8%E7%A4%BA%E6%B3%95%EF%BC%88%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%EF%BC%89%2F</url>
    <content type="text"><![CDATA[大O表示法，又名 时间复杂度，平时在对不同的数据结构进行操作时，都会有不同的时间复杂度，下面看下时间复杂度怎么计算的？ 具体来看看如何定义的： Don’t be one of the leeches.]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>时间复杂度</tag>
        <tag>大O表示法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Solidity学习]]></title>
    <url>%2F2019%2F09%2F14%2FSolidity%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[solidity 语言，作为以太坊平台智能合约语言，那必须得学一下啊。 一、入门智能合约&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;让我们先看一下最基本的例子。现在就算你都不理解也不要紧，后面我们会有更深入的讲解。 1.1 存储合约（把一个数据保存到链上）12345678910111213pragma solidity &gt;=0.4.0 &lt;0.7.0;contract SimpleStorage &#123; uint storedData; function set(uint x) public &#123; storedData = x; &#125; function get() public view returns (uint) &#123; return storedData; &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第一行就是告诉编译器源代码所适用的 Solidity 版本为&gt;=0.4.0 及 &lt;0.7.0 。这是为了确保合约不会在新的编译器版本中突然行为异常。关键字 pragma 的含义是，一般来说，pragmas（编译指令）是告知编译器如何处理源代码的指令的（例如， pragma once ）。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Solidity 中合约的含义就是一组代码（它的 函数 )和数据（它的 状态 ），它们位于以太坊区块链的一个特定地址上。 代码行 uint storedData; 声明一个类型为 uint (256 位无符号整数）的状态变量，叫做 storedData 。 你可以认为它是数据库里的一个位置，可以通过调用管理数据库代码的函数进行查询和变更。对于以太坊来说，上述的合约就是拥有合约（owning contract）。在这种情况下，函数 set 和 get 可以用来变更或取出变量的值。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;要访问一个状态变量，并不需要像 this. 这样的前缀，虽然这是其他语言常见的做法。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;该合约能完成的事情并不多（由于以太坊构建的基础架构的原因）：它能允许任何人在合约中存储一个单独的数字，并且这个数字可以被世界上任何人访问，且没有可行的办法阻止你发布这个数字。当然，任何人都可以再次调用 set ，传入不同的值，覆盖你的数字，但是这个数字仍会被存储在区块链的历史记录中。随后，我们会看到怎样施加访问限制，以确保只有你才能改变这个数字。 注解 所有的标识符（合约名称，函数名称和变量名称）都只能使用 ASCII 字符集。UTF-8 编码的数据可以用字符串变量的形式存储。 警告 小心使用 Unicode 文本，因为有些字符虽然长得相像（甚至一样），但其字符码是不同的，其编码后的字符数组也会不一样。 1.2 子货币合约（Subcurrency）示例&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下面的合约实现了一个最简单的加密货币。这里，币确实可以无中生有地产生，但是只有创建合约的人才能做到（实现一个不同的发行计划也不难）。而且，任何人都可以给其他人转币，不需要注册用户名和密码 —— 所需要的只是以太坊密钥对。 1234567891011121314151617181920212223242526272829pragma solidity &gt;=0.5.0 &lt;0.7.0;contract Coin &#123;// 关键字“public”让这些变量可以从外部读取address public minter;mapping (address =&gt; uint) public balances; // 轻客户端可以通过事件针对变化作出高效的反应 event Sent(address from, address to, uint amount); // 这是构造函数，只有当合约创建时运行 constructor() public &#123; minter = msg.sender; &#125; function mint(address receiver, uint amount) public &#123; require(msg.sender == minter); equire(amount &lt; 1e60); balances[receiver] += amount; &#125; function send(address receiver, uint amount) public &#123; require(amount &lt;= balances[msg.sender], &quot;Insufficient balance.&quot;); balances[msg.sender] -= amount; balances[receiver] += amount; emit Sent(msg.sender, receiver, amount); &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个合约引入了一些新的概念，让我们逐一解读。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;address public minter; 这一行声明了一个可以被公开访问的 address 类型的状态变量。 address 类型是一个 160 位的值，且不允许任何算数操作。这种类型适合存储合约地址或外部人员的密钥对。关键字 public 自动生成一个函数，允许你在这个合约之外访问这个状态变量的当前值。如果没有这个关键字，其他的合约没有办法访问这个变量。由编译器生成的函数的代码大致如下所示（暂时忽略 external 和 view）： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;function minter() external view returns (address) { return minter; }当然，加一个和上面完全一样的函数是行不通的，因为我们会有同名的一个函数和一个变量，这里，主要是希望你能明白——编译器已经帮你实现了。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下一行， mapping (address =&gt; uint) public balances; 也创建一个公共状态变量，但它是一个更复杂的数据类型。 该类型将 address 映射为无符号整数。 Mappings 可以看作是一个 哈希表 它会执行虚拟初始化，以使所有可能存在的键都映射到一个字节表示为全零的值。 但是，这种类比并不太恰当，因为它既不能获得映射的所有键的列表，也不能获得所有值的列表。 因此，要么记住你添加到 mapping 中的数据（使用列表或更高级的数据类型会更好），要么在不需要键列表或值列表的上下文中使用它，就如本例。 而由 public 关键字创建的 getter 函数 getter function 则是更复杂一些的情况， 它大致如下所示： 123function balances(address _account) external view returns (uint) &#123; return balances[_account];&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;正如你所看到的，你可以通过该函数轻松地查询到账户的余额。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;event Sent(address from, address to, uint amount); 这行声明了一个所谓的“事件（event）”，它会在 send 函数的最后一行被发出。用户界面（当然也包括服务器应用程序）可以监听区块链上正在发送的事件，而不会花费太多成本。一旦它被发出，监听该事件的 listener 都将收到通知。而所有的事件都包含了 from ， to 和 amount 三个参数，可方便追踪交易。 为了监听这个事件，你可以使用如下 JavaScript 代码（假设 Coin 是已经通过 web3.js 创建好的合约对象 ）： 12345678910Coin.Sent().watch(&#123;&#125;, &apos;&apos;, function(error, result) &#123; if (!error) &#123; console.log(&quot;Coin transfer: &quot; + result.args.amount + &quot; coins were sent from &quot; + result.args.from + &quot; to &quot; + result.args.to + &quot;.&quot;); console.log(&quot;Balances now:\n&quot; + &quot;Sender: &quot; + Coin.balances.call(result.args.from) + &quot;Receiver: &quot; + Coin.balances.call(result.args.to)); &#125;&#125;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这里请注意自动生成的 balances 函数是如何从用户界面调用的。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;特殊函数 constructor 是在创建合约期间运行的构造函数，不能在事后调用。 它永久存储创建合约的人的地址: msg (以及 tx 和 block ) 是一个特殊的全局变量，其中包含一些允许访问区块链的属性。 msg.sender 始终是当前（外部）函数调用的来源地址。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最后，真正被用户或其他合约所调用的，以完成本合约功能的方法是 mint 和 send。 如果 mint 被合约创建者外的其他人调用则什么也不会发生。 另一方面， send 函数可被任何人用于向他人发送币 (当然，前提是发送者拥有这些币)。记住，如果你使用合约发送币给一个地址，当你在区块链浏览器上查看该地址时是看不到任何相关信息的。因为，实际上你发送币和更改余额的信息仅仅存储在特定合约的数据存储器中。通过使用事件，你可以非常简单地为你的新币创建一个“区块链浏览器”来追踪交易和余额。 二、投票合约&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以下的合约有一些复杂，但展示了很多 Solidity 的语言特性。它实现了一个投票合约。 当然，电子投票的主要问题是如何将投票权分配给正确的人员以及如何防止被操纵。 我们不会在这里解决所有的问题，但至少我们会展示如何进行委托投票，同时，计票又是 自动和完全透明的 。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们的想法是为每个（投票）表决创建一份合约，为每个选项提供简称。 然后作为合约的创造者——即主席，将给予每个独立的地址以投票权。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;地址后面的人可以选择自己投票，或者委托给他们信任的人来投票。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在投票时间结束时，winningProposal() 将返回获得最多投票的提案。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以下是代码，从代码中学习 solidity 的其它一些语法：Ballot Smart Contract &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;源代码在这里，我在学习的时候照着模板编写发现有下面这个错误，就将 address to 引用到 tempTo 就 ok 了，我觉得是变量 to 在循环中被修改了导致的。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>solidity</tag>
        <tag>智能合约</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序设计]]></title>
    <url>%2F2019%2F09%2F13%2F%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;程序如何设计，达到用户使用简单，是我们需要不停探索的问题。 1.抽象&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从what（什么）中将how（如何）分离出来的过程，即类中的操作如何进行，相对什么是类用户可见的，被称为抽象。抽象是软件工程中重要的方面，把类的功能抽象出来，会使程序设计变得更简单，因为在设计的初期就考虑操作的细节。 Be an especially simple person,do not expect good luck coming suddenly,manage yourself well and cherish time at the moment.]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>程序设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法]]></title>
    <url>%2F2019%2F09%2F11%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[数据结构，是指数据在计算机存储空间中（磁盘中）的安排方式，算法，是指软件程序用来操作这些数据结构中的数据的过程。 1.数组Array1.1查找&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从数据的第一位开始查找，直到找到为止，需要n/2步操作；&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果数组中数据项允许重复，则需要全部遍历一遍，需要n步操作。 1.2插入&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;插入过程是很快的，一步完成，新的数据项只需插入到数组中的第一个空位上；&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果数组不允许重复项出现，则需要进行n步查询对比操作。 1.3删除&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;删除操作有3个过程：查找、删除、移动。删除算法中暗含着一个假设，即数组中不允许有洞，洞指的是一个或几个空的数据单元，他们后面还有非空数据单元（在更高的下标下还有数据项），如果删除算法中允许有洞，那么所有其他算法都将变得复杂，因为在查看某一单元数据项时，都需要判断一下是否为空。同样算法需要找到非空数据项而变得效率低下；&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因此，删除操作后，需要将后面非空数据项前移，来填补这个洞。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;删除需要（假设不允许重复）查找平均n/2个数据项，并平均移动剩下的n/2个数据项来填洞，总共是n步。查看删除的代码 2019-09-13更新———————————————————————— 1.4有序数组&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有序数组的有点&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用有序数组会给我们带来什么好处？最主要的好处就是查找速度比无序数组快多了。不好的地方就是在插入数据时，由于所有靠后的数据都需要向后移动一位以腾开空间，导致速度比无序数组慢一些。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有序数组和无序数组的删除操作都比较慢，因为数据项必须向前移动来填补删除数据带来的洞。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有序数组在查找频繁的情况下非常有用，但若是插入和删除比较多的情况下，则不太适用，无法高效工作。例如，有序数组适用于公司雇员的数据库；另一方面，零售商店的货物清单不适用有序数组来实现，这是由于频繁的进货出货导致的插入删除操作都会执行地很慢。 记住一个结论:二分查找法的查询次数最大为log2n，即2对n的对数，n为数组的长度；而线性查找法的平均查询次数为n/2。当n很大时，就可以发现二分查找法的优势了，具体看下图示例： 查看二分查找法的代码 1.5对象存储使用对数组的增删改查功能，自定义对象封装数组，具体代码如下查看二分查找法的代码 Pretty looks are in a rut, while interesting souls are cream of crop,In love, looks and talents,Which do you think is pretty important?]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[比特币双花攻击]]></title>
    <url>%2F2019%2F09%2F09%2F%E6%AF%94%E7%89%B9%E5%B8%81%E5%8F%8C%E8%8A%B1%E6%94%BB%E5%87%BB%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在学习区块链的过程中，大家一定对会听到“双花”这个词，意思就是双重支付，或者更直白点就是一笔资金被花费了两次。这篇文章我们来简单的分析一下为什么会有双花，比特币是如何避免双花的。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在传统的交易中，因为有银行这样的中心化机构，所以是不会存在双花问题的：每一笔支付都将从你的银行账户中扣除相应的资金，所有的明细在银行都有记录。但是在比特币中，因为没有账户的概念，而是引入了UTXO即未花费交易输出。因为没有银行这样的中心化机构的保证，当发生一笔交易时就可能存在着双花的危险：比方说A有一个比特币，然后他同时构造两笔交易T1和T2来花费这1个比特币，其中一个给了B，从B那里买件衣服，一个给了C，从C那里买双鞋。如果不引入某种机制来避免这种情况，那作为数字货币的比特币将没有任何存在的意义。接下来就来分析一下比特币是如何做到防止这种“双花”攻击的。 (1) 正常情况&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先我们来看看正常情况，说白了就是绝大多数时候，区块链的共识机制就能将双花消灭在萌芽状态。我们还是以上面提到的例子来做说明： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设A构造了两笔交易T1和T2，将自己价值1btc的UTXO分别转给了B和C，妄图同时从B和C那里获得好处。然后A几乎在同一时间将构造好的这两笔交易广播至网络。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设网络中的矿工节点先收到了交易T1，发现这笔交易的资金来源确实没有被花费过，于是将T1加入到自己的内存交易池中等待打包进区块。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大部分情况下，这个矿工节点会在不久后又收到交易T2，此时矿工会先检查A的UTXO是否足够，因为T2所指向的交易输入与已经加入交易池的T1相同，于是发现UTXO不足，矿工节点会拒绝处理该交易。网络中其他的矿工节点都类似，因此A试图双花的尝试胎死腹中。 (2) 分叉情况&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上面说的是正常的情况，但是也有非正常的情况要考虑：假设矿工节点M1和M2几乎在同一时间挖出了区块，并且很不幸M1挖到区块时只收到了交易T1，而M2挖到的区块时只收到了交易T2，这样交易T1和T2被分别打包进两个区块。因为这两个区块是差不多同一时间被挖出，于是造成了区块链的分叉： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;网络中某些节点（可能是离M1近的）先收到了M1打包的区块BLK1，于是用该区块延长自己的区块链，而另外一些节点（邻近M2的）则先收到M2打包的区块BLK2，用该区块延长自己的区块链，于是整个区块链网络中呈现出了不一致的问题： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;像这种不一致问题，一般只需要一个确认就能得到解决：假设随后又收到新区块，而新区块是以BLK1作为父区块，那么之前用BLK1延长自己区块链的节点，只需要将新区块链接到自己的区块链上，而之前以BLK2延长自己区块链的节点，则需要切换到新的最长链上，如下图：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因此在出现分叉的情况下，通常也只需要等一个区块的确认时间网络节点中的区块链就可以重新一致，在这个例子中，经过一个区块的确认期以后，B最终确认自己收到A的1btc，而因为包含有转账给C的交易T2的区块BLK2位于备用链上，因此无法通过支付验证。A的双花尝试也以失败告终。 (3) 为什么说比特币需要6个确认才安全&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上面提到一般情况下，只要经过1个区块的确认时间基本上就能确保“相对的安全”。而在比特币中，对于很小额的支付，为了提高交易速度，一般也就是等1个区块的确认即可。但是注意这里说的是“相对安全”，对于数额特别大交易，1个区块的确认远远不够。我们考虑上面提到的分叉情况：假设经过1个区块的确认后，B知道了A给他的1btc确实已经位于链上，于是发货给A。此时A及其同伙掌握着很大的一部分算力，A通知其同伙开始使劲挖矿延长备用链（攻击链），当A最终成功的使攻击链的长度（累计工作量）超过当前主链时，会再一次导致网络中的节点切换主链的情况，如下面的示意图： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;于是包含了A转给C的交易T2的区块BLK2位于了主链之上，此时A通知C钱已到账，C做支付验证也没问题，于是C给A发货，A的双花攻击成功。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;因此对于额度稍大的交易，必须要等待6个区块的确认才能保证安全，因为攻击者要想构造攻击链追上已经经过6个区块确认的主链需要花费的算力成本是非常大的，很有可能得不偿失。 总结 (1) 大部分情况下比特币的UTXO机制和区块链的共识机制都能有效应对双花攻击； (2) 对于小额支付，等待一个确认通常就可以认为安全了，但是对于大额支付，需要等6个确认才能大概率的认为安全，否则如果攻击者掌握很强算力，有可能构造累计工作量超过当前主链的攻击链导致双花成功。 Never give up on something if you think you can fight for it. It’s difficult to wait but it’s more difficult when you regret.]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>BTC</tag>
        <tag>双花攻击</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[比特币本质其实是UTXO]]></title>
    <url>%2F2019%2F09%2F09%2F%E6%AF%94%E7%89%B9%E5%B8%81%E6%9C%AC%E8%B4%A8%E5%85%B6%E5%AE%9E%E6%98%AFUTXO%2F</url>
    <content type="text"><![CDATA[UTXO的全称为Unspent Transaction Output，翻译过来就是未被花费的交易输出。其实并没有什么比特币，我们在交易所里或者钱包里显示的比特币余额其实是UTXO。那到底什么是UTXO呢? 好像觉得还是不太理解。。。。？ 示例&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在比特币区块链账本上记录了一笔一笔的交易，每一笔交易都有若干个交易输入（转账者），也就是资金来源，同时也有若干个交易输出（收款者），也就是资金去向。每一笔交易都要花费一笔输入，产生一笔输出，而产生的这笔输出，就是UTXO。 举个简单的例子：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A地址下有1个btc，A要把1个btc转给B，则账本上交易的输入就是A，输出为B的地址，这时脚本会校验A地址是否有1个btc（余额都不够怎么会给你转），即在某一笔输出（UTXO）中查询到了A确实有1个btc。所以A可以作为输入转给B一个btc，这时就有一笔价值1个btc的输出指向B地址，直到B进行下一次转账前这笔交易都是B未被花费的输出（UTXO）。后续B要转给C时又重复A转B的操作。 总结&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;比特币并不是基于账户的方案，而是基于UTXO方案。这个和传统银行账户的思维完全不一样。张三拥有10个btc，其实就是当前区块链账本中，有若干笔交易的输出（UTXO）收款人都是张三的地址，而这些UXTO的总额为10。这个地址一共收了多少UTXO，则是要通过比特币钱包代为跟踪计算，所以钱包里显示的余额其实是有多少价值btc的输出指向你的地址。 This is your life, and you’ve got to fight for it. Fight for what’s right. Fight for what’s important to you. Fight for the people you love.]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>BTC</tag>
        <tag>UTXO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch集群环境搭建]]></title>
    <url>%2F2019%2F09%2F06%2FElasticSearch%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[ElasticSearch作为一个基于搜索引擎lucene的文档数据库，搜索速度在目前的大数据存储系统中，算是佼佼者了。又有许多人把它当数据库使用，索引做库，类型做表，也是不错的选择。在数据仓库中，也可以做report层的存储，对接数据可视化工具，提供接口查询业务数据、结果数据。下面来看看集群环境怎么搭建。 1、软件需求jdk8elasticsearch包 2、es安装、配置123456789tar -zxvf elasticsearch-*.tar.gz -C /usr/localcd /usr/local/elasticsearchvim /config/elasticsearch.ymlcluster.name: es-cluster-1 配置集群名称 三台服务器保持一致node.name: node-1 配置单一节点名称，每个节点唯一标识network.host: 0.0.0.0 设置绑定的ip地址http.port: 9200 端口discovery.zen.ping.unicast.hosts: [&quot;192.168.21.12&quot;, &quot;192.168.21.13&quot;,&quot;192.168.21.14&quot;] 集群节点ip或者主机discovery.zen.minimum_master_nodes: 3 设置这个参数来保证集群中的节点可以知道其它N个有master资格的节点。默认为1，对于大的集群来说，可以设置大一点的值（2-4） 2.1新建用户（三台都需要）在 Linux 环境中，elasticsearch 不允许以 root 权限来运行！所以需要创建一个非root用户，以非root用户来起eselsearch 新增elsearch用户组 12useradd elsearch -g elsearch -p elasticsearch 创建elsearch用户chown -R elsearch:elsearch ./elasticsearch 用户目录权限 2.2运行操作三台服务12su elsearch./bin/elasticsearch -d //-d表示后台启动 3、问题汇总解决方案3.1问题一12ERROR: bootstrap checks failedmax file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536] 原因：无法创建本地文件问题,用户最大可创建文件数太小解决方案：切换到root用户，编辑limits.conf配置文件， 添加类似如下内容： 1vi /etc/security/limits.conf 添加如下内容: 1234* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096 备注：* 代表Linux所有用户名称（比如 hadoop）保存、退出、重新登录才可生效 3.2问题二1max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144] 原因：最大虚拟内存太小解决方案：切换到root用户下，修改配置文件sysctl.conf 1vi /etc/sysctl.conf 添加下面配置： 1vm.max_map_count=655360 并执行命令：sysctl -p然后重新启动elasticsearch，即可启动成功。 3.3问题三：1max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144] 原因：最大虚拟内存太小解决方案：切换到root用户下，修改配置文件sysctl.confvi /etc/sysctl.conf添加下面配置： 1vm.max_map_count=655360 并执行命令：sysctl -p然后重新启动elasticsearch，即可启动成功。 3.4问题四：ElasticSearch启动找不到主机或路由原因：ElasticSearch 单播配置有问题解决方案：检查ElasticSearch中的配置文件vi config/elasticsearch.yml找到如下配置：discovery.zen.ping.unicast.hosts: [“192.168.21.12”, “192.168.21.13”,”192.168.21.14”]一般情况下，是这里配置有问题，注意书写格式 3.5问题五：org.elasticsearch.transport.RemoteTransportException: Failed to deserialize exception response from stream原因:ElasticSearch节点之间的jdk版本不一致解决方案：ElasticSearch集群统一jdk环境 3.6问题六：Unsupported major.minor version 52.0原因：jdk版本问题太低解决方案：更换jdk版本，ElasticSearch5.0.0支持jdk1.8.0]]></content>
      <categories>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链三大共识机制]]></title>
    <url>%2F2019%2F09%2F03%2F%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%89%E5%A4%A7%E5%85%B1%E8%AF%86%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[区块链中三大共识机制POW、POS、DPOS的区别，进来看看： 三大共识机制POW、POS、DPOS的区别 2019-09-08更新 1.PoW算法1.1 PoW历史工作量证明源于经济学，是一个经济学的概念，是指为了达成某种目标而设定一个度量的方法。可以和平时工作中的绩效考核做类比：为了考核达到5星，你必须要完成leader指派给你的KPI，这些KPI就是工作量证明，完成它可能需要加班加点干很久，但是考评的时候leader验证起来却很容易。 1993年，Cynthia Dwork和Moni Naor在学术论文中首次提出工作量证明的的概念。 1997年，Adam Back在学术论文Hashcash中提出了Hahscash的概念，用于抵抗Dos攻击和垃圾邮件网关的滥用。Hahscash和比特币区块链的PoW如出一辙，在比特币之前，Hashcash的最常见应用场景就是反垃圾邮件。 1999年，Markus Jakobsson和Ari Juels发表的论文中首次提出了Proof of Work这个名词。 PoW需要两个角色：工作者和验证者，并且具备以下特点： (1) 工作只能由验证者发布；(2) 工作者必须要完成一定量的工作，具体的工作量有验证者给出；(3) 工作者没有办法快速完成工作，要完成工作必须消耗一定代价，但是验证者验证起来很容易； 1.2 HashcashHashcash是Adam Back与1997年发明的一种抵抗邮件服务DoS攻击的算法。理解了Hashcash，就能够轻而易举的理解比特币中的PoW。 Hashcash是基于SHA1散列算法，它抵抗垃圾邮件的原理如下： 假设S给R发送邮件，要想发送成功，则： (1) S的邮件头中需要带一个称之为hashcash stamp的戳记；(2) 对hashcash stamp进行SHA1后的值必须满足接收方R设定的条件：生成的hash值的前20位必须为0；(3) hashcash stamp可能由多个域组成，比如生成邮件的时间，收件人地址等不变量，还包含可变量counter；(4) 由于Hash的特点，导致发送方S没有办法快速找到满足条件的hashcash stamp，只能通过不断递增counter的值来穷举；(5) 发送方S通过暴力破解的方式计算出满足接收方条件的值，这个过程发送方消耗了一定量的CPU。而验证方只需要对收到的hashcash stamp进行SHA1，检查结果是否满足； 由于发送方计算满足邮件接收方条件的值需要消耗一定时间，对于垃圾邮件系统来说，这样的成本基本上是不可接受的，从而有效避免了垃圾邮件。 1.3 PoW如何解决分布式系统的共识问题可以把比特币区块链看成一个分布式的账本，然后定义几个名词： (1) 分布式账本：比特币区块链是一个分布式账本，这个账本人人可以随时查阅，但是由谁来记账需要通过共识算法来决定；(2) 记账：将区块写入区块链；(3) 记账者：就是平常所说的矿工，比特币系统中的每个矿工节点都是潜在的记账者；(4) 选举：就是大家所熟知的挖矿，用某种算法从一批候选矿工（记账者）中选出一个来记账（写入账本）；记账者中大部分都是正常的，但是也有少数不怀好意的记账者，因此系统需要通过共识算法选出一个正常的记账者来记账，这其实就是一个拜占庭将军问题：在可能存在恶意节点时，如何保证账本的正确性。 既然是拜占庭问题，那么像PBFT，PoW等算法都可以解决，比特币使用PoW，其达成共识的过程如下： (1) 系统指定一个目标hash值，各个矿工节点竞争，构造出候选区块，并不断计算区块头hash，直到得到满足条件的hash为止；(2) 与hashcash一样，矿工节点除了暴力破解，没有快速找到答案的办法；(3) 率先计算出解的矿工节点将区块广播给全网，其他节点验证区块（工作量是否满足，交易是否合法），没有问题就将区块加入到区块链中；(4) 计算出解的矿工得到一笔奖励费；很明显，这是一个凭算力取胜的游戏，简单分析一下：假设系统有4个矿工节点A，B，C，D，则：(1) 如果4个矿工节点的算力都相同，其中存在一个恶意节点，那么最终能正确写入账本的概率是3/4，而被恶意矿工写入的概率是1/4；(2) 假如B是恶意节点，他买了一台奇快的专用矿机，使得他的算力大增，达到了全部矿工节点算力的51%，那么系统基本上就被这个恶意矿工控制；因此，系统最坏的情况下能容忍的问题节点的数量是：占据整个系统51%算力的问题节点的数量，当然要掌控这么高的算力还是很困难的。关于具体的源码，后续会单独用一篇文章来分析比特币挖矿的过程，本文先理解PoW算法就好。 2.PoS算法2.1 PoS的提出PoW算法存在两个问题： (1) 太浪费资源，因为需要巨量的计算，会浪费资源（电力）；(2) 存在51%攻击问题：一旦能掌握系统51%的算力基本上就能控制整个系统。(3) 系统的吞吐量降低，比如比特币，平均每10分钟才产生一个区块；为了克服PoW算法的问题，2012年Sunny King提出了PoS权益证明算法，并发布了点点币（PPCoin），点点币中采用了PoS作为共识算法。PoS与PoW原理上很相似，都是一种基于概率的解决共识问题的算法。只不过PoW是拼算力，算力越强的抢到记账权的概率越大，而PoS则是拼财力，谁的财力越高，抢到记账权的概率就越大。 2.2 PoS算法的原理PoS一个重要的概念是币龄，币龄 = 持有的币数 * 持有币的天数，例如钱包里有90个点点币，都持有了10天，则币龄=900；与PoW一样，为了抢到将区块写入区块链的权利，节点同样要进行hash计算，只不过最终的解和币龄有关，计算公式：proofHash &lt; coinAge * target；coinAge是币龄，target是一个目标值，用于调整难度。coinAge * target的值越大，难度就越小，抢到区块的概率就越高。假如你的钱包里是0个币，那么你的币龄就是0, 计算一个小于0的hash值的概率基本上也0，因此基本上抢不到区块；PoS可以解决PoW的问题： (1) 首先，不需要PoW那么大的算力，可以减少资源浪费；(2) 不容易遭受51%攻击，相比起掌握系统一半以上的算力，拥有整个系统51%的财力会更加困难。但是PoS也存在明显的缺陷：(1) 容易被垄断：因为持币越多，持有的越久，币龄就越高，越容易挖到区块并得到激励，持币少的人基本上没有机会，这样整个系统的安全性实际上会被持币数量较大的一部分人（大股东们）掌握；而比特币则不存在这个问题，因为理论上任何人都可以购买矿机获得提高自己的算力（甚至可以联合起来），提升自己挖矿成功的概率；(2) 很难应对分叉的情况：当出现分叉时，PoS可以在两条链上同时挖矿并获得收益。而PoW则不存在这个问题，因为当出现分叉以后，PoW总是选择工作量大的链做为主链。 3.DPoS算法PoS算法中记账权很容易被持币较多的人垄断，从而容易趋于中心化（永远是持币多的那些人获得写入区块并获得奖励），于是又有了DPoS（委托权益证明）算法。与PoS算法相比，DPoS中多了受托人的概念。DPoS算法是在2014年由Bitshares的首席开发者Dan Larimer提出，此人现为EOS的CTO。DPoS算法的原理如下： (1) 区块由受托人产生并写入区块链；(2) 受托人由持币人选举产生；(3) 根据受托人所得的票数排名，选取排名最靠前的若干（一般为101位）作为记账节点，来生成区块并写入区块链；(4) 被选中的受托人会隔一定的周期进行一次调整；首先，为了利益最大化，股东会选择将票投给那些信誉好，可靠性高的节点；其次，受托人每隔一定的周期就会重新投票进行调整，更加民主和公平。这就好比公司选举领导层干部，为了公司利益最大化，股东一般会选择能力强的人进入管理层。而一旦管理层出了问题领导，股东可以把他撸下去，重新投票选择更胜任的人。 4.总结本文介绍了PoW、PoS两类基于概率的共识算法，任何一个区块链都必须要解决区块何时产生，由谁将区块写入区块链的问题，PoW和PoS解决的思路总结起来就是： (1) PoW：比拼算力，算力越强越容易拿到写区块链的权利；(2) PoS：比拼财力，占的股份越大（币龄越高），越容易拿到记账权；(3) DPoS：引入了受托人，由投票选举出的若干信誉度更高的受托人记账，受托人每隔一定周期调整。这些算法在许多的区块链中被广泛使用，这些算法是区块链安全的基石，学习中需要结合项目源码加以理解，弄清楚区块链到底在共识什么，为什么需要共识，共识算法是如何解决这些问题的。以太坊将在比特币创世块挖出的那一天2020年1月3日升级ETH1.0为ETH2.0，由POW共识改为POS共识，期待他的表现。 你需要做的就是坚持。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>共识机制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka集群搭建]]></title>
    <url>%2F2019%2F08%2F31%2Fkafka%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[kafka，领英开源消息队列框架，在大数据实时、批处理过程中，充当缓冲、中间存储、解耦的组件，深得工程师的喜爱，下面看下如何搭建。 1、软件环境搭建好的zookeeper集群下载kafka安装包 2、安装、修改配置文件12tar -zxvf kafka_*.tgz -C /usr/local/cd /usr/local/kafka/config 2.1修改配置文件12345678910111213vim server.propertiesbroker.id=1/* 这是这台虚拟机上的值，在另外两台虚拟机上应该是2或者3，这个值是唯一的，每台虚拟机或者叫服务器不能相同。 // 设置本机IP和端口。 我这里设置的是listeners，也可以直接设置host.name=192.168.172.10,port=9092,这个IP地址也是与本机相关的，每台服务器上设置为自己的IP地址。 /listeners=PLAINTEXT://192.168.172.10:9092advertised.listeners=PLAINTEXT://x.x.x.x:9092 //外部访问// 该端口默认是9092// 在og.retention.hours=168下面新增下面三项 #默认消息的最大持久化时间，168小时，7天message.max.byte=5242880 #消息保存的最大值5M default.replication.factor=2 #kafka保存消息的副本数，如果一个副本失效了，另一个还可以继续提供服务replica.fetch.max.bytes=5242880 #取消息的最大直接数/ 设置zookeeper的连接端口，新版本的kafka不再使用zookeeper而是通过brokerlist的配置让producer直接连接broker，这个brokerlist可以配置多个，只要有一个能连接上，就可以让producer获取道集群中的其他broker的信息，绕过了zookeeper。因此这个zookeeper.connect可以设置多个值 */zookeeper.connect=192.168.172.12:2181,192.168.172.11:2181,192.168.172.10:2181 3、启动kafka首先要启动kafka集群，并且是三台都要手动去启动。// 进入kafka的bin目录cd /opt/kafka/kafka_2.11-1.0.0/bin/// 启动kafka./kafka-server-start.sh -daemon ../config/server.properties &amp; //-daemon代表着以后台模式运行kafka集群，这样kafka的启动就不会影响我们继续在控制台输入命令。//查看服务是否正常jps 4、创建topic，测试4.1创建topic创建Topic1./kafka-topics.sh --create --zookeeper 10.0.0.60:2181 --replication-factor 2 --partitions 1 --topic shuaige // 解释 123--replication-factor 2 #复制两份--partitions 1 #创建1个分区--topic #主题为shuaige ‘’’在一台服务器上创建一个发布者’’’ 创建一个broker，发布者123./kafka-console-producer.sh --broker-list 10.0.0.60:9092 --topic shuaige&apos;&apos;&apos;在一台服务器上创建一个订阅者&apos;&apos;&apos;./kafka-console-consumer.sh --zookeeper localhost:2181 --topic shuaige --from-beginning 4.2 查看topic1./kafka-topics.sh --list --zookeeper localhost:2181 4.3 查看topic状态1/kafka-topics.sh --describe --zookeeper localhost:12181 --topic shuaige 下面是显示信息Topic:ssports PartitionCount:1 ReplicationFactor:2 Configs: Topic: shuaige Partition: 0 Leader: 1 Replicas: 0,1 Isr: 1//分区为为1 复制因子为2 他的 shuaige的分区为0//Replicas: 0,1 复制的为0，1 4.4 创建kafka topic1bin/kafka-topics.sh --zookeeper node01:2181 --create --topic t_cdr --partitions 30 --replication-factor 2 注： partitions指定topic分区数，replication-factor指定topic每个分区的副本数 partitions分区数: partitions ：分区数，控制topic将分片成多少个log。可以显示指定，如果不指定则会使用broker(server.properties)中的num.partitions配置的数量 虽然增加分区数可以提供kafka集群的吞吐量、但是过多的分区数或者或是单台服务器上的分区数过多，会增加不可用及延迟的风险。因为多的分区数，意味着需要打开更多的文件句柄、增加点到点的延时、增加客户端的内存消耗。 分区数也限制了consumer的并行度，即限制了并行consumer消息的线程数不能大于分区数 分区数也限制了producer发送消息是指定的分区。如创建topic时分区设置为1，producer发送消息时通过自定义的分区方法指定分区为2或以上的数都会出错的；这种情况可以通过alter –partitions 来增加分区数。 replication-factor副本 replication factor 控制消息保存在几个broker(服务器)上，一般情况下等于broker的个数。 如果没有在创建时显示指定或通过API向一个不存在的topic生产消息时会使用broker(server.properties)中的default.replication.factor配置的数量查看所有topic列表1bin/kafka-topics.sh --zookeeper node01:2181 --list 查看指定topic信息 1bin/kafka-topics.sh --zookeeper node01:2181 --describe --topic t_cdr 控制台向topic生产数据 1bin/kafka-console-producer.sh --broker-list node86:9092 --topic t_cdr 控制台消费topic的数据 1bin/kafka-console-consumer.sh --zookeeper node01:2181 --topic t_cdr --from-beginning 查看topic某分区偏移量最大（小）值 1bin/kafka-run-class.sh kafka.tools.GetOffsetShell --topic hive-mdatabase-hostsltable --time -1 --broker-list node86:9092 --partitions 0 注： time为-1时表示最大值，time为-2时表示最小值增加topic分区数, 为topic t_cdr 增加10个分区 1bin/kafka-topics.sh --zookeeper node01:2181 --alter --topic t_cdr --partitions 10 删除topic，慎用，只会删除zookeeper中的元数据，消息文件须手动删除 1bin/kafka-run-class.sh kafka.admin.DeleteTopicCommand --zookeeper node01:2181 --topic t_cdr 查看topic消费进度这个会显示出consumer group的offset情况， 必须参数为–group， 不指定–topic，默认为所有topic 1234567891011121314151617Displays the: Consumer Group, Topic, Partitions, Offset, logSize, Lag, Owner for the specified set of Topics and Consumer Groupbin/kafka-run-class.sh kafka.tools.ConsumerOffsetCheckerrequired argument: [group]Option Description------ -------------broker-info Print broker info--group Consumer group.--help Print this message.--topic Comma-separated list of consumertopics (all topics if absent).--zkconnect ZooKeeper connect string. (default: localhost:2181)Example,bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --group pvGroup Topic Pid Offset logSize Lag Ownerpv page_visits 0 21 21 0 nonepv page_visits 1 19 19 0 nonepv page_visits 2 20 20 0 none 以上图中参数含义解释如下： 123456topic：创建时topic名称pid：分区编号offset：表示该parition已经消费了多少条messagelogSize：表示该partition已经写了多少条messageLag：表示有多少条message没有被消费。Owner：表示消费者 细看kafka-run-class.sh脚本，它是调用 了ConsumerOffsetChecker的main方法，所以，我们也可以通过java代码来访问scala的ConsumerOffsetChecker类，代码如下： 12345678910111213import kafka.tools.ConsumerOffsetChecker;/** * kafka自带很多工具类，其中ConsumerOffsetChecker能查看到消费者消费的情况, * ConsumerOffsetChecker只是将信息打印到标准的输出流中 * */public class RunClass &#123; public static void main(String[] args) &#123; //group-1是消费者的group名称,可以在zk中 String[] arr = new String[]&#123;&quot;--zookeeper=192.168.199.129:2181,192.168.199.130:2181,192.168.199.131:2181/kafka&quot;,&quot;--group=group-1&quot;&#125;; ConsumerOffsetChecker.main(arr); &#125;&#125; 5、日志说明默认kafka的日志是保存在/opt/kafka/kafka_2.10-0.9.0.0/logs目录下的，这里说几个需要注意的日志server.log #kafka的运行日志state-change.log #kafka他是用zookeeper来保存状态，所以他可能会进行切换，切换的日志就保存在这里controller.log #kafka选择一个节点作为“controller”,当发现有节点down掉的时候它负责在游泳分区的所有节点中选择新的leader,这使得Kafka可以批量的高效的管理所有分区节点的主从关系。如果controller down掉了，活着的节点中的一个会备切换为新的controller. 6、 Kafka-manager（v2.0.0.2）（Kafka集群可视化管理）6.1 sbt编译123curl https://bintray.com/sbt/rpm/rpm &gt; bintray-sbt-rpm.repomv bintray-sbt-rpm.repo /etc/yum.repos.d/yum install sbt 检查sbt是否安装成功 1sbt version 6.2 安装部署kafka-manager12wget https://github.com/yahoo/kafka-manager/releases/kafka-manager-2.0.0.2.tar.gztar zxvf kafka-manager-2.0.0.2.tar.gz -C /usr/local 编译kafka-manager 12cd /usr/local/kafka-manager-2.0.0.2./sbt clean dist //需要一段时间 编译结果查看 1ls /usr/local/kafka-manager-2.0.0.2/target/universal/ //存在kafka-manager-2.0.0.2.zip 创建目录kafka-manager12mkdir -p /usr/local/kafka-managercp /usr/local/kafka-manager-2.0.0.2/target/universal/kafka-manager-2.0.0.2.zip /usr/local/kafka-manager 解压文件 1unzip kafka-manager-2.0.0.2.zip 修改配置文件 1vim /usr/local/kafka-manager/kafka-manager-2.0.0.2/conf/application.conf 修改信息 1234单机：kafka-manager.zkhosts=&quot;localhost:2181&quot;集群：kafka-manager.zkhosts=&quot;node3.cn:2181,node4.cn:2181,node5.cn:2181&quot; 6.3启动kafka-manager控制台启动 1bin/kafka-manager 后台守护启动 1nohup bin/kafka-manager &amp; 后台启动通过 -Dhttp.port，指定端口; -Dconfig.file=conf/application.conf指定配置文件 1nohup bin/kafka-manager -Dconfig.file=conf/application.conf -Dhttp.port=8080 &amp;]]></content>
      <categories>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建zookeeper集群]]></title>
    <url>%2F2019%2F08%2F31%2F%E6%90%AD%E5%BB%BAzookeeper%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[zookeeper作为一个hadoop生态组件的连接器，在节点服务之间的通信及元数据管理上起着非常重要的作用，下面看看搭建步骤。 1、软件环境Linux服务器。使用数量为一台，三台，五台，（2*n+1）。zookeeper集群的工作是超过半数才能对外提供服务，三台中超过两台超过半数，允许一台挂掉。最好不要使用偶数台。例如：如果有4台，那么挂掉一台还剩下三台，如果再挂掉一台就不能行了，因为是要超过半数。 Java jdk1.8 zookeeper包 2、配置与安装zookeeper配置文件zoo.cfg12345678910111213141516tar -zxvf zookeeper-*.tar.gz -C /usr/localcd /usr/local/zookeeper/confcp zoo_sample.cfg zoo.cfgvim zoo.cfgtickTime=2000initLimit=10syncLimit=5dataDir=/usr/local/zookeeper/zkdatadataLogDir=/usr/local/zookeeper/zkdatalogclientPort=2181// 此处的IP就是你所操作的三台虚拟机的IP地址，每台虚拟机的zoo.cfg中都需要填入这三个地址。第一个端口是master和slave之间的通信端口，默认是2888，第二个端口是leader选举的端口，集群刚启动的时候选举或者leader挂掉之后进行新的选举的端口默认是3888server.1=192.168.172.10:2888:3888server.2=192.168.172.11:2888:3888server.3=192.168.172.12:2888:3888// server.1 这个1是服务器的标识也可以是其他的数字， 表示这个是第几号服务器，用来标识服务器，这个标识要写到快照目录下面myid文件里创建myid文件。以现在所在的第一台虚拟机192.168.172.10为例，对应server.1，通过上边的配置信息可以查到。创建myid文件的目的是为了让zookeeper知道自己在哪台服务器上，例如现在所在的虚拟机是192.168.172.10，它对应的id是1，那么就在myid文件中写入1. 节点id配置1234echo &quot;1&quot; &gt; /usr/local/zookeeper/zkdata/myid另外两台虚拟机上也需要创建myid文件并写入相应的id，id根据zoo.cfg文件中的IP地址查询。echo &quot;2&quot; &gt; /usr/local/zookeeper/zkdata/myidecho &quot;3&quot; &gt; /usr/local/zookeeper/zkdata/myid 3、启动zookeeper12345cd /usr/local/zookeeper/bin// 启动服务 (注意！三台虚拟机都要进行该操作)./zkServer.sh start// 检查服务器状态./zkServer.sh status // 显示如下JMX enabled by defaultUsing config: /opt/zookeeper/zookeeper-3.4.6/bin/../conf/zoo.cfgMode: follower #他是主节点leader还是从节点follower 4、补充说明1. myid文件和server.myid在快照目录下存放的标识本台服务器的文件，他是整个zk集群用来发现彼此的一个重要标识，myid必须与zoo.cfg配置中的 server.? 一致。 2. zoo.cfg配置文件zoo.cfg文件是zookeeper配置文件，在conf目录里。 123456789101112// tickTime：这个时间是作为 Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。// initLimit：这个配置项是用来配置 Zookeeper 接受客户端（这里所说的客户端不是用户连接 Zookeeper 服务器的客户端，而是 Zookeeper 服务器集群中连接到 Leader 的 Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过 5个心跳的时间（也就是 tickTime）长度后 Zookeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 52000=10 秒// syncLimit：这个配置项标识 Leader 与Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个 tickTime 的时间长度，总的时间长度就是52000=10秒// dataDir：快照日志的存储路径// dataLogDir：事物日志的存储路径，如果不配置这个那么事物日志会默认存储到dataDir制定的目录，这样会严重影响zk的性能，当zk吞吐量较大的时候，产生的事物日志、快照日志太多// clientPort：这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。修改他的端口改大点]]></content>
      <categories>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink学习]]></title>
    <url>%2F2019%2F08%2F26%2FFlink%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[flink，号称第二代实时大数据计算引擎，被他的名头吸引过来，我也来学习学习，下面是我在学习过程中遇到的一些问题和解决方案。 如何保证数据处理的有序性&nbsp;&nbsp;&nbsp;&nbsp;flink通过watermark来解决这个问题。当使用事件时间来进行对事件排序时，很有必要跟踪事件的处理时间，例如在一个窗口操作t到t+5中，只有当系统能够保证没有数据的事件时间小于t+5时，然后对这个窗口中的数据进行排序计算，才是保证数据处理的有序性，那么如何确定没有数据的事件时间小于t+5呢？flink是使用watermark来确定的，它会追踪穿过系统中的每一条数据，当它知道没有数据对应的时间戳小于t1后，它会将这个t1水印广播📢到下流operators，一旦watermark被提交，下流operators在获取watermark值时就会发现并作出相应的反应。&nbsp;&nbsp;&nbsp;&nbsp;在窗口操作中，窗口会等待t+5的watermark，然后触发计算，并向下游广播t+5的watermark。&nbsp;&nbsp;&nbsp;&nbsp;当所有的operater都在等待他的watermark和输入数据时，系统会被延时，从而影响时效性。&nbsp;&nbsp;&nbsp;&nbsp;下图是实际水印、事件时间与处理时间之间的关系： you can see the original document at this link Time and Order in Streams 学习使我快乐。]]></content>
      <categories>
        <category>大数据</category>
        <category>实时计算</category>
      </categories>
      <tags>
        <tag>flink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重温《头号玩家》VR游戏中的区块链世界]]></title>
    <url>%2F2019%2F08%2F19%2F%E9%87%8D%E6%B8%A9%E3%80%8A%E5%A4%B4%E5%8F%B7%E7%8E%A9%E5%AE%B6%E3%80%8BVR%E6%B8%B8%E6%88%8F%E4%B8%AD%E7%9A%84%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%96%E7%95%8C%2F</url>
    <content type="text"><![CDATA[2018年上映的电影《头号玩家》，得到许多年轻人的喜爱，故事情节紧凑而又丰富，其中包含许多区块链世界的元素，咱们一起探讨下吧。 2019-08-25更新———————————— 游戏中通用的金币、不同的游乐场景、统一的入口等等，貌似现在的区块链世界。比特币、以太坊、比特现金，谁会是区块链游戏中的通用货币呢？每个玩家都有自己的唯一私钥，可以访问不同区域不同游戏，音乐、电影、游戏、运动等等，应有尽有，其中私钥就是区块链世界的入口。而且金币可以买现实世界中的物品，所以金币属于虚拟资产，类似现在的Q币、游戏币等等。你们觉得这种游戏会在现实中出现吗？我觉得可能，中心化的游戏，为并发和性能提供支持，区块链实现资产的去中心化，不受别人控制。所有如何实现centralized app与decentralized app之间的交互呢？]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>头号玩家</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[以太坊]]></title>
    <url>%2F2019%2F08%2F18%2F%E4%BB%A5%E5%A4%AA%E5%9D%8A%2F</url>
    <content type="text"><![CDATA[以太坊 Do you like it? 一、layer2扩展解决方案 侧链loom network plasma 2019-08-25更新———————————— 二、Ethereum2.0研发计划阶段0:信标链&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;主要负责管理权益证明协议的运行，并协调所有独立的平行分片，他是整个开发中最复杂的部分，详情请看信标链 阶段1:分片链&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;主要实现将验证者分散在1024条分片链上，点对点网络以足够快的速度与验证者之间准确无误的进行通信。 阶段2:执行层&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;提供巨大的设计空间和无拘无束的开发氛围，提供一些不同的执行环境，例如代币转账执行环境（匿名），智能合约语言执行环境，为处理高容量Plasma侧链而优化的执行环境，以及为企业用户量身打造的执行环境，具备许可性和隐私性。 2019-09-08更新 三、账户&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以太坊中有2类账户，他们共用同一个地址空间。 外部账户&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;该类账户被公钥-私钥对（人类）控制 合约账户&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;该类账户被存储在合约中的代码控制 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;另外，每个账户都有一个以太币余额，单位是Wei，该账户余额可以向它发送带有金额交易的方式来改变。 四、以太坊虚拟机&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以太坊虚拟机EVM，是以太坊中智能合约的运行环境。它不仅被沙箱隔离起来，实际上完全隔离，也就是说运行在虚拟机中的代码，不能接触到网络、文件系统、或其他进程。甚至智能合约和其他智能合约只能有有限的接触。 五、Gas&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以太坊上的每笔交易都需要消耗gas，目的是限制执行交易所需的工作量，同时为执行支付费用。当EVM执行交易时，gas将按照特定规则被逐渐消耗。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;gas price（gas价格，以太币计）是由交易创建者设定的，发送账户需要预付的交易费用=gas price * gas amount，如果执行结束gas还有剩余，那么这些gas将返回给发送账户。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;无论交易被执行到什么位置，一旦gas被耗尽（比如降为负值），将会触发一个out of gas异常，当前调用帧所做的所有状态修改都将被回滚。 2019-09-13更新———————————————————————— 六、存储、内存和栈6.1 存储&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;每个账户有一块持久化内存区叫做存储。存储是将256位字映射到256位字的键值存储区，在合约中枚举存储是不可能的，且读存储的开销很高，修改存储的开销甚至更高。合约只能读写存储区内属于自己的部分。 6.2 内存&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第二个内存区称为内存，合约会试图为每一次消息调用获取一块被重新擦拭干净的内存示例。内存是线性的，可以按照字节寻址，但读的长度被限制在256位，而写的长度可以是8位或256位。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当访问（无论是读还是写）之前从未访问过的内存字（word）时（无论是偏移到该字内的任何位置），内存将按字进行扩展（每个字是256位）。扩容也将消耗一定的gas。 随着内存使用量的增长，其费用也会增高（以平方级别）。 6.3 栈&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;EVM不是基于寄存器的，而是基于栈的，因此所有的计算都在一个称为 栈。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;栈最大有1024个元素，每个元素的长度为一个字（256位），对栈的访问仅限于顶端，限制方式为允许拷贝最顶端的16个元素中的一个到栈顶，或者是栈顶元素和下面的16个元素中的一个进行交换。所有其他操作都只能取最顶的2个（或1个，或更多，取决于具体的操作）元素，运算后，把结果压入栈顶。当然可以把栈上的元素放到存储或内存中。但是无法只访问栈上指定深度的那个元素，除非先从栈顶移除其他元素。 七、指令集&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;EVM的指令集量应尽量少，以最大限度地避免可能导致共识问题的错误实现。所有的指令都是针对”256位的字（word）”这个基本的数据类型来进行操作。具备常用的算术、位、逻辑和比较操作。也可以做到有条件和无条件跳转。此外，合约可以访问当前区块的相关属性，比如它的编号和时间戳。 八、消息调用&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;合约可以通过消息调用的方式来调用其它合约或者发送以太币到非合约账户。消息调用和交易非常类似，它们都有一个源、目标、数据、以太币、gas和返回数据。事实上每个交易都由一个顶层消息调用组成，这个消息调用又可创建更多的消息调用。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;合约可以决定在其内部的消息调用中，对于剩余的 gas ，应发送和保留多少。如果在内部消息调用时发生了out-of-gas异常（或其他任何异常），这将由一个被压入栈顶的错误值所指明。此时，只有与该内部消息调用一起发送的gas会被消耗掉。并且，Solidity中，发起调用的合约默认会触发一个手工的异常，以便异常可以从调用栈里“冒泡出来”。 如前文所述，被调用的合约（可以和调用者是同一个合约）会获得一块刚刚清空过的内存，并可以访问调用的payload——由被称为 calldata 的独立区域所提供的数据。调用执行结束后，返回数据将被存放在调用方预先分配好的一块内存中。 调用深度被 限制 为 1024 ，因此对于更加复杂的操作，我们应使用循环而不是递归。 九、委托调用/代码调用和库&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有一种特殊类型的消息调用，被称为 委托调用(delegatecall) 。它和一般的消息调用的区别在于，目标地址的代码将在发起调用的合约的上下文中执行，并且 msg.sender 和 msg.value 不变。 这意味着一个合约可以在运行时从另外一个地址动态加载代码。存储、当前地址和余额都指向发起调用的合约，只有代码是从被调用地址获取的。 这使得 Solidity 可以实现”库“能力：可复用的代码库可以放在一个合约的存储上，如用来实现复杂的数据结构的库。 十、日志&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有一种特殊的可索引的数据结构，其存储的数据可以一路映射直到区块层级。这个特性被称为 日志(logs) ，Solidity用它来实现 事件(events) 。合约创建之后就无法访问日志数据，但是这些数据可以从区块链外高效的访问。因为部分日志数据被存储在 布隆过滤器(Bloom filter) 中，我们可以高效并且加密安全地搜索日志，所以那些没有下载整个区块链的网络节点（轻客户端）也可以找到这些日志。 十一、合约创建&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;合约甚至可以通过一个特殊的指令来创建其他合约（不是简单的调用零地址）。创建合约的调用 create calls 和普通消息调用的唯一区别在于，负载会被执行，执行的结果被存储为合约代码，调用者/创建者在栈上得到新合约的地址。 十二、失效和自毁&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;合约代码从区块链上移除的唯一方式是合约在合约地址上执行自毁操作 selfdestruct 。合约账户上剩余的以太币会发送给指定的目标，然后其存储和代码从状态中被移除。移除一个合约听上去不错，但其实有潜在的危险，如果有人发送以太币到移除的合约，这些以太币将永远提丢失。 *注释 尽管一个合约的代码中没有显式地调用 selfdestruct ，它仍然有可能通过 delegatecall 或 callcode 执行自毁操作。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果要使合同失效，则应通过更改内部状态来禁用合约，这样可以在使用函数无法执行从而进行 revert，从而达到返还以太的目的。 *注释 旧合约的删减可能会，也可能不会被以太坊的各种客户端程序实现。另外，归档节点可选择无限期保留合约存储和代码。目前，外部账户 不能从状态中移除。 当你累了的时候，停下来做个梦吧。愿你坚持到底。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>以太坊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[拜占庭问题]]></title>
    <url>%2F2019%2F08%2F18%2F%E6%8B%9C%E5%8D%A0%E5%BA%AD%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[拜占庭问题，即去中心化网络的一致性问题。 一、问题&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;拜占庭帝国想要进攻一个强大的敌人，为此派出了 10 支军队去包围这个敌人。这个敌人虽不比拜占庭帝国，但也足以抵御 5 支常规拜占庭军队的同时袭击。这 10 支军队在分开的包围状态下同时攻击。他们任一支军队单独进攻都毫无胜算，除非有至少 6 支军队（一半以上）同时袭击才能攻下敌国。他们分散在敌国的四周，依靠通信兵骑马相互通信来协商进攻意向及进攻时间。困扰这些将军的问题是，他们不确定他们中是否有叛徒，叛徒可能擅自变更进攻意向或者进攻时间。在这种状态下，拜占庭将军们才能保证有多于 6 支军队在同一时间一起发起进攻，从而赢取战斗？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;先看在没有叛徒情况下，假如一个将军 A 提一个进攻提议（如：明日下午 1 点进攻，你愿意加入吗？）由通信兵通信分别告诉其他的将军，如果幸运中的幸运，他收到了其他 6 位将军以上的同意，发起进攻。如果不幸，其他的将军也在此时发出不同的进攻提议（如：明日下午 2 点、3 点进攻，你愿意加入吗？），由于时间上的差异，不同的将军收到（并认可）的进攻提议可能是不一样的，这是可能出现 A 提议有 3 个支持者，B 提议有 4 个支持者，C 提议有 2 个支持者等等。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;再加一点复杂性，在有叛徒情况下，一个叛徒会向不同的将军发出不同的进攻提议（通知 A 明日下午 1 点进攻， 通知 B 明日下午 2 点进攻等等），一个叛徒也会可能同意多个进攻提议（即同意下午 1 点进攻又同意下午 2 点进攻）。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;叛徒发送前后不一致的进攻提议，被称为 “拜占庭错误”，而能够处理拜占庭错误的这种容错性称为「Byzantine fault tolerance」，简称为 BFT。 二、解决方案1. 中本聪的解决方案: 工作量证明机制（POW）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在出现比特币之前，解决分布式系统一致性问题主要是 Lamport 提出的 Paxos 算法或其衍生算法。Paxos 类算法仅适用于中心化的分布式系统，这样的系统的没有不诚实的节点（不会发送虚假错误消息，但允许出现网络不通或宕机出现的消息延迟）。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;中本聪在比特币中创造性的引入了 “工作量证明（POW : Proof of Work）” 来解决这个问题，有兴趣可进一步阅读工作量证明。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过工作量证明就增加了发送信息的成本，降低节点发送消息速率，这样就以保证在一个时间只有一个节点 (或是很少) 在进行广播，同时在广播时会附上自己的签名。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个过程就像一位将军 A 在向其他的将军（B、C、D…）发起一个进攻提议一样，将军 B、C、D… 看到将军 A 签过名的进攻提议书，如果是诚实的将军就会立刻同意进攻提议，而不会发起自己新的进攻提议。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以上就是比特币网络中是单个区块（账本）达成共识的方法（取得一致性）。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;理解了单个区块取得一致性的方法，那么整个区块链（总账本）如果达成一致也好理解。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们稍微把将军问题改一下：假设攻下一个城堡需要多次的进攻，每次进攻的提议必须基于之前最多次数的胜利进攻下提出的（只有这样敌方已有损失最大，我方进攻胜利的可能性就更大），这样约定之后，将军 A 在收到进攻提议时，就会检查一下这个提议是不是基于最多的胜利提出的，如果不是（基于最多的胜利）将军 A 就不会同意这样的提议，如果是的，将军 A 就会把这次提议记下来。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这就是比特币网络最长链选择。 2. 权益证明机制（POS）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;工作量证明其实相当于提高了做叛徒（发布虚假区块）的成本，在工作量证明下，只有第一个完成证明的节点才能广播区块，竞争难度非常大，需要很高的算力，如果不成功其算力就白白的耗费了（算力是需要成本的），如果有这样的算力作为诚实的节点，同样也可以获得很大的收益（这就是矿工所作的工作），这也实际就不会有做叛徒的动机，整个系统也因此而更稳定。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;很多人批评工作量证明造成巨大的电力浪费，促使人们去探索新的解决一致性（共识）问题的机制：”权益证明机制（POS: Proof of Stake）”是一个代表。在拜占庭将军问题的角度来看，它同样提高了做叛徒的成本，因为账户需要首先持有大量余额才能有更多的几率广播区块。 2019-08-25更新————————————当你累了的时候，停下来做个梦吧。愿你坚持到底。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>拜占庭问题,拜占庭容错</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发与并行]]></title>
    <url>%2F2019%2F08%2F18%2F%E5%B9%B6%E5%8F%91%E4%B8%8E%E5%B9%B6%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[下面一张图片可以让你更好地理解程序中的并发与并行之间的区别： 更详细的信息，请参考链接https://golangbot.com/concurrency/]]></content>
      <categories>
        <category>计算机语言</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>并行</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DAPP到底是什么？]]></title>
    <url>%2F2019%2F08%2F14%2FDAPP%E5%88%B0%E5%BA%95%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[什么是Dapp，相比较于app，有什么不同？ 一、什么是Dapp？DAPP是Decentralized Application的缩写，即去中心化应用，也有人称为分布式应用。它被认为开启了区块链3.0时代。DAPP就是在底层区块链平台衍生的各种分布式应用，是区块链世界中的服务提供形式。DAPP之于区块链，有些类似APP之于IOS和Android。 二、Dapp的特点 1.Dapp通过网络节点去中心化操作可以运行在用户的个人设备之上，比如：手机、个人电脑。永远属于用户，也可以自由转移给任何人。2.运行在对等网络上不依赖中心服务器，不需要专门的通信服务器传递消息，也不需要中心数据库来记数据。数据保存在用户个人空间，可能是手机，也可能是个人云盘。3.数据加密后存储在区块链上可以依托于区块链进行产权交易、销售，承载没有中介的交易方式。4.参与者信息被安全存储可以保护数字资产，保证产权不会泄露、被破坏。5.Dapp必须开源、自治可以由用户自由打包生成，签名标记所属权。它的发布不受任何机构限制。 各种创意与创新可以自由表达和实现。 三、Dapp与app的区别从客户体验角度APP相对于DAPP有四大问题，一是截留用户数据，二是垄断生态平台，三是保留用户权利，四是限制产品标准扼杀创新。但是由于Dapp得到的是去中心化，所以响应速度固然没有中心化服务器快。从技术角度DAPP与APP区别主要有两个方面，一是APP在安卓或苹果系统上安装并运行；DAPP在区块链公链上开发并结合智能合约；二是APP信息存储在数据服务平台，可以运营方直接修改；DAPP数据加密后存储在区块链，难以篡改。 四、Dapp的分类根据去中心化的对象，DAPP可以进行分类。对于一个中心化服务器而言，包括计算、存储能力，以及所产生的数据三个方面，而由数据之前的关联度又产生了某种特定的“关系”。因此一般而言，去中心化包括以下几类： 1.基于计算能力的去中心化（Pow机制）2.基于存储能力的去中心化（IPFS）3.基于数据的去中心化（Steemit）4.基于关系的去中心化（去中心化ID）]]></content>
      <categories>
        <category>区块链</category>
        <category>Dapp</category>
      </categories>
      <tags>
        <tag>Dapp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语言学习]]></title>
    <url>%2F2019%2F08%2F10%2Fgo%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[go语言: 面向对象、强类型、类似c的语言。 1.同一个目录下面不能有多个package main，分到不同的文件夹中即可；2.go test *_test.go是golang特有的约定，为测试文件: go run: cannot run *_test.go files; go test 默认执行当前目录下以xxx_test.go的测试文件; go test -v 可以看到详细的输出信息; go test -v xxx_test.go 指定测试单个文件，但是该文件中如果调用了其它文件中的模块会报错; go test -v -test.run Testxxx, 该测试会测试包含该函数名的所有函数. 函数修饰符view：只能读取数据，不能更改数据；修饰符pure：不访问程序中的数据，他的返回值完全取决于传入的参数 测试代码见github 2019-08-25更新————————————当你累了的时候，停下来做个梦吧。愿你坚持到底。 2019-09-01————————————推荐给大家一个非常好的入门学习中文网站，里面很全，从基本数据类型、语法，到协程并发、高阶函数、类、多态等。go语言中文网 panic和recover参考文档：panic和recover代码在这里 头等函数参考文档：头等函数代码在这里 反射参考文档：反射代码在这里 读取文件参考文档：读取文件代码在这里 写入文件/并发写入参考文档：写入文件/并发写入代码在这里 2019-09-15更新 框架beego学习执行过程 当你累了的时候，停下来做个梦吧。愿你坚持到底。]]></content>
      <categories>
        <category>计算机语言</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[比原链-共享经济平台简介]]></title>
    <url>%2F2019%2F08%2F04%2F%E6%AF%94%E5%8E%9F%E9%93%BE-%E5%85%B1%E4%BA%AB%E7%BB%8F%E6%B5%8E%E5%B9%B3%E5%8F%B0%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[Origin Protocol ：基于以太坊，开源的共享经济平台，是否能够成功呢？ Origin Protocol ：基于以太坊，开源的共享经济平台诸如Airbnb、Uber、Craigslist、WeWork等共享经济公司出现之后，共享经济改变了整个商业世界的规则：消费者更喜欢去拥有一个事物的使用权，而不是所有权；而服务提供者从自己提供服务变成了生产者和消费者之间连接的纽带。整个商业模式发生了变化。 到2016年为止，美国有大约22%成年人成为了共享经济的供应商，共享经济平台的收入在2017年是186亿美元，而据估计在2022年会达到400多亿美元，这是一个巨大的市场。 痛点现有市场还存在哪些问题呢？ 首先，价值的分配是不公平的。都说第一个吃螃蟹的人能够获取更多的利益，但是第一个开Uber、第一个给Airbnb提供房间的人并没有因为自己是早期参与者（共建者）而受益，利益全部都在公司本身手里。 其次，高昂的终结费用。Airbnb对房客收取5%-15%手续费，对房东也收取3%-5%，Uber也会对司机和乘客收取类似比例的费用。并且在平台做大之后，他们为了垄断会把收入用在阻碍创新上。 然后，还有数据的所有权、安全性等问题。 其实上述的问题都是中心化平台出现的问题。Origin Protocol就是为解决上述的痛点开发的。 ￼ 简介Origin Protocol是基于以太坊上的共享经济平台，并用IPFS解决文件的存储问题，在分布式网络环境中促进开放、免费的服务交换。平台主要由三个部分组成： 1、 Origin Dapp：分布式应用（Dapp）服务提供者能够锁定一定的代币作为抵押来创建列表，让用户搜索服务，在Dapp中能够利用法币、ERC20代币来进行结算。在不同垂直行业可以开发不同的应用来做到定制化。并且，在Origin Protocol中注册的用户能够方便地访问基于Origin Protocol的所有应用。 2、 Origin 共享数据层和标准共享数据层能够让所有人都能够访问数据库。这些数据存储在IPFS和以太坊中，任何人都可以从中获取到列表项目、交易记录和买卖双方的信誉评级，从而能够被信任。 3、 Origin 社区基金很大一部分的资金会交与基金管理，保证平台的长期发展。基金需要负责；项目管理、项目的孵化、雇佣开发者编写以及审核代码、财务和技术审核、提供仲裁服务等。 4、Origin Protocol的特点用智能合约保证价值的点对点传播（无中介，安全可靠） 支持数百种列表类型，提供多元化的服务 用共享数据鼓励创新 利用区块链技术保证数据和身份的安全 5、团队目前，Origin的核心团队有10名成员，延伸团队有8名成员，涵盖了技术团队、社群运营专家、商业产品团队，具备了项目研发、商业落地的人力资源。核心成员来自伯克利、斯坦福等高校，拥有丰富的创业经验，其创业项目被沃尔玛、雅虎等公司收购。首席区块链工程师曾任Sphero（知名智能玩具公司）的核心技术工程师，技术团队都拥有软硬件开发的从业经历。总的来说，这是一个组成完备，从业经验丰富的团队。￼ 6、Origin Protocol代币技术层面上Origin Protocol的代币是十分复杂的，具体可以参考白皮书。一句话来说，代币的作用是用正面和负面的激励来确保平台的安全、实现管理并且促进买卖双方的交易。 一个具体的场景是，为了避免垃圾信息，卖家在实施相关措施的时候需要抵押一定的代币，通过“押金-质疑-投票”机制，鼓励用户抵押等量代币，标记出质疑的内容，社区进行投票，胜利方可以获得这些代币，通过这样的机制来避免垃圾信息。 具体代币分配暂未公布。 目前在COINLIST上开放投资者注册通道，不允许中国投资者参与，请需要参加的准备好相关材料。 7、开发路线Origin Protocol项目从17年五月开始，12月份就推出了测试网络，预计在18年第三季度完成平台的开发，19年达到去中心化并且正式运行。 合作伙伴 官网上列出大量合作伙伴，并且有不少团队已经开始基于Origin Protocol的app开发。 ￼ 总结总体来看，Origin Protocol相比于各类提出4.0、5.0概念的公链，是一个十分落地的项目，并且已经与大量的企业建立合作关系。目前Origin Protocol的测试网络已经上线，我们期待未来Origin Protocol的发展。 官网：https://www.originprotocol.com 白皮书：https://www.originprotocol.com/en/product-brief DEMO视频：https://demo.originprotocol.com 个人观点比原链如何避免共享平台的垃圾信息、虚假信息呢？比原链的解决方案是，卖家在实施相关措施的时候需要抵押一定的代币，通过“押金-质疑-投票”机制，鼓励用户抵押等量代币，标记出质疑的内容，社区进行投票，胜利方可以获得这些代币，通过这样的机制来避免垃圾信息。那在所有人都可以参与的情况下，如何保证刷单的事情发生呢？卖家同时拥有许多账号，并且进行投票给自己的竞争对手，此时，就会形成恶性竞争。]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>比原链</tag>
        <tag>公链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[公链如此多，而应用却寥寥无几]]></title>
    <url>%2F2019%2F08%2F04%2F%E5%85%AC%E9%93%BE%E5%A6%82%E6%AD%A4%E5%A4%9A%EF%BC%8C%E8%80%8C%E5%BA%94%E7%94%A8%E5%8D%B4%E5%AF%A5%E5%AF%A5%E6%97%A0%E5%87%A0%2F</url>
    <content type="text"><![CDATA[现在很多公司都在开发自己的公链，真正应用落地的很少，其中包括IBM开源，贡献给Linux基金会的HyperLedger，另一个就是以太坊了。 下面来看看为什么？ 现在很多公司都在开发自己的公链。创业团队在开发公链，一些加密数字货币交易所也在开发公链。我曾经见过一个由三个年轻人组成的创业团队，不仅开发了自己的公链，而且还提出了一个新的共识算法。但目前的公链市场却出现了一个非常尴尬的局面，一方面是公链产品无穷多，但另外一方面却是公链落地的项目寥寥无几。显然在区块链产品落地应用方面，出现了明显的脱节。当然任何一个新技术的落地应用都需要一段时间。对于区块链技术这个从根本上改变现有的以中心化技术为基础的计算模式的新技术来说，其应用落地的时间就更长。但在目前的公链产品落地应用的过程中，还是有些方面可以改进，以此来加速公链技术应用落地的。在当前的社会中，其实不缺区块链应用的落地场景。市场中的很多问题实际上都能应用区块链能得到非常好的解决。区块链技术的最强项是采用完全信息真实透明的方式杜绝欺诈，是用技术的方式保证多方的合作顺利完成。如果从这个角度看，现实中太多的问题都可以用区块链来解决了。譬如个人借贷的违约方面。违约者的一个主要动机就是因为违约成本非常低。他可以欺诈了一个出借方之后，再去欺诈另外一个欺诈方。但是如果每个人的信贷记录都真实无误地记录在公链上，任何个人和机构都能查到这个借贷记录，那么借贷者进行欺诈动机就小多了。对于一直没有被现有的金融机构服务到的客户来说，如果其在金融机构之外的各种借贷记录都真实无误的记录在区块链上，那么他个人的信用历史就是真实可信的。金融机构就可以基于这个信用向其进行贷款，因为在这个过程中，征信的成本几乎为零，而征信成本过高正是金融机构不愿意进行贷款的一个原因。在公司的层面，同样存在着大量的可以应用区块链技术的地方，譬如贸易金融和银团的联合贷款。在证券领域，区块链技术除了在交易后清算之外，另外一个最直接的应用就是投行项目的融资过程。由于上市的收获巨大，所以在这个过程中，各个参与者在各个融资阶段铤而走险进行欺诈的案例屡见不鲜。在这个过程中的一个主要欺诈方面就是信息作假。如果采用区块链技术来管理这个流程，每个参与者都需要为自己上传到链上的信息负责，那么每个参与者作假的动机就会大幅减小。即使有人铤而走险进行造假，那么此后的法律诉讼过程中的取证就非常容易，也就容易形成及时公正的判决。那么为什么现实中有这么多的需求，但于此同时基于区块的应用却为什么这么少？在这个方面既有产品通常规律中犯错的地方，也有区块链技术应用的具体问题。 1、产品同市场的需求不匹配首先，造成这种局面的原因主要还是产品与市场需求的不匹配，也就是缺少 Product Market Fit. 一些区块链技术的开发方专注于解决区块链技术本身的问题，而忽略了解决其技术应该解决的市场中的问题。一些公链项目总是在宣扬自己的产品的性能如何好，能达到多少的 TPS。但这个卖点本身就是错误的定位。首先，一个企业级技术产品的衡量指标不只是性能，而且还有稳定性、安全性、权限控制等其他方面。其次，市场中对区块链技术的评价，首先会把它同相应的中心化解决方案相比较。在性能方面，基于区块链的解决方案绝对无法同基于中心化技术的解决方案相比的。所以一味地强调性能根本无法说服市场来接受这个产品。区块链技术最擅长的解决是多方合作中的信任问题。而在现实的场景中，很多这种场景是不需要高性能的。譬如贸易金融的合作过程，又譬如企业融资过程中的各类机构合作的过程。这些过程更注重于性能以外的其他因素，如信息的一致性、权限控制和使用的便捷性等等。如果公链一味地追求性能，那么它就同市场中的真正需求南辕北辙了。 2、高度竞争的领域公链产品定位的另外一个主要错误是在开发一个同以太坊相竞争的普适的公链。但这样的产品定位，其成功的可能性极小。以太坊的问题很多，这是众所周知的。但它已经是经过几年的发展，已经基本上成为市场中默认的公链选择。现在希望取代以太坊的公链创业项目太多了。在这样的高度竞争的环境中，胜出的几率是非常小的。在这个方面，很多公链团队都做出了错误的选择。选择加入到了一个高度竞争的领域。这恰恰违背了一个产品开发的基本规律，就是避开竞争。记得彼得•蒂尔的建议避开竞争的观点吗？避开竞争的一个有效手段就是采用创新的方式来解决市场中的一个问题。因为创新一开始是并不为市场接受，所以并没有太多的竞争者做同样的事情。当创新的方式逐渐为市场接受时，这个创新产品在市场中已经占据稳定的地位了。别的团队就无法再做同样的产品进行竞争。在这个方面，中本聪发明的比特币就是此方面的最好的代表。中本聪的初衷是发行一个电子现金来取代市场中的货币。但是他并没有以直接同现有货币竞争的方式发行一种货币。比特币的金融属性直到多年以后才被市场发现，拥有了众多的用户，并开始对现有的金融市场形成了巨大的挑战。尽管后来也持续不断的有模仿者，但这些模仿者都已经无法对比特币的地位形成挑战了。 3、改变群体行为的困难区块链技术本身的特点也决定它比其它的产品更难被市场接受。这是因为它需要改变的是一个群体行为，而不是一个个体行为。譬如在多方合作的过程中，如果只有一方愿意采用基于区块链的解决方案，但其他它方没有动力的情况下，这个解决方案就没法推动。特别是当其中的一些参与方本来的想法就是利用信息的不透明来为自己谋利。那么如何才能实现区块链技术的快速落地应用呢？首先我认为从技术的角度来切入市场没问题，但更应该从需求的角度来切入市场，也就是说从市场中的一个具体的问题出发，来分析如何用区块链技术来解决这个问题。鉴于目前市场中互不信任和欺诈行为的普遍存在，所以找到这样的场景并不困难。其次才是自己开发或在市场中找到合适的区块链底层来进一步开发。而这样的区块链技术底层并不一定需要各项技术指标方面都十全十美。它只要能对针对需要解决的问题能够令人满意的解决就可以了。看一看目前的国内市场，获得市场欢迎和资本支持的一些成功的区块链项目并不是基于什么技术性能特别好的公链项目，实际上这些项目是利用的只是区块链技术最基本的分布式存储和不可更改的功能。但是这些技术底层为需要解决的问题提供了足够好的技术方案，这就足以创造很好的商业价值了。其次就是不要挑战以中心化技术为基础的现有实力最强的地方。这些领域如零售支付、稳定币、证券和银行领域中的清算。在这些领域中采用区块链技术，产生的收益未必足够大，但遇到的风险和阻力却会非常大，因此在这些领域中应用区块链技术需要非常慎重。第三，一定要用创新的方式解决现有的问题。在这方面，比特币是最优秀的典范。在现有的很多问题中，由于技术、监管、经营习惯和、成本、应用落地所需的时间和风险等方面的考虑，行业中现有的参与者们并没有很强的动力去采用区块链技术、区块链技术的应用一定要找到非常创新，容易被市场接受的地方。尽管这个初始应用的市场并不大，但只要是此方面应用的商业和技术模式具有很强的可扩展性，并且是针对潜在的巨大市场，只要项目方做好商业和技术方面的顶层设计（见我的相关文章区块链时代的顶层设计）；另外，再由于这种创新方式不一定被广泛认可，因此也不会迅速地吸引竞争者，这个方式因此就有足够的时间逐步发展起来。等到市场的各方终于发现这种创新模式的价值的时候，同它的竞争和对它的打压都已经来不及了。这就是在本质上重新复制了比特币的成功模式。 本文摘抄自链接：https://www.jianshu.com/p/58f4cce02e3f]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>公链</tag>
        <tag>区块链应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018年全球各国谋杀比例]]></title>
    <url>%2F2019%2F08%2F04%2F2018%E5%B9%B4%E5%85%A8%E7%90%83%E5%90%84%E5%9B%BD%E8%B0%8B%E6%9D%80%E6%AF%94%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[Murders rate per 100,000 people, last available year.2018年，每10万人中被谋杀的比例如下： 比例 国家 🇭🇳HON: 90 洪都拉斯 🇻🇪VEN: 54 委内瑞拉 🇧🇷BRA: 25 巴西 🇲🇽MEX 21.5 墨西哥 🇳🇬NIG: 20 尼日尔 🇷🇺RUS: 9.2 俄罗斯 🇵🇰PAK: 7.7 巴基斯坦 🇺🇸USA: 4.7 美国 🇮🇳IND: 3.5 印度 🇹🇷TUR: 2.6 土耳其 🇨🇦CAN: 1.6 加拿大 🇦🇺AUS 1.1 澳大利亚 🇨🇳CHN: 1 中国 🇬🇧GBR: 1 英国 🇫🇷FRA: 1 法国 🇰🇷KOR: 0.9 韩国 🇮🇹ITA: 0.9 意大利 🇩🇪GER: 0.8 德国 🇪🇸ESP: 0.8 西班牙 🇦🇪UAE: 0.7 阿联酋 🇯🇵JPN: 0.3 日本]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>谋杀比例</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿甘正传剪辑]]></title>
    <url>%2F2019%2F08%2F03%2F%E9%98%BF%E7%94%98%E6%AD%A3%E4%BC%A0%E5%89%AA%E8%BE%91%2F</url>
    <content type="text"><![CDATA[var player = new YKU.Player( 'youkuplayer',{ styleid: '0', client_id: 'YOUR YOUKUOPENAPI CLIENT_ID', vid: 'XNDI5NzE3Mzk0MA', newPlayer: true } );]]></content>
      <categories>
        <category>视频剪辑</category>
      </categories>
      <tags>
        <tag>阿甘正传</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[airbnb开源调度系统airflow的一些命令及使用方法]]></title>
    <url>%2F2019%2F08%2F02%2Fairbnb%E5%BC%80%E6%BA%90%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9Fairflow%E7%9A%84%E4%B8%80%E4%BA%9B%E5%91%BD%E4%BB%A4%E5%8F%8A%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[python写的调度系统，用python脚本，动态生成dag，跨dag依赖，是一个不错的调度系统，下面介绍一些我使用过程中用到的命令和问题的解决方案。 1.operator12345678BashOperatorPythonOperatorEmailOperatorHTTPOperatorSqlOperatorSensorDockerOperatorHiveOperator 2.给DAG实例传递参数执行命令 1airflow trigger_dag example_passing_params_via_test_command -c &apos;&#123;&quot;foo&quot;:&quot;bar&quot;&#125;&apos; 代码获取变量： 123def my_py_command(ds, **kwargs):logging.info(kwargs)logging.info(kwargs.get(&apos;dag_run&apos;).conf.get(&apos;foo&apos;)); 3.填补数据1234#清除dag在这段时间内的状态，清除后airflow会自动启动这些任务，如果dag设置了catchup=True;dependency_on_past=True;那么dag会按照时间顺序一天一天跑任务，这对于修补数据很有用哦airflow clear db2src_usersdb_byshell -s 2018-12-01 -e 2018-12-04#回填数据，当新建一个dag，需要补跑以前的数据，回填命令是个不错的选择airflow backfill db2src_usersdb_byshell -s 2018-12-03 -e 2018-12-04 4.根据depend_on_pastTrue or False来判断是否需要依赖start_time前段时间跑的相同的任务情况来运行现在的任务。 5.airflow卡住的问题连接元数据mysql库：select * from task_instance where state = ‘running’; 6.airflow自带变量：12345678910111213141516171819202122232425262728| Variable | Description || :------: | :---------: ||&#123;&#123; ds &#125;&#125; |the execution date as YYYY-MM-DD||&#123;&#123; ds_nodash &#125;&#125; |the execution date as YYYYMMDD||&#123;&#123; yesterday_ds &#125;&#125; |yesterday’s date as YYYY-MM-DD||&#123;&#123; yesterday_ds_nodash &#125;&#125; |yesterday’s date as YYYYMMDD||&#123;&#123; tomorrow_ds &#125;&#125; |tomorrow’s date as YYYY-MM-DD||&#123;&#123; tomorrow_ds_nodash &#125;&#125; |tomorrow’s date as YYYYMMDD||&#123;&#123; ts &#125;&#125; |same as execution_date.isoformat()||&#123;&#123; ts_nodash &#125;&#125; |same as ts without - and :||&#123;&#123; execution_date &#125;&#125; |the execution_date, (datetime.datetime)||&#123;&#123; prev_execution_date &#125;&#125; |the previous execution date (if available) (datetime.datetime)||&#123;&#123; next_execution_date &#125;&#125; |the next execution date (datetime.datetime)||&#123;&#123; dag &#125;&#125; |the DAG object||&#123;&#123; task &#125;&#125; |the Task object||&#123;&#123; macros &#125;&#125; |a reference to the macros package, described below||&#123;&#123; task_instance &#125;&#125; |the task_instance object||&#123;&#123; end_date &#125;&#125; |same as &#123;&#123; ds &#125;&#125;||&#123;&#123; latest_date &#125;&#125; |same as &#123;&#123; ds &#125;&#125;||&#123;&#123; ti &#125;&#125; |same as &#123;&#123; task_instance &#125;&#125;||&#123;&#123; params &#125;&#125; |a reference to the user-defined params dictionary||&#123;&#123; var.value.my_var &#125;&#125; |global defined variables represented as a dictionary||&#123;&#123; var.json.my_var.path &#125;&#125; |global defined variables represented as a dictionary with deserialized JSON object, append the path to the key within the JSON object||&#123;&#123; task_instance_key_str &#125;&#125; |a unique, human-readable key to the task instance formatted &#123;dag_id&#125;_&#123;task_id&#125;_&#123;ds&#125; ||conf |the full configuration object located at airflow.configuration.conf which represents the content of your airflow.cfg||run_id |the run_id of the current DAG run||dag_run | a reference to the DagRun object||test_mode | whether the task instance was called using the CLI’s test subcommand| 7.导入导出airflow变量12airflow variables --import variable.jsonairflow variables --export variable.txt 8.Template Not FoundTemplateNotFound: sh /data/airflow_dag/dags_migration/sh/export-variables.sh这是由于airflow使用了jinja2作为模板引擎导致的一个陷阱，当使用bash命令的时候，尾部必须加一个空格 12345t2 = BashOperator(task_id=‘sleep‘,bash_command=&quot;/home/batcher/test.sh&quot;, // This fails with `Jinja template not found` error#bash_command=&quot;/home/batcher/test.sh &quot;, // This works (has a space after)dag=dag) 9. 手动触发dag运行1airflow trigger_dag dag_id -r RUN_ID -e EXEC_DATE 10. 手动触发task运行1airflow run dag_id task_id EXEC_DATE 11. “Failed to fetch log file from worker”查看task_instance中hostname字段，存储的均为localhost；分析：修改/etc/hosts文件，删除127.0.0.1 hostname映射；worker log服务获取到hostname后，映射到ip后得到127.0.0.1，故无法访问到log。 12. airflow中每个task对应的执行priority计算方式dummy2 = DummyOperator( task_id=’dummy_’ + src_db, pool=’db’, priority_weight=weight, dag=dag) 所有后置依赖的priority_weight之和，最后一个任务的priority_weight如果没有自定义，默认为1，这样，在同一个pool中做到了任务优先运行；]]></content>
      <categories>
        <category>调度系统</category>
      </categories>
      <tags>
        <tag>airflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux命令相关]]></title>
    <url>%2F2019%2F07%2F28%2FLinux%E5%91%BD%E4%BB%A4%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[关于linux操作系统的一些使用命令，看下面。 1. linux下查看某个文件或文件夹占用的磁盘空间大小1du -ah --max-depth=1 2.sed修改文件在每行行首或者行尾添加相同的字符串 12sed &apos;s/^/HEAD&amp;/g&apos; text.file 每行行首添加HEADsed &apos;s/$/&amp;TAIL/g&apos; text.file 每行行尾添加TAIL 如果要修改原文件，则添加 -i参数 12sed -i &apos;s/^/HEAD&amp;/g&apos; text.filesed -i &apos;s/$/&amp;TAIL/g&apos; text.file 递归替换 1find . -type f -print0 | xargs -0 sed -i &apos;s/10.1.0.33,10.1.0.44,10.1.0.48/$&#123;es_nodes&#125;/g&apos; 文件第一行添加字符串 1sed -i &quot;1i\添加内容&quot; filename 3.查看centos版本1cat /etc/redhat-release 4.查看cpu12cat /proc/cpuinfo |grep &quot;physical id&quot;|sort|uniq|wc -l 查看cpu核数cat /proc/cpuinfo | grep &quot;cpu cores&quot; | uniq 物理cpu个数 5.查看内存1free -h 6.查看磁盘容量1df -h 7.查看端口号对应进程号1netstat -tunlp|grep 端口号 8.查看未释放空间的进程1lsof | grep deleted 9.杀死未释放空间的进程1lsof | grep deleted | awk &apos;&#123;print $2&#125;&apos; | sort | uniq | xargs kill -9 10.grep12345grep -o &quot;ods\.[a-z|A-Z|_]*&quot; ods2report.py | grep &quot;_&quot; | sort | uniq -cgrep -o只显示匹配内容uniq -c计算重复行数量grep &quot;\&quot;db\&quot;&quot; *.py | awk -F &apos;:&apos; &apos;&#123;print $1&#125;&apos; | sort | uniqgrep -o &quot;ods\.[a-z|A-Z|_|0-9]*&quot; *.py | awk -F &apos;:&apos; &apos;&#123;print $2&#125;&apos; |grep &quot;_&quot; | sort | uniq -c 11.查看详细进程信息1top -c]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hive相关]]></title>
    <url>%2F2019%2F07%2F21%2Fhive%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[下面的内容包含hive的简单操作，增删改查，权限，一些异常的解决方案。 1. 在linux命令行端执行hql语句1hive -e &apos;show table tableName&apos; 2. 在linux命令行端执行hql文件1hive -f fileName 3. 按照分区查看hive表中的数据量1hive -e &apos;select dt, count(1) from test_hive.wps_android_uuid_userid group by dt&apos; 4. 添加分区1alter table test_hive.wps_android_uuid_userid add if not exists partition (dt=&apos;2018-08-04&apos;) 5. 赋表权限1grant select on table usersdb.account_src to user w_wangzhe 6. 赋库权限12345GRANT ALL ON DATABASE DEFAULT TO USER fatkun;GRANT ALL ON TABLE test TO GROUP kpi;REVOKE ALL ON TABLE test FROM GROUP kpi;GRANT ALL TO USER fatkun;REVOKE ALL FROM fatkun; 7. 重命名1alter table data_platform.td_request_log rename to data_platform.td_request_log_old 8. Errorwhile processing statement: FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask 1set hive.auto.convert.join = false; 9.执行sql文件1hive -d etldate=&apos;2018-08-16&apos; -f loan_periods.hql 10.add jar1add jar /usr/hdp/current/hive-client/lib/commons-httpclient-3.0.1.jar; 11.add column1hive -e &quot;alter table report.user_detail_20180614 add columns(identifier_type string comment &apos;注册类型&apos;,channel string comment &apos;注册渠道&apos;)&quot; 12.load 文件到hive表本地文件： 1hive -e &quot;load data local inpath &apos;/data/code/app_list_0814.csv&apos; into table dim.dim_app_list&quot; hdfs文件： 1hive -e &quot;load data inpath &apos;/data/code/app_list_0814.csv&apos; into table dim.dim_app_list&quot; 13.列13.1修改列位置alter table factor.mf_bus_finc_app change column submit_op_no submit_op_no string after company_id 13.2增加列hive -e “alter table data_platform_new.face_request_log add columns(channel string)” 14.修改权限hive -e “grant select on table stg.risk_apply_users to user userName” 15.自定义函数12create function dateformat as &apos;com.kso.dw.hive.udf.DateFormat&apos; using jar &apos;hdfs://hdfs-ha/hiveudf/dw_hive_udf.jar&apos;;mysql -h10.0.1.160 -uadmin -pmd854NHmv3bF0kl9 hive4fac31f3 -e &apos;select name from dbs&apos; | xargs -n 1 -i echo &quot;create function &#123;&#125;.mymd5_kc as &apos;com.kso.dw.hive.udf.MyMd5_KeyCenter&apos; using jar &apos;hdfs://hdfs-ha/hiveudf/dw_hive_udf.jar&apos;;&quot; 16.全局替换1sed -i &apos;s/CREATE TABLE/CREATE EXTERNAL TABLE/g&apos; *.hql 17.not a file exceptionnot a file ks3://online-hadoop/ods/report/dt=2019-01-01/1 1set mapreduce.input.fileinputformat.input.dir.recursive=true; 18.exception1set hive.execution.engine=mr; 19. too many countersorg.apache.hadoop.mapreduce.counters.LimitExceededException: Too many counters: 121 max=120resolved:change the tez configuration 1tez.counters.max= 200 20.SHOW TRANSACTIONS12345ABORT TRANSACTIONS 4951;show locks;mysql:select * from hive_locks;select * from hive_locks where HL_TXNID &gt; 0; 21.acquiring locksFAILED: Error in acquiring locks: Lock acquisition for LockRequest(component:[LockComponent(type:EXCLUSIVE关闭事务： set hive.support.concurrency=false 22.事务表查询12345set hive.support.concurrency=true;set hive.exec.dynamic.partition.mode=nonstrict;set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;set hive.compactor.initiator.on=true;set hive.compactor.worker.threads=1; 23. 内部表转外部表1alter table default.test set TBLPROPERTIES(&apos;EXTERNAL&apos;=&apos;true&apos;); 24. 外部表转内部表1alter table tableA set TBLPROPERTIES(&apos;EXTERNAL&apos;=&apos;false&apos;) 25.修改元数据路径元数据库：123UPDATE dbs SET DB_LOCATION_URI=REPLACE(DB_LOCATION_URI,&apos;hdfs-ha&apos;,&apos;bjCluster&apos;);``` 元数据表： UPDATE sds SET LOCATION=REPLACE(LOCATION,’ks-jinrong-dw’,’online-hadoop’);UPDATE sds SET LOCATION=REPLACE(LOCATION,’hdfs-ha’,’bjCluster’); 1自定义函数： UPDATE func_ru SET RESOURCE_URI=REPLACE(RESOURCE_URI,’hdfs-ha’,’bjCluster’); 123# 26.set role admin# 27.控制map个数 set mapred.max.split.size=400000000;set mapred.min.split.size.per.node=400000000;set mapred.min.split.size.per.rack=400000000;set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;]]></content>
      <categories>
        <category>IT</category>
        <category>hive</category>
      </categories>
      <tags>
        <tag>hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[debezium实时同步mysql、postgresql数据介绍]]></title>
    <url>%2F2019%2F07%2F20%2Fdebezium%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5mysql%E3%80%81postgresql%E6%95%B0%E6%8D%AE%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[给大家介绍一个实时同步数据库的组件debezium，它可以同步mysql、postgresql、mongo、oracle、sql server数据库到hdfs、kafka，功能强大，具体如下。 大致安装步骤： 1.插件decoderbufs或者wal2json2.postgresql配置logical等3.confluent平台搭建4.配置connector 参考文档：https://debezium.io/docs/connectors/ for postgresql to kafka 核心：一个active slot，多个connector 1. bin/connect-distributed etc/kafka/connect-distributed.properties三台服务器分别执行启动distributed服务（相同的slot.name、group.id保证复制同一个slot replication，保证在同一个组内） 123bin/connect-distributed etc/kafka/connect-distributed-8084.propertiesbin/connect-distributed etc/kafka/connect-distributed-8085.propertiesbin/connect-distributed etc/kafka/connect-distributed-8086.properties 2. bin/connect-standalone etc/kafka/connect-standalone.properties etc/kafka-connect-postgres/debezium.propertiesbin/kafka-console-consumer –zookeeper localhost:2182 –topic postgres.localhost.public.test –from-beginning 3. 安装decoderbufs、wal2json pluginhttps://github.com/debezium/postgres-decoderbufs/blob/master/README.mdhttps://github.com/eulerto/wal2json/blob/master/README.md 安装wal2json时出现的问题：Makefile:10: /usr/lib64/pgsql/pgxs/src/makefiles/pgxs.mk: No such file or directoryyum install postgresql10-devel即可 4. 配置参考文档：https://zhubingxu.me/2018/06/05/debezium-postgres/ share/java/下创建debezium文件夹，创建文件debezium.properties： 1234567891011121314name=events-debeziumtasks.max=1connector.class=io.debezium.connector.postgresql.PostgresConnectordatabase.hostname=localhostdatabase.port=5432database.user=postgresdatabase.password=postgresdatabase.dbname=postgresdatabase.history.kafka.bootstrap.servers=localhost:9092database.server.id=1database.server.name=postgres.localhostplugin.name=wal2jsoninclude.schema.changes=trueslot.name=my\_slot\_name 5. 异常Error while fetching metadata with correlation id 1 : {postgres.localhost.public.test=LEADER_NOT_AVAILABLE} https://stackoverflow.com/questions/35788697/leader-not-available-kafka-in-console-producer 配置debezium中$DEBEZIUM_HOME/etc/kafka/server.properties 指定参数advertised.host.name ERROR A logical replication slot named ‘debezium’ for plugin ‘wal2json’ and database ‘postgres’ is already active on the server.You cannot have multiple slots with the same name active for the same database (io.debezium.connector.postgresql.connection.PostgresReplicationConnection:104) 在创建connector的配置参数中添加新的slot.name，slot.name的规范必须为字母数字下划线。不指定的话默认为debezium，会产生冲突。 6. 分布式kafka connector配置：https://archive.cloudera.com/kafka/kafka/2/kafka-0.9.0-kafka2.0.1/connect.html分布式connector需要通过rest api进行增删改 https://mapr.com/docs/52/Kafka/Connect-distributed-mode.html connect-distributed.properties 连接参数配置：https://debezium.io/docs/connectors/postgresql/#connector-properties 7. 注意：table.whitelist格式：schemaName.tblname 如果启动connector出现权限不足时：需要给用户赋update权限： GRANT SELECT, UPDATE ON TABLE test TO debezium; 不监控无主键的表 8. 查看postgresql slota.登陆：psql -U user -d db -h host -p port -Wb.查看所有slot： select * from pg_replication_slots;c.添加slot：SELECT * FROM pg_create_physical_replication_slot(‘pg96_102’);d.删除slot：SELECT * FROM pg_drop_replication_slot(‘pg96_102’); for mysql to kafka 核心：启动多个connector即可 1. 账户及权限mysql user: debezium:******* GRANT SELECT, RELOAD, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO ‘debezium’ IDENTIFIED BY ‘******‘; 2. 配置https://debezium.io/docs/connectors/mysql/#setting-up-mysql 3. 启动bin/connect-standalone etc/kafka/connect-standalone.properties share/java/debezium/mysql-debezium-8087.properties 三台服务器分别运行： 123bin/connect-distributed etc/kafka/mysql-connect-distributed-8134.propertiesbin/connect-distributed etc/kafka/mysql-connect-distributed-8134.propertiesbin/connect-distributed etc/kafka/mysql-connect-distributed-8134.properties 4. kafka connector请求添加connector-task，随便在哪一台服务器添加1个task curl -X POST -H “Content-Type: application/json” –data @share/java/debezium/mysql-8134.json http://localhost:8134/connectors table.whitelist格式：dbname.tblname 测试环境test-hadoop：/mnt/confluent下生成的topic名称为：servername.dbname.tblname 5. 异常（未解决） 如果有解决方案，请联系我邮箱chenzuoli709@163.com，不胜感激。]]></content>
      <categories>
        <category>组件</category>
      </categories>
      <tags>
        <tag>实时同步</tag>
        <tag>mysql</tag>
        <tag>oracle</tag>
        <tag>postgresql</tag>
        <tag>mongo</tag>
        <tag>sql server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[英国构成国]]></title>
    <url>%2F2019%2F07%2F07%2F%E8%8B%B1%E5%9B%BD%E6%9E%84%E6%88%90%E5%9B%BD%2F</url>
    <content type="text"><![CDATA[英国，全称为大不列颠及北爱尔兰联合王国（United Kingdom of Great Britain and Northern Ireland），世界第五大经济体。 听说，去了北爱尔兰，不要说英格兰好，不然会被打，哈哈 地理位置： 构成国： 各构成国详情：]]></content>
      <categories>
        <category>世界国家</category>
      </categories>
      <tags>
        <tag>英国</tag>
        <tag>北爱尔兰</tag>
        <tag>英格兰</tag>
        <tag>苏格兰</tag>
        <tag>威尔士</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[世界各国人民平均汽车拥有量]]></title>
    <url>%2F2019%2F06%2F29%2F%E4%B8%96%E7%95%8C%E5%90%84%E5%9B%BD%E4%BA%BA%E6%B0%91%E5%B9%B3%E5%9D%87%E6%B1%BD%E8%BD%A6%E6%8B%A5%E6%9C%89%E9%87%8F%2F</url>
    <content type="text"><![CDATA[【世界银行：每1000人拥有的汽车数量，美国为837辆最高，中国为173辆】 具体排名如下： 美国：837澳大利亚：747意大利：695加拿大：670日本：591德国：589英国：579法国：569马来西亚：433俄罗斯：373巴西：350墨西哥：297沙特：209土耳其：199伊朗：178南非：174中国：173印度尼西亚：87尼日利亚：64印度：22]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>汽车</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[说英语的国家]]></title>
    <url>%2F2019%2F06%2F28%2F%E8%AF%B4%E8%8B%B1%E8%AF%AD%E7%9A%84%E5%9B%BD%E5%AE%B6%2F</url>
    <content type="text"><![CDATA[有哪些以英语为母语的国家呢？ 参照下图，印度人说的最多。 英语学起来，走向全世界。]]></content>
      <categories>
        <category>语言</category>
      </categories>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[世界十大语言排名]]></title>
    <url>%2F2019%2F06%2F11%2F%E4%B8%96%E7%95%8C%E5%8D%81%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%8E%92%E5%90%8D%2F</url>
    <content type="text"><![CDATA[世界语言排名，瑞士社会学家按照母语、第二语言、国家经济实力、科学外交重要性、社会、文学地位等方面进行综合评价，得出如下排名。 瑞士社会家者George Weber提出了这样的语言评价体系（图）： 具体来说，评价语言地位需要按这6条标准加权评分综合考虑： 1. 以该语言为母语人数:最高得分 4 2. 以该语言为第二语言的人数: 最高得分 6 3. 使用该语言国家的经济实力: 最高得分8 4. 科学、外交中该语言的重要性:最高得分8 5. 使用该语言的国家数和人口数：最高得分7 6. 该语言的社会、文学地位：最高得分4分（如果是联合国工作语言加1分） 一种语言，在当今世界上处于什么样的排名，地位如何，主要取决于6个指标。 1 使用某种语言的母语人口数量。 （Number of native speakers of the language） 评分：4分 2 使用某种语言的非母语人口数量。 （Number of non-native speakers of the language） 评分：6分 3 使用这种语言的国家数量与人口。 （Number and population of countries using the language） 评分：7分 4 使用这种语言的国家的经济，科技与军事实力。 （Economic, scientific and military power of the countries using the language） 评分：8分 5 在外交，国际贸易，国际组织，学术交流等领域使用这种语言的频率。 （Number of major fields, such as diplomacy, international trade relations, international organizations and academic community, using the language globally） 评分：8分 6 在社会人文领域的声望。（例如：某种语言获得过多少次诺贝尔文学奖，某种语言有过多少世界名著等等） （International socio-literary prestige of the language） 评分：4分 （如果是联合国的官方语言，额外加3分） 上面6个指标，就是判断一种语言在当今世界的排名，地位的综合指标。满分是40分。按母语人口排序的前10名是： 12345678910（1）中文（占世界总人口20.7%）（2）英语（6.2%）（3）西班牙语（5.6%）（4）印地、乌尔都语（4.7%）（5）阿拉伯语（3.8%）（6）孟加拉语（3.5%）（7）巴西葡萄牙语（3.0%）（8）俄语（3.0%）（9）日语（2.3%）（10）德语（1.8%） 值得注意的是法语连前10名都没有进，仅排在第13位（1.4%），险胜排在第14位的韩语。 再看第二项指标：有多少人以该语言为第二语言： 12345678910（1）法语（约1亿8千万）（2）英语（约1亿5千万）（3）俄语（约1亿2千万）（4）葡萄牙语（约3000万）（5）阿拉伯语（约2400万）（6）西班牙语（约2200万）（7）中文（约2100万）（8）德语（约2000万）（9）日语（约1000万）（10）印地语 当然括号中的数字只是大致的估算，不是也不可能是科学统计，但先后顺序大致是不错的。 George Weber先生对其他4项指标也做了估算，限于篇幅不一一叙述，他最后排出了世界语言的前十名： 根据上面那6个指标，所做出的排名 12345678910 第一名：英语 37分 第二名：法语 23分 第三名：西班牙语 20分 第四名：俄语 16分 第五名：阿拉伯语 14分 第六名：汉语 13分 第七名：德语 12分 第八名：日语 10分 第九名：葡萄牙语 10分 第十名：印地语 9分 综上总结： 全球性交流媒介：英语 洲际交流媒介：法语、西班牙语、俄语、阿拉伯语、葡萄牙语]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Turkish]]></title>
    <url>%2F2019%2F05%2F21%2FTurkish%2F</url>
    <content type="text"><![CDATA[土耳其，一个横跨欧亚大陆，南临地中海，东南与叙利亚、伊拉克接壤，西临爱琴海，并与希腊以及保加利亚接壤，东部与格鲁吉亚、亚美尼亚、阿塞拜疆和伊朗接壤，有热气球的浪漫国家，这边的人民对于工作有什么想法呢？ Where Turkish workers would like to move for work. US Germany Italy Canada UK France Australia Japan Russia China South Korea Brazil India Saudi Argentina (BCG) US.]]></content>
  </entry>
  <entry>
    <title><![CDATA[儿童贫困率排行]]></title>
    <url>%2F2019%2F05%2F19%2F%E5%84%BF%E7%AB%A5%E8%B4%AB%E5%9B%B0%E7%8E%87%E6%8E%92%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[世界儿童贫困率排行，来看看。 Child poverty rate, 2016. (%) 🇨🇳CHN: 33.1%🇧🇷BRA: 30.1%🇹🇷TUR: 25.3%🇮🇳IND: 23.6%🇪🇸ESP: 22.1%🇺🇸USA: 20.9%🇲🇽MEX: 19.7%🇮🇹ITA: 18.3%🇨🇦CAN: 17.1%🇯🇵JPN: 13.9%🇦🇺AUS: 13.0%🇬🇧GBR: 11.8%🇫🇷FRA: 11.3%🇩🇪GER: 11.2%🇨🇭SUI: 9.5%🇸🇪SWE: 8.9%🇰🇷KOR: 7.1%🇫🇮FIN: 3.3%🇩🇰DEN: 2.9% (OECD)]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>儿童</tag>
        <tag>贫困率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[世界失业率排行]]></title>
    <url>%2F2019%2F05%2F19%2F%E4%B8%96%E7%95%8C%E5%A4%B1%E4%B8%9A%E7%8E%87%E6%8E%92%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[来看看倒数第一是谁，哈哈。 失业率排行：South Africa（南非）: 27%Nigeria（尼日利亚）: 23%Spain（西班牙）: 14.7%Turkey（土耳其）: 14.7%Brazil（巴西）: 12.7%Iran（伊朗）: 12.2%Italy（意大利）: 10.2%France（法国）: 8.7%Egypt（埃及）: 8.1%Pakistan（巴基斯坦）: 5.9%Canada（加拿大）: 5.7%Australia（澳大利亚）: 5.2%Indonesia（印度尼西亚）: 5%Russia（俄国）: 4.7%UK（英国）: 3.8%US（美国）: 3.6%India（印度）: 3.5%Germany（德国）: 3.2%Mexico（墨西哥）: 3.2%Japan（日本）: 2.5% 此列不包含一些发达国家和未公布失业率的国家。]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>失业率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Starbucks]]></title>
    <url>%2F2019%2F05%2F14%2FStarbucks%2F</url>
    <content type="text"><![CDATA[Starbucks，founded at March 31, 1971. It is an American coffee company and coffeehouse chain. 2018年全球员工总数：29.1万 在欧洲的门店数量： 英国：1,030土耳其：470法国：175德国：168西班牙：154俄罗斯：135荷兰：106爱尔兰：82波兰：72瑞士：65罗马尼亚：46捷克共和国：40希腊：31匈牙利：28比利时：26挪威：23葡萄牙：23奥地利：19 （星巴克） 星巴克，一个卖咖啡的，不仅给了我们咖啡、空间，就业也是它对社会的价值。]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>Starbucks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[美国软件巨头Oracle简介]]></title>
    <url>%2F2019%2F05%2F11%2F%E7%BE%8E%E5%9B%BD%E8%BD%AF%E4%BB%B6%E5%B7%A8%E5%A4%B4Oracle%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[甲骨文公司（英语：Oracle，NASDAQ：ORCL）是一间全球性的大型企业软件公司。总部位于美国加州红木城的红木岸（Redwood Shores），现时首席执行官为公司创办人劳伦斯·埃里森（Lawrence J. Ellison）。甲骨文是继微软后，全球收入第二多的软件公司。随着中美之间的贸易摩擦升级，美国软件巨头Oracle公司撤离中国区研发中心，只留下销售部门。这个软件巨头什么来历呢？ 发展历史 1977年劳伦斯·埃里森、鲍勃·迈纳（Bob Miner）、埃德·奥茨（Ed Oates）在美国加州资成立公司，名为软件发展实验室（Software Development Laboratories，SDL)。其中创始人拉里·埃里森以670亿美元的身价排名全球第六。1978年，开发出第一版甲骨文系统（Oracle），以汇编语言写成；1979年，更名为关连式软件公司（Relational Software, Inc.，RSI)。1982年，推出甲骨文系统，公司也更名为甲骨文系统公司（Oracle Systems Corporation）；2016年，每年的研发投入$22亿美金，应用软件收入$70亿美金，中间件收入$10亿美金。30,000应用软件客户，30,000中间件客户，270,000数据库客户。Oracle 在云端 SaaS 上的收入已为全球最大。 产品 主要分两类：1.服务器及工具 数据库服务器：12c 应用服务器：Oracle WebLogic Application Server 开发工具：Oracle JDeveloper，Oracle Designer，Oracle Developer，等等 2.应用软件 应用软件包与2010年9月20日甲骨文OpenWorld大会上推出的Oracle Fusion Application，一个全面的模块化的应用包； 企业资源计划（ERP）软件。已有10年以上的历史。2005年，并购了开发企业软件的仁科软件公司以增强在这方面的竞争力； 客户关系管理（CRM）软件。自1998年开始研发这种软件。2005年，并购了开发客户关系管理软件的希柏软件公司（Siebel）； 人力资源管理（HCM），收购了仁科（PeopleSoft）软件； 操作系统SolarisOracle Linux 虚拟技术Oracle VMVirtualBox Java平台JavaGlassFish（Sun Java System Application Server）WebLogic 数据库管理系统Oracle数据库Berkeley DBMySQLJava DB 云计算Oracle Cloud下图是Oracle Cloud在全球市场份额占比： 其它软件NetBeansSun Grid EngineSun Studio 都有自己的操作系统了，真的厉害]]></content>
      <categories>
        <category>公司</category>
      </categories>
      <tags>
        <tag>软件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全球各国人均GDP排行]]></title>
    <url>%2F2019%2F05%2F07%2F%E5%85%A8%E7%90%83%E5%90%84%E5%9B%BD%E4%BA%BA%E5%9D%87GDP%E6%8E%92%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[在这个世界上，人均GDP的提高，不仅需要天时地利，更重要的是人和。来看看全球各国人均GDP排行吧，并介绍下人均GDP最高的国家：卢森堡大公国。 2018年度全球各国人均GDP排名如下：来介绍下人均收入最高的卢森堡大公国吧： 基本信息 语言：卢森堡语、德语、法语 首都：卢森堡市 货币：欧元 国土面积：0.25万平方公里 简介卢森堡是欧盟成员国，因境内有欧洲法院、欧洲审计院、欧洲投资银行等多个欧盟机构被称为继布鲁塞尔和斯特拉斯堡之后的欧盟“第三首都”。卢森堡实行君主立宪制。 国家元首为卢森堡大公，也是目前欧洲唯一的一个大公国。而行政权则由内阁行使。国会共有60个席位，议员任期为5年。 地理位置卢森堡位于西欧内陆，地势北高南低，东邻德国，南接法国，北部和西部同比利时接壤。北部为阿登高原，森林茂密，南部为丘陵。气候温和，属温带海洋性气候，风景优美。首都卢森堡城有“花都”之称。铁矿丰富。这里也是中世纪的要塞。最高点为布尔格普拉兹峰，海拔约550米。 经济自1999年以来，卢森堡一直是欧元区的一部分。卢森堡的经济过去以工业为主，现在卢森堡则是全球最大的金融中心之一。卢森堡是欧元区内最重要的私人银行中心及全球第二大的投资信托中心（仅次于美国）。 1）银行：仅次于美国的世界第二、欧洲最大的基金管理中心； 2）阿塞洛尔—米塔尔集团（Arcelor-Mittal）：卢第一大企业，世界第一大钢铁集团； 3）欧洲卫星公司（SES GLOBAL）：成立于1985年，拥有卫星数量52颗，居欧洲首位、世界第二，其卫星信号全球覆盖率达99.999%。1.22亿欧洲家庭可接收该公司卫星转播的2400套电视、电台节目； 4）卢森堡货运航空公司（Cargolux Airlines International）：成立于1970年，是欧洲最大全货运航空公司，拥有波音747货机26架，员工1856人，航线90多条，覆盖全球50多个国家和地区； 5）卢森堡广播电视公司（RTL）：该公司系卢与德 [5] 国联合组建的欧洲最大的视听媒体集团，拥有40个电视台和33个广播电台。 教育教育体制中卢、德、法三语循序渐进，并行不悖。小学低年级用卢森堡语授课，高年级开始用德语讲习，中学开始再转化成法语。熟练掌握这三门语言是当地中学毕业的必要条件。 人种卢森堡的外国侨民特别多，占全国人口的三成以上，最大的移民团体是葡萄牙人和意大利人。他们也同时带来了自己的语言。不过，葡萄牙语和意大利语基本只限于移民团体内部交流，在大范围内运用并不广泛。 宗教多数信奉天主教，亦有部分信奉其他宗教（包含基督新教和犹太教）。]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>GDP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[截至2019年5月5日世界上最富有的人排行]]></title>
    <url>%2F2019%2F05%2F05%2F%E6%88%AA%E8%87%B32019%E5%B9%B45%E6%9C%885%E6%97%A5%E4%B8%96%E7%95%8C%E4%B8%8A%E6%9C%80%E5%AF%8C%E6%9C%89%E7%9A%84%E4%BA%BA%E6%8E%92%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[截至2019年的最富有的人。（以十亿美元计） 马云在2018年7月已跌出亚洲首富，现为印度人穆克什·安巴尼，世界排名如下： 12345678910🇺🇸杰夫·贝索斯：161 亚马逊 电子商务 美国🇺🇸比尔·盖茨：102 微软 软件 美国🇫🇷伯纳德·阿诺特：94 LVMH集团总裁 奢侈品 法国🇺🇸沃伦·巴菲特：90 伯克希尔哈撒韦 投资、咨询 美国🇺🇸马克·扎克伯格：73 Facebook 社交 美国🇺🇸拉里·埃里森：67 甲骨文Oracle 软件服务 美国🇪🇸阿曼西奥·奥特加：66 Zara 服装零售 西班牙🇲🇽卡洛斯·斯利姆：61 卡尔索集团 商业、电信 墨西哥🇮🇳穆克什·安巴尼：56 信诚工业集团 商业 印度🇺🇸迈克尔·布隆伯格：55 彭博 媒体、慈善 美国]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>世界财富排名</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全球最受欢迎的无广告网站-维基百科]]></title>
    <url>%2F2019%2F05%2F04%2F%E5%85%A8%E7%90%83%E6%9C%80%E5%8F%97%E6%AC%A2%E8%BF%8E%E7%9A%84%E6%97%A0%E5%B9%BF%E5%91%8A%E7%BD%91%E7%AB%99-%E7%BB%B4%E5%9F%BA%E7%99%BE%E7%A7%91%2F</url>
    <content type="text"><![CDATA[全球最受欢迎的网站排行，前三当属Google、YouTube、Facebook，没有广告、最受欢迎的网站呢，当属wikipedia莫属。没有广告的维基百科，收入从哪里来呢，谁在运营？ 下面来看看该网站的基本信息： 创建日期：2001-01-15创始人：吉米·威尔士与拉里·桑格持有者：维基媒体基金会（非营利组织）总部：美国网站类型：自由内容、自由编辑的网络百科全书名称来源：Wikipedia是混成词，分别取自于网站核心技术“Wiki”以及英文中百科全书之意的“encyclopedia”语言：301种官方网站：维基百科 哈哈，你能访问吗？ 根据知名的Alexa Internet其网络流量统计数字指出全世界总共有近3.65亿名民众使用维基百科，且维基百科也是全球浏览人数排名第五高的网站，同时也是全世界最大的无商业广告的网站。 目前网站运营资金来源于捐款，在wikipedia18岁生日的时候，Google捐款310万美元，10年接收捐款总额超过7500万美元。]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>维基百科</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链三大公链Dapp平台ETH、EOS、TRON对比]]></title>
    <url>%2F2019%2F04%2F27%2F%E5%8C%BA%E5%9D%97%E9%93%BE%E4%B8%89%E5%A4%A7%E5%85%AC%E9%93%BEDapp%E5%B9%B3%E5%8F%B0ETH%E3%80%81EOS%E3%80%81TRON%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[区块链三大公链Dapp平台ETH、EOS、TRON对比，根据创始人经历、平台共识机制、平台发展历程、目前发展现状等方面进行对比，寻找最有可能实现未来去中心化操作系统的平台。 一、创始人1.ETH以太坊创始人：维塔利克·布特林（Vitalik Buterin） 出生日期：1994年1月31日 国籍：俄罗斯裔加拿大人 学历：加拿大滑铁卢大学肄业 区块链经历：2012年17岁时从他父亲那里了解了比特币，开始研究比特币、为比特币杂志写文章转比特币稿费，当时出版社给他一篇文章5个比特币；2013年18岁时获得奥林匹亚资讯奖铜牌，经常去访问其他国家的比特币社区开发人员，讨论比特币的发展与问题；2014年19岁自加拿大滑铁卢大学休学；该年11月，公布《以太坊白皮书》初版，开始募集开发者；2015年20岁获得硅谷知名的亿万富翁设立的泰尔奖学金10万美元成立非营利组织以太坊基金会，全职在以太坊工作；在迈阿密的比特币会议公开发表以太坊计画，该年7月，启动以太坊计画众售募资，募得3.1万枚比特币（当时约合1840万美元）2016年21岁以太坊最初版本Frontier问世、以太币开始在世界各地交易所公开交易2017年22岁被《财星》杂志评选为2016年40岁以下的40大杰出人物 2.EOS柚子创始人：丹尼尔·拉里默（Daniel Larimer） 出生日期：未查到 国籍：美国 学历：2003年毕业于佛吉尼亚大学计算机系本科学士学位 区块链经历：2009年对比特币感兴趣，开始了解；2013年创建BitShares去中心化交易所，是一个拥有钱包, 账本, 交易所, 货币系统，社群与一身的产品，与之对应的是BTS(比特股)虚拟货币的发行，目前市值排名51；2016年离开BitShares创建Steem区块链平台和利用区块链技术实现的社交app steemit，该平台可以对用户的创作予以代币奖励；项目完成后，2017年7月发布EOS白皮书，提供分散式应用程序托管﹑智能合约功能与分散式储存的企业方案，解决比特币和以太坊等区块链的可扩展性问题，并消除用户的交易费用。成立了Block.One公司并搭建了EOSIO平台，并发行以ERC-20方式发行1亿枚EOS代币 3.TRON波场创始人：孙宇晨 出生日期：1990年 国籍：中国 学历：北京大学、宾夕法尼亚大学硕士 区块链经历：2013年以前投资比特币，获得二十倍以上收益；由于比特币的投资经历，孙宇晨活跃于美国比特币社区，并对加密货币，去中心化清算协议产生了极其浓厚的兴趣。经过长期调查与研究，他对于诞生于加州硅谷的全球第一个分布式清算支付网络协议——Ripple协议产生了极其浓厚的兴趣。2013年底加入RippleLabs，成为Ripple协议缔造者与研发者中的一员；2014年，他回国创立锐波并兼任CEO，锐波也成为中国首家从事去中心化清算系统产品开发的互联网科技公司；2017年，孙宇晨在“世界区块链峰会上”发表《From it to bit》主题演讲，讲述了互联网的发展历史，阐释了web 4.0的观点。7月，随后推出了自己所做的项目：波场TRON，发布波场白皮书，基于区块链的开源去中心化内容娱乐协议，致力于利用区块链与分布式存储技术，构建一个全球范围内的自由内容娱乐体系，这个协议可以让每个用户自由发布，存储，拥有数据，并通过去中心化的自治形式，以数字资产发行，流通，交易方式决定内容的分发、订阅、推送，赋能内容创造者，形成去中心化的内容娱乐生态。2018年7月，完成了对于BitTorrent及其旗下所有产品的收购，并将其并入到波场生态中。 二、区块链共识机制先来介绍下三种共识机制的概念 POW：Proof Of Work工作量证明机制：通过计算机随机不停地计算得到指定hash值后获得记账权，并将区块链接到区块链上的机制，每个获得记账权的矿工会获得一定的代币，作为记账的奖励，这个过程俗称挖矿。 POS：Proof Of Stake权益证明机制：人们对于POW日趋中心化的算力分布(矿池)心怀忌惮之际，产生了权益证明机制，即对于验证人/节点的奖励，不是通过算力挖矿，而是通过持币而产生利息，这里就要引入一个概念叫做—币龄，币龄=币量x持有天数。这是根据你持有货币的量和时间，给你发利息的一个制度。当你获得了利息以后，你的所有币龄将被清空，你的持币时间将从0重新算起。 DPOS：Delegated Proof Of Stake委托权益证明机制：可以说DPOS是POS共识机制理念的一个变种。先通过选举，产生若干超级节点；后续记账权将以相同概率分配于超级节点中。它有点像是议会制度或人民代表大会制度。如果代表不能履行他们的职责(当轮到他们时，没能生成区块)，他们会被除名，网络会选出新的超级节点来取代他们。DPOS让每一个持有代币的人都有权利通过投票给验证人的方式行使自己的权利，利用科技的手段实现民主治理。 1.ETH 第一阶段，边境（Frontier，2015年7月）以太坊的第一次版本发布，允许开发人员对以太坊进行挖矿，并基于以太坊进行 DApp 与工具软件的开发。 第二阶段，家园（Homestead，2016年3月）发布了第一个生产环境版本，对许多协议进行了优化改进，为之后的升级奠定了基础，并且加快了交易速度。 第三阶段，大都会（Metropolis，2017年10月）第三阶段分为两次升级，分别命名为拜占庭（Byzantium，2017年10月）和君士坦丁堡（Constantinople，2019年1月），将会使得以太坊更轻量、更快速、更安全。 第四阶段，宁静（Serenity，时间待定）这个版本将会使用期待已久的 PoS 共识，其中将会使用 Casper 共识算法。 目前第三阶段已升级完成，所以ETH仍然使用POW共识机制。 2.EOSDPOS目前已选出21个超级节点进行选举出块。 3.TRONDPOS 第一阶段：Exudos，出埃及记数据自由-基于点对点的分布式的内容上传、存储和分发机制。出埃及记阶段，波场（TRON）将建立在以IPFS为代表的分布式存储技术之上，为用户提供一个可以完全自由可依赖的数据发布，存储，传播平台。 第二阶段：Odyssey，奥德赛（2019年1月-2020年6月，2019年5月发布2.0，9月发布3.0）内容赋能-经济激励赋能内容生态。区块链技术，将为内容产生，分发，传播建立一整套充分竞争、回报公平的经济机制，激励个体，赋能内容，从而不断拓展系统的边界。 第三阶段：Great Voyage（2020年7月-2021年7月）伟大航程，人人发行数字价值。波场（TRON）基于区块链的优势，解决了收益衡量、红利发放和支持者管理三大难题，实现了从“粉丝经济”向“粉丝金融”的重大转变，波场（TRON）基于区块链以波场币（TRX）为官方代币的自治经济体系使得个人内容生产者在体系内的每一笔收入和支出都公开、透明且不可篡改，通过智能合约，支持者们可以自动参与内容生产者的数字资产购买并按照约定自动共享红利成长，不需要任何第三方进行监督即可公正地完成全部流程。 第四阶段：Apollo，阿波罗（2021年8月-2023年3月）价值自由流动-去中心化的个体专属代币交易。当每一个波场（TRON）体系内的内容生产者都可以发行自己的专属代币，则系统必须拥有一整套完整的去中心化交易所解决方案，方能实现价值的自由流动。 第五阶段：Star Trek，星际旅行（2023年4月-2025年9月）流量变现-去中心化的博弈与预测市场。全球博弈市场规模2014年超过4500亿美元。波场（波场（TRON））内容平台所带来的流量，为构建去中心化的线上博弈平台提供了可能。开发者可以通过波场（TRON）自由搭建线上博弈平台，提供全自治的博弈预测市场功能。 第六阶段：Eternity，永恒之地（2025年10月-2027年9月）流量转化-去中心化的游戏。2016年，全球电子游戏市场规模达996亿美元，其中手机游戏市场规模461亿美元，占比42%。波场（波场（TRON））为构建去中心化的线上游戏平台提供了可能。开发者可以通过波场（TRON）自由搭建游戏平台，实现游戏开发众筹，并为普通投资者提供参与投资游戏的可能。 目前第二阶段升级到1.0版本。 平台功能ETH1.Smart Contract：智能合约2.EVM：以太坊虚拟机，提供智能合约运行的分布式区块链环境3.ICO：发币融资（如：BNB）4.DAPPs5.转账 EOS1.Smart Contract：智能合约2.ICO：发币融资3.DAPPs4.转账 TRON1.内容上传、存储和分发2.给予内容创作者奖励3.ICO（未实现）4.去中心化的博弈与预测市场（未实现）5.去中心化游戏（未实现）6.DAPPs7.转账 三、平台目前发展现状实时数据据 DAppTotal4月29日数据显示，过去一周，综合对比 ETH、 EOS、 TRON四大公链的 DApp生态情况发现： 总用户量(个)EOS(292,337)&gt; TRON(87,261)&gt; ETH(31,678)； 总交易次数(笔)EOS(26,393,841)&gt; TRON(9,856,747)&gt; IOST(2,360,126)&gt; ETH(373,918)； 总交易额(美元)EOS(144,852,700)&gt; TRON(88,426,176)&gt; ETH(39,182,195)； 跨四条公链按用户量 TOP3 DAppsEOS Global(EOS)、 Endless Game(EOS)、 Lore Free(EOS)； 按交易次数 TOP3 DAppsHash Baby(EOS)、 TRONbet(TRON)、 Dice(EOS)； 按交易额 TOP3 DAppsTRONbet(TRON)、 EOS Global(EOS)、 TronWoW(TRON)。 统计数据尴尬，这个网站：State of Dapps 没有统计TRON平台的数据。 转账交易速度TPS由于平台共识机制不同，导致去中心化程度、运行速度也不同，下面是几大平台交易速度：其中EOS，TPS可达3500.比其他几大平台都快。 这些是目前公共区块链平台的一些基本信息，希望对大家有用，如有错误的地方还请指正，联系方式：chenzuoli709@163.com，一起交流学习。]]></content>
      <categories>
        <category>数字货币</category>
      </categories>
      <tags>
        <tag>Dapp</tag>
        <tag>区块链</tag>
        <tag>公链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[世界上钻石价格排行]]></title>
    <url>%2F2019%2F04%2F27%2F%E4%B8%96%E7%95%8C%E4%B8%8A%E9%92%BB%E7%9F%B3%E4%BB%B7%E6%A0%BC%E6%8E%92%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[世界上最贵的钻石，在哪里呢，来看看。 1.Koh-i-Noor: 现在英国，产地印度，21.12 g，无价；2.The Sancy: 现在印度，11.046 g，无价3.The Cullinan: 现在英国，产地南非，1905年被发现时621.35g，后来被拆分成105颗，价值4亿美元；4.The Hope Diamond: 现在美国，产地印度9.11g，价值3.5亿美元；5.Millennium Star: 属于戴比尔斯集团，产地扎伊尔，40.6.8g，价值1.29亿美元；6.Centenary Diamond: 属于戴比尔斯集团，产地南非，54.77g，价值1亿美元；7.Pink Star: 属于戴比尔斯集团，产地南非，11.92g，价值7千万美元；8.The Regent Diamond: 现在法国，产地印度，28.12g，价值6200万美元；]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>钻石</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全球奢侈珠宝品牌排名]]></title>
    <url>%2F2019%2F04%2F24%2F%E5%85%A8%E7%90%83%E5%A5%A2%E4%BE%88%E7%8F%A0%E5%AE%9D%E5%93%81%E7%89%8C%E6%8E%92%E5%90%8D%2F</url>
    <content type="text"><![CDATA[珠宝首饰一直是人们爱美时的装饰品，一直都是如此，下面来看下全球珠宝首饰排名，了解世界品牌。 10 萧邦choppard国家：瑞士创建日期：1860年创始人：路易•尤利斯•萧邦简介：除了制作奢华的瑞士手表外，萧邦的房子也以其奢华的珠宝系列而闻名。 Chopard的日常珠宝系列仅采用最优质的材料制成，采用厚度为18K的黄金和最高等级的宝石制成。不仅如此，萧邦还非常注重细节和精确度，为其已经很昂贵的产品线增加了更多价值。 9 Mikimoto御木本国家：日本创建日期：1893年创始人：御木本幸吉简介：Mikimoto的创始人Kokichi Mikimoto不仅因其收藏而闻名，而且因为他发明并传播了使用养殖珍珠制作珠宝首饰的事实。 Mikimoto的系列仅选用最好的珍珠，包括南海珍珠，粉红海螺珍珠，大溪地珍珠，白珍珠和其他稀有标本。最重要的是，Mikimoto的珠宝系列仅使用18k金和铂金作为金属部件和顶级钻石。只有最好的丝线用于有珍珠串的首饰。 8 Bvlgari宝格丽国家：意大利创建日期：1884年创始人：索帝里欧·宝格丽简介：宝格丽毫无疑问是一个着名的奢侈品牌，从时装到手表再到珠宝。而对于后者而言，这个以罗马为基础的品牌将优雅和奢侈品完美结合，并且不失其对传统的偏好。即使在今天，Bvlagri的系列仍然标榜着该房子的标志性特征，包括用于中心件的大型宝石，大胆的形状以及凸圆形宝石的使用（这一传统可追溯到1960年代的意大利魅力）。除了最好的宝石外，宝格丽仅使用18K黄金作为其收藏品。 7 伯爵伯爵国家：瑞士创建日期：1874创始人：乔治．伯爵简介：Piaget是普通人的另一个熟悉的名字，最初是作为汝拉瑞士部分的制表公司开始的。随着业务的增长，该公司很快就进入了珠宝行业，并在其中脱颖而出，为那些能够负担公司要求的价格的人们制作奢侈品。今天，Piaget以旧世界概念和现代设计相结合为荣，现在设计时尚线条和大胆的角度。但其最着名的外观是玫瑰，它已成为伯爵的标志性设计。 6 Graff格拉夫国家：英国创建日期：1960年创始人：劳伦斯·格拉夫简介：格拉夫是顶级品牌，在富人和精英中非常受欢迎。使Graff的系列与众不同的不仅仅是用于制作昂贵单品的宝石和金属的工艺或质量。相反，它是Graff在其珠宝系列中使用的宝石的大小。他们是巨大的，格拉夫的创始人劳伦斯格拉夫喜欢这样。 5 Tiffany＆Co。蒂芙尼国家：美国创建日期：1837年创始人：查理斯·路易斯·蒂芙尼和泰迪·杨简介：甚至大众都知道蒂芙尼在珠宝方面是一个巨大的奢侈名称，主要是因为他们的产品线包括日常穿着的件，无论什么场合。他们广泛的收藏不仅限于女性，蒂芙尼也适合男性和儿童。自1837年开始运营以来，Tiffany的创作产生了经典设计，由专业工匠制作。那些被归类为超豪华的人往往需要数年才能完成。 4 Buccellatibucellati国家：意大利创建日期：1919年创始人：Mario Buccellati简介：Buccellati用最好的意大利金制作优雅的珠宝，彰显罗马的传统。这家总部位于罗马的珠宝公司制作了罗马风格的设计，并将其融入其收藏中。罗马风格的项链和手镯袖口只是他们最畅销的一些。 Buccellati也为能够提供某些设计而感到自豪，这些设计使其珠宝具有非常吸引人的外观，如使用高品质的宝石和钻石刷金属和哑光，以及厚重的结壳。 3 Van Cleef＆Arpels梵克雅宝国家：法国创建日期：1896年创始人：Alfred Van Cleef和Salomon Arpels简介：当Estelle Arpels和Alfred Van Cleef决定将他们的合作作为永久性安排时，Van Cleef＆Arpels成立。虽然它的大部分系列都展现了旧世界物品中的优雅风格，但它还有其他系列产品，散发着自己的风格和阶级。这座房子展示了一个庞大的系列，融合了传统和叙事风格以及技术专长。 2卡地亚卡地亚国家：法国创建日期：1847年创始人：路易-弗朗索瓦·卡地亚简介：列表中的另一个家喻户晓的名字，卡地亚是一个已存在多年的名字。 卡地亚成立于1860年，一直是皇室成员的珠宝商，他们希望拥有个性化的系列。 黑豹是卡地亚最知名的设计，经过不断的修改和重新概念化，以吸引客户不断变化的品味。 卡地亚以其装饰艺术历史而闻名，但也创造了几条线条来庆祝旧世界的优雅。 1 Harry Winston温斯顿国家：美国创建日期：1932创始人：哈里温斯顿简介：一个在珠宝行业引起共鸣的名字，Harry Winston于1932年开始创业，并一直处于领先地位。 Harry Winston的系列仅使用最好的宝石和最好的金属，仅由珠宝工艺大师设计。 Harry Winston家居的产品不仅优雅而奢华，而且耐用，并且很容易通过时间的考验。]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>珠宝</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[以太坊（Ethereum）简介]]></title>
    <url>%2F2019%2F04%2F23%2F%E4%BB%A5%E5%A4%AA%E5%9D%8A%EF%BC%88Ethereum%EF%BC%89%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[以太坊是一个开源的有智能合约功能的公共区块链平台。通过其专用加密货币以太币（Ether，又称“以太币”）提供去中心化的虚拟机（称为“以太虚拟机”Ethereum Virtual Machine）来处理点对点合约。 以太坊（Ethereum）简介 概念：是一个开源的有智能合约功能的公共区块链平台。通过其专用加密货币以太币（Ether，又称“以太币”）提供去中心化的虚拟机（称为“以太虚拟机”Ethereum Virtual Machine）来处理点对点合约。 以太坊的概念首次在2013至2014年间由程序员维塔利克·布特林受比特币启发后提出，大意为“下一代加密货币与去中心化应用平台”，在2014年透过ICO众筹得以开始发展。 截至2018年6月，以太币是市值第二高的加密货币，以太坊亦被称为“第二代的区块链平台”，仅次于比特币。 创始人Vitalik Buterin（V神）国籍：俄裔加拿大人出生日期：1994年1月31日事迹：以太坊创始人、以太坊白皮书作者 特点1.智能合约（smart contract）存储在区块链上的程序，由各节点运行，需要运行程序的人支付手续费给节点的矿工或权益人。 2.代币（tokens）智能合约可以创造代币供分布式应用程序使用。分布式应用程序的代币化让用户、投资者以及管理者的利益一致。代币也可以用来进行首次代币发行。 3.叔块（uncle block）将因为速度较慢而未及时被收入母链的较短区块链并入，以提升交易量。使用的是有向无环图的相关技术。 4.权益证明（proof-of-stake）相较于工作量证明更有效率，可节省大量在挖矿时浪费的计算机资源，并避免特殊应用集成电路造成网络中心化。 5.支链（Plasma）用较小的分支区块链运算，只将最后结果写入主链，可提升供单位时间的工作量。 6.状态通道（state channels）原理类似比特币的闪雷网络，可提升交易速度、降低区块链的负担，并提高可扩展性。尚未实现，开发团队包括雷电网络（Raiden Network）和移动性网络（Liquidity Network）。 7.分片（sharding）减少每个节点所需纪录的数据量，并透过平行运算提升效率。 8.分布式应用程序以太坊上的分布式应用程序不会停机，也不能被关掉。 发展历程1.激活：边境以太坊的公共区块链在2015年7月30日引导。最初的以太坊版本称为边境（Frontier，也有“前锋”的意思），用的是[工作量证明]（proof-of-work）的算法，目前转换成[权益证明]（proof-of-stake）。 2.硬分叉自最初版本以来，以太坊网络成功进行了数次硬分叉。第一次分叉调整了未来挖矿的难度，确保未来的用户会有转换至权益证明的动机。当前第五个分叉正在开发中。 3.第二次分叉：家园2016年春季进行了第二次分叉，发布了第一个稳定版本，称作“家园”（Homestead）。 4.第三次分叉：DAO和区块链分叉2016年六月，以太坊上的一个去中心化自治组织被骇，造成市值五千万美元的以太币被移动到只有该黑客可以控制的“分身DAO”。因为程序不允许黑客立即提取这些以太币，以太坊用户有时间讨论如何处理此事，考虑的方案包括取回以太币和关闭DAO，而DAO去中心化的本质也表示没有中央权力可以立即反应，而需要用户的共识。最后在2016年7月20日，以太坊进行硬分叉，作出一个向后不兼容的改变，让所有的以太币（包括被移动的）回归原处，而不接受此改变的区块链则成为古典以太坊。这是第一次有主流区块链为了补偿投资人，而透过分叉来更动交易记录。 在这次分叉之后，造成了在两个区块链之间进行重放攻击的可能，加上其他网络攻击，让以太坊和古典以太坊又各自进行了数次分叉来避免攻击。 5.第四次分叉：减重和防DDoS2016年11月底进行了第四次的分叉。这次分叉为区块链减重（de-bloat），并加入一些避免网络攻击的设计。因为沟通疏失，这次分叉短暂造成以太坊的两个主要客户端程序 Parity 和 Geth 失去共识而产生意外的分叉，但问题在数小时内即被找出并修正。 发展与挑战2018年9月，比特币核心开发者Jeremy Rubin在美国科技媒体TechCrunch上发表文章《ETH的崩溃无法避免》，称就算以太坊网络继续存续，ETH的价值也会必然归零。以太坊创始人Vitalik在回应中承认了问题的存在：“如果以太坊不改变，Jeremy Rubin的言论可能是对的”。此番言论造成ETH的价钱一度下挫。同时，许多以太坊的项目开始转移到EOS﹑波场等的其他公链上，有人担心以太坊将被取代。在ETH的价格影响下，以太坊的全网算力开始收缩，按etherscan.io的算力统计显示，9月到11月以太坊全网算力下跌了20％，从近300TH/s收缩至240TH/s。 2018年12月10日，Vitalik在推特上宣称，未来采用基于[权益证明 (PoS)]的分片技术的区块链“效率将提高数千倍”。 2019年，以太坊项目进行君士坦丁堡硬分叉，这是一个刺激以太坊网络改变其核心共识机制算法的代码，这一段代码引导之后以太坊便会面临所谓的“冰河时代”，在该网络上的创建新区块的难度将会不断提升，最终减慢到完全停止。在该硬分叉升级之后，以太坊区块链的状态将“永久性”的改变。]]></content>
      <categories>
        <category>数字货币</category>
      </categories>
      <tags>
        <tag>以太坊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[人们最有可能帮助陌生人的十大国家]]></title>
    <url>%2F2019%2F04%2F23%2F%E4%BA%BA%E4%BB%AC%E6%9C%80%E6%9C%89%E5%8F%AF%E8%83%BD%E5%B8%AE%E5%8A%A9%E9%99%8C%E7%94%9F%E4%BA%BA%E7%9A%84%E5%8D%81%E5%A4%A7%E5%9B%BD%E5%AE%B6%2F</url>
    <content type="text"><![CDATA[2018年, 人们最有可能帮助陌生人的十大国家: 排名如下： 利比亚: 83% 伊拉克: 81% 科威特: 80% 利比里亚: 80% 塞拉利昂: 80% 巴林: 74% 冈比亚: 74% 沙特阿拉伯: 74% 肯尼亚: 72% 美国: 72% (World Giving Index)]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[2018年全球道路质量排行]]></title>
    <url>%2F2019%2F01%2F10%2F%E9%81%93%E8%B7%AF%E8%B4%A8%E9%87%8F%E6%8E%92%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[Quality of roads, 2018. (of 140 countries) index as below:1.🇸🇬Singapore 新加坡2.🇨🇭Switzerland 瑞士3.🇳🇱Netherlands 荷兰 6.🇯🇵Japan 日本7.🇫🇷France 法国9.🇦🇪UAE 阿拉伯联合酋长国11.🇺🇸USA 美国13.🇪🇸Spain 西班牙19.🇩🇪Germany 德国25.🇨🇦Canada 加拿大26.🇬🇧UK 英国33.🇹🇷Turkey 土耳其42.🇨🇳China 中国51.🇮🇳India 印度69.🇵🇰PAK 巴基斯坦104.🇷🇺Russia 俄国110.🇲🇳Mongolia 蒙古112.🇧🇷Brazil 巴西132.🇳🇬Nigeria 尼日利亚]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>道路质量</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全球数字货币市值排名第三瑞波币XRP介绍]]></title>
    <url>%2F2019%2F01%2F06%2F%E7%91%9E%E6%B3%A2%E5%B8%81%EF%BC%88XRP%EF%BC%89%2F</url>
    <content type="text"><![CDATA[下面介绍瑞波币（XRP）的信息，希望对大家数字货币及投资有帮助。 概述： 旨在消除比特币对集中交换的依赖，比比特币使用更少的电力，并且比比特币更快地执行交易； Ripple加密货币协议于2012年推出，其主要目标是确保“任何规模的安全，即时和几乎免费的全球资金运营，无需任何退款”。该协议支持使用法定货币，加密货币，货物或任何其他单位（如旅客奖励里程或移动会议纪要）付款。 Ripple数字货币系统确认交易不是采矿，而是网络参与者的共识。 这种方法消除了对比特币中使用的集中交换的依赖。 Ripple也比比特币使用更少的电力，而交易执行得更快。 创始人： Ripple coin于2004年由加拿大温哥华市的网络开发人员Ryan Fugger首次实施跨境支付； 2005年，Fugger开始将Ripplepay建成金融服务，通过全球网络为在线社区成员提供安全支付选项； 在此协议的基础上，2011年5月出现了一种新的数字货币系统，其中发布了自己的加密货币XRP； 发行量：1000亿枚 发行时间：2011年 用途： 在Ripple中，用户通过使用以任意现实世界资产（美元，黄金，飞行里程等）计价的加密签名交易在他们之间进行支付。 为此，Ripple保留了一个分类账，用于记录彼此信任的用户之间的债务。 通过这种方式，所有资产都表示为债务。 当在彼此信任的两个用户之间进行支付时，根据每个用户设置的限制调整相互信用额度的余额。 为了在没有直接建立信任关系的用户之间发送资产，系统尝试在两个用户之间找到路径，使得路径的每个链接在具有信任关系的两个用户之间。 然后沿路径平衡所有，同时原子性调整。 客户：欧洲进出口银行、SendFriend、JNFX、FTCS、科威特Ahli银行、Transpaygo、BFC Bahrain、ConnectPay、GMT、WorldCom Finance、Olympia Trust company、Pontual/USEND和Rendimento等200家商业银行和金融机构。 事件： 1.2011-04-18，瑞波币是Ripple网络的基础货币，它可以在整个ripple网络中流通，总数量为1000亿 2.2015-01-20，Ripple Labs任命前白宫顾问Gene Sperling为董事 Sperling表示：“我很高兴加入Ripple Labs，他们的使命是通过一个通用的互联网协议大幅提高跨境支付的速度和效率。“与货币无关的Ripple协议是一项独特的技术，可以从根本上改变通信银行业务，并导致实时支付系统。 3.2016-10-20，Ripple和R3在跨境银行支付方面取得突破 该试验发生在旧金山的Ripple和由数十家银行支持的金融创新联盟R3之间。周四发布的公告涉及到12家银行，其中包括巴克莱和BMO,这些银行使用Ripple的货币XRP来为跨境结算提供流动性 4.2017-10-11：瑞波全球支付网络产品签署九个新用户 计划进行跨境资金转移 新成员包括国际支付处理服务商Bexs Banco de Cambio、为优步和GoDaddy提供支付服务的dLocal。目前该网络成员超过100，包括Credit Agricole、Currencies Direct、IFX、TransferGo、Cuallix, Krungsri和Rakbank。 5.2018年2月6日，交易平台BitMEX对外公布一份Ripple调查报告，其中阐述瑞波币早期的分类账本中已遗失32570个区块，无法修复并获得其中的数据，而无法完整审核整个瑞波币区块链和1000亿XRP币的完整路径； 6.2018年2月，西联汇款宣布与Ripple公司合作，测试通过Ripple进行资金交易并实现资本最优化。 7.2018年某段时期一度超越以太坊成为第二大加密货币，目前第三位。]]></content>
      <categories>
        <category>数字货币</category>
      </categories>
      <tags>
        <tag>XRP</tag>
        <tag>瑞波币</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全球游戏公司游戏营收排行]]></title>
    <url>%2F2019%2F01%2F05%2F%E6%B8%B8%E6%88%8F%E5%B8%82%E5%9C%BA%E8%90%A5%E6%94%B6%E6%8E%92%E5%90%8D%2F</url>
    <content type="text"><![CDATA[游戏市场市场研究机构Newzoo发布2018年全球游戏市场报告，报告中显示，腾讯游戏相关营收增长9%，达到197亿美元，占据全球游戏市场近15%的份额。索尼以142亿美元营收排名第二，微软营收98亿美元排名第三。 游戏营收排名：1.腾讯2.索尼3.微软4.苹果5.动视暴雪6.谷歌7.网易8.EA9.任天堂10.万代南梦宫]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>游戏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[恒星币（XLM）]]></title>
    <url>%2F2019%2F01%2F04%2F%E6%81%92%E6%98%9F%E5%B8%81%EF%BC%88XLM%EF%BC%89%2F</url>
    <content type="text"><![CDATA[下面介绍全球数字货币市值排名第九的恒星币（XLM） 概述：代码是基于瑞波币的基础上修改的。用于搭建一个数字货币与法定货币之间传输的去中心化网关，是一个用于价值交换的开源协议； 该协议由非营利性、非股票型组织因此，基金的创始人无法从其经营或出售其股份中获益； Stellar Development Foundation基金会提供支持； 平台完全对外开源； 该平台承诺发布涵盖其活动的各种报告：关于雇员工资的报告;关于流氓补助金工作人员的报告;预算;分布流明数;流明的分布机制等； 在平台上可以看到发行量，每周产生的流量（每年产生1%的认为通胀），基金的发展将要花多少钱（总数的5%）； 大多数免费发放，5%作为运营使用，25%流向非营利组织； 拥有大量恒星币的组织或个人必须拥有5年以上才能出售其资产； Stellar平台的组织者已经尽一切可能从这个项目中排除任何赌博组件； 2019年3月，IBM发布公告称，包括Banco Bradesco，Bank Rusan和Rizal Commercial Banking Corporation在内的六家国际银行签署了在World Wire上发行自己的稳定币的意向书，这是IBM利用Stellar公共区块链的支付网络。 创始人：瑞波币的前创始人Jed McCaleb，电驴（BT下载软件）的创始人 发行量：1000亿枚，95%用于免费发放。目前流通量约为191亿枚： 50%通过直接分发计划分配给全世界； 25%通过增加覆盖计划分配给非营利组织以给予金融服务匮乏的人群； 20%通过比特币计划分配； 5%留作运营费用恒星币运营。 发行时间：2014年 用途：去中心化网关，通过转换全球各国之间的稳定加密货币的方式，进行跨境支付 客户：IBM、菲律宾的RCBC、巴西的Banco Bradesco、韩国的Bank Busan 2017年10月Stellar宣布与IBM合作，成为IBM Blockchain平台战略的一部分，为跨国界提供更便宜，更快速的支付]]></content>
      <categories>
        <category>数字货币</category>
      </categories>
      <tags>
        <tag>XLM</tag>
        <tag>恒星币</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[德国的世界品牌]]></title>
    <url>%2F2019%2F01%2F04%2F%E5%BE%B7%E5%9B%BD%E7%9A%84%E4%B8%96%E7%95%8C%E5%93%81%E7%89%8C%2F</url>
    <content type="text"><![CDATA[Companies based in Germany:德国的世界品牌： 品牌如下： 1234567891011121314151617181920- Volkswagen 大众 汽车- Allianz 安联 保险- Mercedes Benz 奔驰 汽车- Audi 奥迪 汽车- BMW 宝马 汽车- Porsche 保时捷 汽车- Lufthansa 汉莎 航空- Siemens 西门子 电子电器工程- BASF 巴斯夫 化工- Bayer 拜耳 医疗保健、化工及农业- Fresenius 费森尤斯 医药- Merck 默克 生物科技- Linde 林德 工业机械- ThyssenKrupp Group蒂森克虏伯 工业工程、钢铁- SAP 思爱普 企业管理、咨询- Deutsche Telekom 德国电信 电信- Aldi 阿尔迪 食品连锁超市- Bosch 博世 工业、交通- Lidl 历德 零售（欧洲的沃尔玛）- Adidas 阿迪达斯 服装 你用到了哪些呢？]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>德国</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[尼古拉·特斯拉]]></title>
    <url>%2F2019%2F01%2F03%2F%E5%B0%BC%E5%8F%A4%E6%8B%89%C2%B7%E7%89%B9%E6%96%AF%E6%8B%89%2F</url>
    <content type="text"><![CDATA[下面介绍 尼古拉·特斯拉 这个交流电之父。 24岁的特斯拉全无天才的气质，甚至可以说，是一个失败者。1882年，成为一家电话公司的工程师。特斯拉开始展现才华，设计出第一台感应电机模型。1884年，带着前雇主的推荐信，特斯拉第一次来到美国，见到了传说中的爱迪生，成为他的助手。后来辞职后创业。爱迪生是直流电的死忠，特斯拉主推交流电。可以说，直流电与交流电之争决定两家公司的生死。再后来，交流电取代直流电，成为主流，奠定了现代电力的基础。因此，特斯拉，而非爱迪生才是真正的“电气时代之父”。1897年就获得了无线电技术的专利。1898年，特斯拉制造了能产生人工地震的振荡器，在输入频率时，差点将纽约市夷为平地。1899年，特斯拉造出一大堆球状闪电，这是迄今为止，世界上唯一一次在实验室制造出球状闪电。1901年，特斯拉建造了沃登克里弗塔，用于横跨大西洋的无线电能传输实验。1917年，特斯拉就向美国海军提出雷达的概念。特斯拉先于伦琴发现X射线。还发明了遥控器、发动机火花塞、霓虹灯、现代电动机。建立了第一次成功记录接收了来自外太空无线电电波，他在一百多年前就持有晶体管的专利世界上第一个水利发电站——尼亚加拉水电站。现在手机吹嘘的“无线充电技术”，其实是特斯拉100年前玩剩下的。特斯拉的无线照明特斯拉还设计过一种”没有机翼，没有副翼，没有螺旋桨，没有其他外部装置的飞机“。飞行速度极高，完全通过反作用实现续航和驱动。 他每天只睡2个小时，独自取得700多项发明专利，合作开发1000种以上。他被诺贝尔物理学奖提名11次，全部让贤。作为交流电的发明人，一年之内，就可以靠专利费，成为世界首富。他却毅然将“交流电专利”撕毁，免费向社会开放。最终，一生贫困潦倒。1943年，尼古拉·特斯拉在贫穷、孤独中去世。今天，提起特斯拉，大部分人想到的只是一辆电动车，而非一位科学家。]]></content>
      <categories>
        <category>人物</category>
      </categories>
      <tags>
        <tag>特斯拉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[印度处于领先地位的产品]]></title>
    <url>%2F2019%2F01%2F02%2F%E5%8D%B0%E5%BA%A6%E5%A4%84%E4%BA%8E%E9%A2%86%E5%85%88%E5%9C%B0%E4%BD%8D%E7%9A%84%E4%BA%A7%E5%93%81%2F</url>
    <content type="text"><![CDATA[印度处于领先地位的产品： 香蕉 芒果 番木瓜 柠檬 水牛奶 山羊奶 辣椒 生姜 鹰嘴豆 小米 黄麻 木材燃料 你用过或者吃过吗？]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>印度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各国诺贝尔奖数]]></title>
    <url>%2F2019%2F01%2F02%2F%E5%90%84%E5%9B%BD%E5%BE%97%E8%AF%BA%E5%A5%96%E6%95%B0%2F</url>
    <content type="text"><![CDATA[Nobel prizes.诺贝尔奖数： 排名如下：US: 377 美国UK: 130 英国Germany: 108 德国France: 70 法国Sweden: 32 瑞典Japan: 27 日本Canada: 26 加拿大Switzerland: 26 瑞士Russia 25 俄国Austria: 21 奥地利Netherlands: 21 荷兰Italy: 20 意大利Poland: 14 波兰Denmark: 13 丹麦Norway: 13 挪威Hungary: 13 匈牙利Australia: 12 澳大利亚Israel: 12 以色列Belgium: 11 比利时India: 10 印度South Africa: 10 南非China: 8 中国Spain: 8 西班牙 中国： 大陆：第十四世达赖喇嘛 刘晓波 莫言 屠呦呦 台湾：丁肇中 李遠哲 李政道 杨振宁]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>诺贝尔奖</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019年最健康的国家指数]]></title>
    <url>%2F2019%2F01%2F01%2F%E6%9C%80%E5%81%A5%E5%BA%B7%E7%9A%84%E5%9B%BD%E5%AE%B6%E6%8C%87%E6%95%B0%EF%BC%8C2019%E5%B9%B4%2F</url>
    <content type="text"><![CDATA[最健康的国家指数，2019年 排名如下：1.西班牙2.意大利3.冰岛4.日本6.瑞典7.澳大利亚8.新加坡9.挪威10.以色列12.法国16.加拿大17.韩国19.英国23.德国26.希腊35.美国40.波兰48.匈牙利51.土耳其52.中国53.墨西哥54.阿根廷（彭博社） 希望你所在的国家，没有食品安全问题。]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>健康</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中本聪与比特币]]></title>
    <url>%2F2018%2F12%2F31%2F%E4%B8%AD%E6%9C%AC%E8%81%AA(Satoshi%20Nakamoto)%26%E6%AF%94%E7%89%B9%E5%B8%81%2F</url>
    <content type="text"><![CDATA[介绍下比特币与中本聪的故事，点击更多 中本聪(Satoshi Nakamoto) 【BTC设计初衷】并不希望数字加密货币被某国政府或中央银行控制，而是希望其成为全球自由流动、不受政府监管和控制的货币。 【BTC发展概述】比特币协议及其相关软件Bitcoin-Qt的创造者，但真实身份未知。于2008年发表了一篇名为《比特币：一种点对点式的电子现金系统》（Bitcoin: A Peer-to-Peer Electronic Cash System）的论文，描述了一种被他称为“比特币”的电子货币及其算法。2009年，他发布了首个比特币软件，并正式启动了比特币金融系统。2010年，他逐渐淡出并将项目移交给比特币社区的其他成员。2015年，加州大学洛杉矶分校金融学教授Bhagwan Chowdhry曾提名中本聪为2016年诺贝尔奖经济学奖的候选人。Bhagwan Chowdhry说：“比特币的发明简直可以说是革命性的。中本聪的贡献不仅将会彻底改变我们对金钱的思考方式，很可能会颠覆央行在货币政策方面所扮演的角色，并且将会破坏如西联这样高成本汇款的服务，彻底消除如Visa，MasterCard、PayPal他们收取2-4%的中间人交易税，消除费事且昂贵的公证和中介服务，事实上它将彻底改变法律合约的方式。” 【中本聪身份猜测】1.中情局特勤小组有阴谋论者认为比特币其实是由美国金融机构与政府联手打造的一款骗局工具，目的是地巨大利差引诱投资者巨额投入，再以利差吸取这些投资以平衡美国政府财政。因此中本聪并不是一个人，而是一个小组的代号。这种说法并未得到任何机构或个人的认可，但在反比特币者当中认同度很高。随着近期比特币等加密货币价格的暴跌，这种说法开始在一些比特币持有者当中流传。 2.望月新一2012年5月，计算机科学家泰德·尼尔森认为中本聪就是日本数学家望月新一，认为其足够聪明，研究领域包含比特币所使用的数学算法。更重要的是，望月不使用常规的学术发表机制，而是习惯是独自工作，发表论文后让其他人自己理解。然而也有人提出质疑，认为设计比特币所需的密码学并非望月的研究兴趣。望月本人亦予以否认。 3.尼克·萨博2013年12月，博客作家Skye Grey通过对中本论文的计量文体学分析得出结论，认为其真实身份是前乔治华盛顿大学教授尼克·萨博。萨博热衷于去中心化货币，还发表过一篇关于“比特黄金”（bit gold）的论文，被认为是比特币的先驱。他也是一个著名的从90年代起就喜欢使用化名的人。在2011年5月的一篇文章中，萨博谈起比特币创造者时表示：“在我认识的人里面，对这个想法足够感兴趣，并且能付诸实施的，本来只有我自己、戴维（Wei Dai）、哈尔·芬尼三个人，后来中本出现了（假定中本不是芬尼也不是戴维）。” 4.多利安·中本最为公众所熟知的猜测发生在2014年3月6日。新闻周刊记者Leah McGrath Goodman发表文章称自己已经找到真正的中本，是一个居住在加利福尼亚州的日裔美国人，名叫多利安·中本，而“哲史”是他出生时的名字。除了名字相同以外，Goodman还找到了一些佐证，其中最有力的一条是，当Goodman在当面采访并提出比特币的问题时，多利安的回答看起来确认了其比特币之父的身份：“我已经不再参与它了，不能讨论它。它已经被转交给其他人。他们现在在负责。我已经没有任何联系。”这段话的真实性亦得到了当时在场的洛杉矶郡警察的确认。报道被公开后受到了包括比特币社区在内舆论的质疑和批评，但同时也引起了媒体的巨大兴趣。记者们蜂拥而至多利安的住宅外蹲守，甚至追逐他的汽车。然而在后来的正式访谈中，多利安否认了自己与比特币的全部联系，称自己从未听说过，只是误解了Goodman的提问，以为她问的是自己之前从军方承接的保密性工作。当天晚些时候，中本聪本人也站出来否认。他在P2P基金会的账户在尘封五年之后发了第一条消息，称：“我不是多利安·中本。” 5.克雷格·史蒂芬·怀特2015年12月，《连线杂志》报道说澳大利亚学者克雷格·史蒂芬·怀特很有可能是中本聪的本尊。同时也指出，也许只是他精心设计的一个高明的骗局想让我们相信他就是中本聪本人。直到2016年5月2日，澳大利亚企业家克雷格·史蒂芬·怀特公开承认自己就是发明比特币的中本聪，首度有人公开承认。其证据是中本聪的加密签名档，但被质疑该档只要是稍微高端一点的黑客都能在暗网中找到下载，早就在不少计算机高手圈流传，另一证据是早期第1及第9区块比特币地址的私钥，但此私钥如果是早期比特币开发人员或其亲近者都有可能拿到。最关键证明是导入比特币至2009年的比特币第一笔交易地址，该地址被视为是中本聪所有，并要求表演汇回，BBC记者将0.017个比特币导入，但最终没有汇回。BBC刊退出和他的访谈片段，自称他就是比特币发明者。但克雷格声明与证据的真实性受到普遍的质疑，在最后阶段要求演示关键证据时，克雷格拒绝并发布了一篇顾左右而言他的博客文章。 6.Vincent van Volkmer自2018年以来，互联网声称美国艺术家Vincent van Volkmer是中本聪。对此同时也有一系列证据，例如：他谈到他是一名数学家和密码学家的事实，他也与拥有导致阻碍技术相关知识的专家保持着良好的联系。不过，他自己也反驳了他就是中本聪的这种说法。 7.其它猜测还有一些其他个人或团体被认为是中本聪的真身。其中包括：芬兰经济社会学家Dr Vili Lehdonvirta及爱尔兰密码学研究生Michael Clear。两人分别否认。德国及美国研究人员Neal King、Vladimir Oksman和Charles Bry。他们曾共同申请注册一项与比特币相关的专利，而比特币项目官方网站的域名bitcoin.org恰好注册于专利申请提交之后的第三天。三人均否认此猜测。比特币基金会首席科学家Gavin Andresen、比特币交易平台Mt. Gox创始人Jed McCaleb，或某个政府机构。[1]美国企业家及安全研究员Dustin D. Trammell，但他公开否认。也有人认为Satoshi Nakamoto的名字实际上是四家公司名字的组合，包括三星（Samsung）、东芝（Toshiba）、中道（Nakamichi）和摩托罗拉（Motorola），暗示着比特币其实是这四家公司联手开发并以Satoshi Nakamoto，即“中本聪”的化名来发表。]]></content>
      <categories>
        <category>数字货币</category>
      </categories>
      <tags>
        <tag>数字货币</tag>
        <tag>中本聪</tag>
        <tag>比特币</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三星集团]]></title>
    <url>%2F2018%2F12%2F30%2F%E4%B8%89%E6%98%9F%E9%9B%86%E5%9B%A2%2F</url>
    <content type="text"><![CDATA[下面介绍下三星集团的基本信息： 三星集团1.公司名称：三星集团2.成立时间：1938年3.创始人：李秉哲4.现任会长：李健熙5.总部位置：韩国首尔6.公司分类：电子、金融、机械、化学7.全球员工人数：20万8.年营收：2119.41亿美元（2018年），约等于14200亿人民币9.全球500强：第12位10.旗下所有业务：电子： 三星电子：消费型电子（手机、显示器）、内存、闪存等； 三星SDI：太阳能电池、燃料电池、能源储存； 三星SDS：IT相璃基板、等离子过滤器、显像管和玻璃； 三星航空：三星贝尔427，为贝尔、波音等公司的产品提供服务； 三星半导体：主要业务为生产SD卡，世界最大的存储芯片制造商；机械 三星重工：主要业务为造船； 三星工程：主要业务为制造电子零件装备、军用飞机零组件； 三星道逹尔：主要业务为制造塑料、化工产品、石油产品。； 三星石油化学：主要业务为PTA； 三星精密化学：主要业务为制造电子化学材料、精密化学制品； 三星BP化学：主要业务为制造硝酸、H2、VAM；金融保险 三星生命保险：主要业务为人寿保险和金融服务； 三星火灾海上保险：主要业务为人寿保险和金融服务； 三星信用卡 [18] ：主要业务为信用卡业务，贷款，租赁服务； 三星证券：主要业务为资产管理、中介业务； 三星投资信托管理：主要业务为投资信托； 三星风险投资：主要业务为风险投资业务；其他 三星物产：主要业务有贸易部门和建设部门； 三星第一毛织：主要业务为是时装、纺织、化工、电子材料相关； 三星第一广告：主要业务为是广告代理业务； 三星新罗酒店：主要业务为是酒店相关业务； 三星爱宝乐园：位于京畿道龙仁市的游乐园，是韩国第二大游乐园，由庆典世界、加勒比海湾、爱宝乐园赛车场组成； 三星首尔医院：位于韩国首尔的医院，韩国最大、最具影响力的医院，隶属于三星集团； 三星狮：韩国职业棒球捧场数最多的球队；]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>三星</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018世界医药顶尖大学]]></title>
    <url>%2F2018%2F12%2F29%2FTop%20universities%20in%20medicine%2C%202018%2F</url>
    <content type="text"><![CDATA[Top universities in medicine, 2018.2018世界医药顶尖大学： 排名如下： 123456789101. Harvard 哈佛大学 美国2. Oxford 牛津大学 英国 3. Cambridge 剑桥大学 英国4. Stanford 斯坦福大学 美国5. John Hopkins 约翰·霍普金斯大学 美国6. Karolinska Institutet 卡罗林斯卡学院 瑞典7. Uni of California, LA 加州大学洛杉矶分校 美国8. Yale 耶鲁大学 美国9. MIT 麻省理工学院 美国10. University College London 伦敦大学学院 英国]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>医药大学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019世界上城市生活成本排行]]></title>
    <url>%2F2018%2F12%2F29%2FWorld's%20most%20expensive%20cities%2C%202019.%20(cost%20of%20livi%2F</url>
    <content type="text"><![CDATA[World’s most expensive cities, 2019. (cost of living)2019世界上城市生活成本排行： 排名如下： 1234567891011=1.🇸🇬Singapore 新加坡 新加坡=1.🇫🇷Paris 巴黎 法国=1.🇭🇰Hong Kong 香港 中国4.🇨🇭Zurich 苏黎世 瑞士=5.🇨🇭Geneva 日内瓦 瑞士=5.🇯🇵Osaka 大阪 日本=7.🇰🇷Seoul 首尔 韩国=7.🇩🇰Copenhagen 哥本哈根 丹麦=7.🇺🇸New York 纽约 美国=10.🇮🇱Tel Aviv 特拉维夫 以色列=10.🇺🇸Los Angeles 洛杉矶 美国 The Economist Intelligence Unit, 2019]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>城市生活成本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019世界上最著名的运动员]]></title>
    <url>%2F2018%2F12%2F28%2FThe%20world%E2%80%99s%20most%20famous%20athletes%2C%202019%2F</url>
    <content type="text"><![CDATA[The world’s most famous athletes, 2019.2019世界上最著名的运动员： 1234567891011121314151617181920排名 人名 中文名 职业 就职国家 国籍 1 Ronaldo 罗纳尔多 足球 西班牙 葡萄牙2 LeBron 勒布朗·詹姆斯 篮球 🇺🇸美国 美国3 Messi 里奥·梅西 足球 🇦🇷阿根廷 阿根廷4 Neymar 内马尔·达席尔瓦 足球 法国 巴西5 McGregor 康纳·麦格雷戈 格斗 🇮🇪爱尔兰 爱尔兰6 Federer 罗杰·费德勒 网球 🇨🇭瑞士 瑞士7 Kohli 维拉·哥利 板球 🇮🇳印度 印度8 Nadal 拉菲尔·纳达尔 网球 🇪🇸西班牙 西班牙12 Pogba 保罗·博格巴 足球 🇫🇷法国 几内亚14 Mbappe 姆巴佩 足球 🇫🇷法国 法国17 Serena 塞雷娜·威廉姆斯 网球 🇺🇸美国 美国19 Özil 梅苏特·厄齐尔 足球 🇩🇪德国 德国21 󠁧Hamilton 理查德·汉密尔顿 篮球 🇺🇸美国 美国30 Salah 穆罕默德·萨拉赫 足球 🇪🇬埃及 埃及33 Bale 加雷斯·贝尔 足球 威尓士 威尓士38 Ramos 塞尔吉奥·拉莫斯 足球 🇪🇸西班牙 西班牙41 Ninja Ninja 电竞 🇺🇸美国 美国 58 Benzema 卡里姆·本泽马 足球 🇫🇷法国 法国73 Kroos 托尼·克罗斯 足球 🇩🇪德国 德国]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>运动员</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The world's Top 100 Airports for 2018]]></title>
    <url>%2F2018%2F12%2F27%2FThe%20world's%20Top%20100%20Airports%20for%202018%2F</url>
    <content type="text"><![CDATA[The world’s Top 100 Airports for 2018, as voted for by air travellers around the world during the 2017/2018 survey periodPlease note that over 500 airports were covered in the survey but we only feature the top 100 listing here (this listing may not be reproduced without the consent of Skytrax). as blow: 1 Singapore Changi 1 20172 Seoul Incheon 3 20173 Tokyo Haneda 2 20174 Hong Kong 5 20175 Doha Hamad 6 20176 Munich 4 20177 Centrair Nagoya 7 20178 London Heathrow 9 20179 Zurich 8 201710 Frankfurt 10 2017 15 Taiwan Taoyuan 21 2017 18 Shanghai Hongqiao 18 2017 28 London City 36 2017 33 Beijing Capital 25 2017 37 Paris CDG 32 2017 51 San Francisco 39 2017]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>Airports</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全球各国家离婚率排行]]></title>
    <url>%2F2018%2F12%2F26%2FHighest%20Divorce%20Rate%20by%20Country%2F</url>
    <content type="text"><![CDATA[Highest Divorce Rate by Country全球各国家离婚率排行： 1.Luxembourg : 87% 卢森堡2.Spain: 65% 西班牙3.France: 55% 法国4.Russia: 51% 俄国5.United States: 46% 美国6.Germany: 44% 德国7.United Kingdom: 42% 英国8.New Zealand: 42% 新西兰9.Australia: 38% 澳大利亚10.Canada 38% 加拿大. .. India 1% 印度 你们国家的离婚率大概是多少呢？let me know in the comments.]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>离婚率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日本近几年的经济数据]]></title>
    <url>%2F2018%2F12%2F26%2FJapan%20Economy%20Data%2F</url>
    <content type="text"><![CDATA[Japan Economy Data ![日本近几年经济数据](Japan Economy Data/japan_economy_data.jpg) 你看到了什么？]]></content>
      <categories>
        <category>经济</category>
      </categories>
      <tags>
        <tag>日本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019全球国家手机网络连接速度排行]]></title>
    <url>%2F2018%2F11%2F26%2FAverage%20speed%20of%20mobile%20internet%20connections%2C%202019%2F</url>
    <content type="text"><![CDATA[Average speed of mobile internet connections, 2019. (in MBPS)2019全球国家手机网络连接速度排行（MB/s) 1.ISL: 73.93 以色列2.NOR: 70.29 挪威3.CAN: 65.68 加拿大4.AUS: 56.70 澳大利亚5.SIN: 54.96 新加坡6.KOR: 52.53 韩国7.FRA: 43.34 法国8.USA: 33.19 美国9.JPN: 32.08 日本10.HK: 32.00 香港11.GER: 31.46 德国12.KSA: 30.80 沙特阿拉伯13.GBR: 30.12 英国14.CHN: 30.08 中国15.RUS: 19.16 俄国16.IND: 10.13 印度 (Ookla) 你在哪个国家呢？]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>移动通信</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows_C盘垃圾清理]]></title>
    <url>%2F2018%2F11%2F03%2Fwindows-C%E7%9B%98%E5%9E%83%E5%9C%BE%E6%B8%85%E7%90%86%2F</url>
    <content type="text"><![CDATA[windows c盘垃圾清理程序，清理各类软件的缓存文件、日志文件等，长时间未清洗，可以空出10多G的空间出来，具体程序如下，创建一个abc.bat可执行文件（名字随便取），点击运行即可： 12345678910111213141516171819@echo off echo 正在清除系统垃圾文件，请稍等...... del /f /s /q %systemdrive%\*.tmp del /f /s /q %systemdrive%\*._mp del /f /s /q %systemdrive%\*.log del /f /s /q %systemdrive%\*.gid del /f /s /q %systemdrive%\*.chk del /f /s /q %systemdrive%\*.old del /f /s /q %systemdrive%\recycled\*.* del /f /s /q %windir%\*.bak del /f /s /q %windir%\prefetch\*.* rd /s /q %windir%\temp &amp; md %windir%\temp del /f /q %userprofile%\小甜饼s\*.* del /f /q %userprofile%\recent\*.* del /f /s /q &quot;%userprofile%\Local Settings\Temporary Internet Files\*.*&quot; del /f /s /q &quot;%userprofile%\Local Settings\Temp\*.*&quot; del /f /s /q &quot;%userprofile%\recent\*.*&quot; echo 清除系统LJ完成！ echo. &amp; pause 随便放在电脑的一个位置，点击运行即可。]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>垃圾清理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019年全球最具价值的餐饮品牌]]></title>
    <url>%2F2018%2F10%2F26%2F2019%E5%B9%B4%E5%85%A8%E7%90%83%E6%9C%80%E5%85%B7%E4%BB%B7%E5%80%BC%E7%9A%84%E9%A4%90%E9%A5%AE%E5%93%81%E7%89%8C%2F</url>
    <content type="text"><![CDATA[2019年全球最具价值的餐饮品牌，拒绝食品垃圾。 品牌名称 国家 成立日期1.星巴克 美国 19712.麦当劳 美国 19553.赛百味 美国 19654.肯德基 美国 19525.提姆霍顿 加拿大 19646.达美乐披萨 美国 19607.汉堡王 美国 1952 公司能经营六七十年，背后是对品质、服务的追求，难道我们不应该支持吗？让地沟油、毒奶粉死去吧。 海底捞 中国 1994真功夫 中国 1990永和大王 中国 1995德克士 中国 1994喜家德 中国 2002味多美 中国 1996嘉和一品 中国 2004渝是乎 中国 2015呷哺呷哺 台湾 1998 半个世纪后见。]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>餐饮</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里巴巴mysql数据库binlog的增量订阅与消费组件canal]]></title>
    <url>%2F2018%2F09%2F05%2F%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4mysql%E6%95%B0%E6%8D%AE%E5%BA%93binlog%E7%9A%84%E5%A2%9E%E9%87%8F%E8%AE%A2%E9%98%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E7%BB%84%E4%BB%B6canal%2F</url>
    <content type="text"><![CDATA[首先介绍下canal他可以做什么，基于日志增量订阅&amp;消费支持的业务, 监控mysql数据，将mysql增量数据从binlog中获取过来实现数据库的镜像、数据库实时备份、多级索引、业务cache刷新等，具体参考阿里开源项目代码：canal github canaldbkafka简介canaldbkafka是连接canal和kafka的一个中间件。目的是实现数据库某个表格数据变更转变成消息流的形式，以便后续业务消费kafka的消息流。 canal wiki:https://github.com/alibaba/canal/wiki 消息的类型canal的binlog 会被解析成以下3中类型的消息。其他的类型被过滤掉了。 insert12345678910111213141516171819202122232425&#123; &quot;data&quot;: &#123; &quot;need_sub&quot;: &#123; &quot;type&quot;: &quot;int(11)&quot;, &quot;updated&quot;: true, &quot;value&quot;: &quot;0&quot; &#125;, &quot;order_description&quot;: &#123; &quot;type&quot;: &quot;varchar(1024)&quot;, &quot;updated&quot;: true, &quot;value&quot;: &quot;&quot; &#125;, &quot;pay_amount&quot;: &#123; &quot;type&quot;: &quot;int(11)&quot;, &quot;updated&quot;: true, &quot;value&quot;: &quot;0&quot; &#125;, &quot;pay_order&quot;: &#123; &quot;type&quot;: &quot;varchar(30)&quot;, &quot;updated&quot;: true, &quot;value&quot;: &quot;&quot; &#125; &#125;, &quot;type&quot;: &quot;insert&quot;&#125; delete12345678910111213141516171819202122232425&#123; &quot;data&quot;: &#123; &quot;need_sub&quot;: &#123; &quot;type&quot;: &quot;int(11)&quot;, &quot;updated&quot;: true, &quot;value&quot;: &quot;0&quot; &#125;, &quot;order_description&quot;: &#123; &quot;type&quot;: &quot;varchar(1024)&quot;, &quot;updated&quot;: true, &quot;value&quot;: &quot;&quot; &#125;, &quot;pay_amount&quot;: &#123; &quot;type&quot;: &quot;int(11)&quot;, &quot;updated&quot;: true, &quot;value&quot;: &quot;0&quot; &#125;, &quot;pay_order&quot;: &#123; &quot;type&quot;: &quot;varchar(30)&quot;, &quot;updated&quot;: true, &quot;value&quot;: &quot;&quot; &#125; &#125;, &quot;type&quot;: &quot;delete&quot;&#125; updatedata对象是各字段类型、是否被更新、值。olddata对象是之前的状态。 123456789101112131415161718192021222324252627&#123; &quot;data&quot;: &#123; &quot;Quota&quot;: &#123; &quot;type&quot;: &quot;tinyint(4)&quot;, &quot;updated&quot;: false, &quot;value&quot;: &quot;0&quot; &#125;, &quot;ReqAmount&quot;: &#123; &quot;type&quot;: &quot;int(11)&quot;, &quot;updated&quot;: true, &quot;value&quot;: &quot;100&quot; &#125; &#125;, &quot;olddata&quot;: &#123; &quot;Quota&quot;: &#123; &quot;type&quot;: &quot;tinyint(4)&quot;, &quot;updated&quot;: false, &quot;value&quot;: &quot;0&quot; &#125;, &quot;ReqAmount&quot;: &#123; &quot;type&quot;: &quot;int(11)&quot;, &quot;updated&quot;: false, &quot;value&quot;: &quot;0&quot; &#125; &#125;, &quot;type&quot;: &quot;update&quot;&#125; 使用说明编译安装123456789101112131415mvn compilemvn packagell target/canal-dbkafka #可部署total 0drwxr-xr-x 5 xxx staff 170B 12 21 21:26 bindrwxr-xr-x 3 xxx staff 102B 12 21 21:26 confdrwxr-xr-x 24 xxx staff 816B 12 21 21:26 libdrwxr-xr-x 2 xxx staff 68B 12 21 21:26 logsll target/canal-dbkafka/bin #startmy.sh为启动示例-rwxr-xr-x 1 xxx staff 271B 12 21 21:26 startmy.sh-rwxr-xr-x 1 xxx staff 2.5K 12 21 21:26 startup.sh-rwxr-xr-x 1 xxx staff 1.0K 12 21 21:26 stop.sh 启动说明已startmy.sh为例 123456789101112#!/bin/bashcurrent_path=`pwd`case &quot;`uname`&quot; in Linux) bin_abs_path=$(readlink -f $(dirname $0)) ;; *) bin_abs_path=`cd $(dirname $0); pwd` ;;esaccd $&#123;bin_abs_path&#125; &amp;&amp; ./startup.sh testdb thetable 127.0.0.1:2181 127.0.0.1:9092 testdb 是canal配置的destination thetable kafka的具体topic 127.0.0.1:2181 是canal配置HA 对应的zookeeper的地址 127.0.0.1:9092 是kafka的地址 使用注意事项 mysql binlog模式设置为row模式 为了保证数据库消息的顺序性，将消息存储kafka的时候组件采用了同步的方式 canal 必须配置zookeeper ha的模式 https://github.com/alibaba/canal/wiki/AdminGuide#ha%E6%A8%A1%E5%BC%8F%E9%85%8D%E7%BD%AE 之前使用针对的是数据库中的一个表在canal配置中已经过滤所以消息中没有表名 可以说是个设计的缺陷。 高可用及分布式监控多个mysqlcanal分服务端和客户端，我们需要监控多个mysql时，可以配置多个instance，具体编辑服务端配置文件canal.properties： 123456789############################################################# destinations ##############################################################canal.destinations=dest21,dest14# conf root dircanal.conf.dir = ../conf# auto scan instance dir add/remove and start/stop instancecanal.auto.scan = truecanal.auto.scan.interval = 5 其中dest21和dest14为不同的instance，目录结构如下： 12345-rwxr-xr-x 1 root root 2882 Aug 27 18:44 canal.propertiesdrwxr-xr-x 2 root root 4096 Sep 5 19:08 dest14drwxr-xr-x 2 root root 4096 Sep 5 19:09 dest21-rwxr-xr-x 1 root root 3038 Jun 19 17:18 logback.xmldrwxr-xr-x 3 root root 4096 Jun 19 17:18 spring dest14和dest21目录分别为监控不同mysql的配置文件放置位置，具体如下： 12345678910111213141516171819202122232425262728293031323334353637################################################### mysql serverIdcanal.instance.mysql.slaveId=14# position infocanal.instance.master.address=1.1.1.1:3306canal.instance.master.journal.name=canal.instance.master.position=canal.instance.master.timestamp=# table meta tsdb infocanal.instance.tsdb.enable=truecanal.instance.tsdb.dir=$&#123;canal.file.data.dir:../conf&#125;/$&#123;canal.instance.destination:&#125;canal.instance.tsdb.url=jdbc:h2:$&#123;canal.instance.tsdb.dir&#125;/h2;CACHE_SIZE=1000;MODE=MYSQL;#canal.instance.tsdb.url=jdbc:mysql://127.0.0.1:3306/canal_tsdbcanal.instance.tsdb.dbUsername=canalcanal.instance.tsdb.dbPassword=canal#canal.instance.standby.address =#canal.instance.standby.journal.name =#canal.instance.standby.position =#canal.instance.standby.timestamp =# username/passwordcanal.instance.dbUsername=canalcanal.instance.dbPassword=*****canal.instance.defaultDatabaseName=canal.instance.connectionCharset=UTF-8# table regex#canal.instance.filter.regex=.*\\..*canal.instance.filter.regex=event_collection\.user_location_lng_lat# table black regexcanal.instance.filter.black.regex=################################################# 你需要修改的地方： 12345canal.instance.mysql.slaveId -- 不同的instance分配不同的slaveId，因为canal监控mysql的原理就是伪装成mysql的slave来获取binlog日志的canal.instance.master.address -- 配置监控的mysql ip地址canal.instance.dbUsername -- 连接mysql的用户名canal.instance.dbPassword -- 连接mysql的密码canal.instance.filter.regex -- 监控mysql中的哪个库，哪个表 其中监控mysql的哪个库哪个表编写格式如下： 123.*\\..* --表示监控mysql所有库所有表test\..* --表示监控mysql test库下的所有表test\.test --表示监控mysql test库下的test表 阿里巴巴，我们程序员的梦想，开源的canal还是不错的，希望大家借助这篇文章能够熟练掌握canal的简单使用，如果遇到什么问题，欢迎一起讨论，在下方留言或者mail我：chenzuoli@gmail.com]]></content>
      <categories>
        <category>监控组件</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>canal</tag>
        <tag>监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[北京租房小中介骗局]]></title>
    <url>%2F2018%2F07%2F29%2F%E5%8C%97%E4%BA%AC%E7%A7%9F%E6%88%BF%E5%B0%8F%E4%B8%AD%E4%BB%8B%E9%AA%97%E5%B1%80%2F</url>
    <content type="text"><![CDATA[给大家说说我亲身经历的租房骗局，小中介如何骗你的钱。我会不定期在网站发布个人生活中遇到的各种骗局，发布到【个人黑名单】分类中，请大家持续关注，避免遇到同样的坑，打击坑蒙拐骗，让那些只顾赚钱，不顾服务的商家，淘汰掉。 中介公司美丽家园房地产有限公司、昊园恒业房地产有限公司 产品大熊公寓 总部地址北京市朝阳区财满街8号楼2单元703室 个人情况首先说说我的情况，码农一枚跟朋友一起租房，3个人，租2间房，一间2人，一间1人，无奈北京房租太贵，链家、我爱我家中介费太高，只好找小中介，不受中介费。 租房第一个坑：预付款时，一定看好是“订金”还是“定金”找到一个小中介公司，在一个小区里面租下15平米左右的主卧2000元，收了一个月押金。当时保证押金可以退回，家具家电均可以上门维修。于是就签合同，另一个朋友，在签合同的时候，了解到，如果中途退租的话，需要找到接盘侠，才能退租，把押金退给你，他不干，于是签了一半的合同终止了，但是中介不干啊，他说合同是要收钱的，200块，你说气不气人，还有，跟他们争论的时候，还问他们索要订金200块，但是那个条子上写的是“定金”，意思就是你已经预付款一些金钱把这个房子定下来了，于是发现情况不对，就对他们客气地说话，说我们之前没弄清楚情况，麻烦谅解一下，最后扣了100块，定金退了。所以大家以后预付款的时候，一定看好是“订金”还是“定金”。 第二个坑：房租付款方式，自付最好，不要和第三方借贷平台签约租金结算方式为58月付，58月付是一个借贷平台，通过借贷的方式，一次性借贷1年的房租也就是20000元，58月付一下子就把钱打给了中介公司，然后58每个月从你的银行卡中扣除2000元，这样中介公司实际就获得了20000元的借款，可以拿去投资或者业务扩张了，而实际是你借的钱。这种借贷是上了征信的，如果你有违约，征信就会出现问题，所以我没一次敢怠慢。 第三个坑：房屋中的家电不能用租下房子之前看过了房子，家电、桌椅、床等设施都齐全，灯、空调、冰箱都使用过了，确实是好的，于是签了合同，住进来才发现洗衣机没法用，缺少一根水管，于是联系他们，配一根洗衣机水管，于是他就叫我们自己弄，公司没有这项规定，也没有相应的业务人员做这个事情，于是只能自己网上买水管了啊，合同都签了。还有一次，灯不亮了，也叫他们过来维修，同样的理由，叫我们自己网上买个灯管，我们真是服了，对于服务这么差的中介，绝对不会合作第二次。 第三个坑：重新签合同，导致交租金提前美丽家园被收购，母公司重新过来签合同，之前是每月16日交租，现在12日交租，房租提前4天交，他们的业务员说会把这4天的钱退给我们，但是一直没退。 第四个坑：退租，乱扣租金退租的时候，房管一副高高在上的样子，好像谁欠他钱似的，查看了房间，检查了家电，押金中扣了我们300元，我去你大爷，住了10个月，给你换了灯管、镇流器、洗衣机水管，还给我们说损坏费用。这300块，100块写在单子上付给公司，另外200块说私下给他转过去，这是拿回扣啊，好好好给你这个死胖子。好了，这押金搞定了，还有房租的事情，因为每次交房租都是交的下个月的，于是我们最后一个月交的是下个月的，应该退我们1个月的房租，但是~一脸横肉的房管，硬生生给我们算成了26天，我跟他算数，他不跟我算数，一直按照他的那套算法来，他妹的，你们还差我4天前没退呢，最后也懒得跟这种人打交道了，就26天了，拿了单子走人了。最后说是押金和租金会在1-2个月内退回，你妹的，你们工作效率这么低吗，要这么长时间。我拿了押金条，快速离开了这个人。这里附上退租押金条： 第五个坑：不退押金，原因是财务正在处理一个月到了确实退了我们租金，但是押金没有退给我们，于是找他们要，第一次，他说提交给财务，第二次去催催财务，第三次去催催财务，这几次，态度极其恶劣，如果不是钱在他手里，我就骂死他，于是又忍气吞声1个月半月过去了，承诺给我们的1-2个月已经超过了半个月，继续联系，我们同一个套间里面的其他朋友也都在催，于是叫我们联系客服，客服电话一直打不通，一次没打通过，于是跟他理论，自己去总部要钱，他说不知道总部位置，我晕死，你一个业务人员不知道总部的位置，还干啥啊，回家种田吧，又联系一次，说是找找总部位置，给我发了一个地址：朝阳区牌坊街8号楼2单元703，好了，我带着沉重的心情去总部要钱，没把握要到钱啊，位置离我2个小时车程。到了，没有公司牌子，很像一个租户的屋，于是敲门，问问，果然是的。于是恼火了，我2个小时到这里，你给我一个错误的地址？打电话过去骂他，我们互相对骂，这几年没骂人了，骂的痛快，你不让我好过，我也不让你好过。无奈啊，找物业问了，也是说没有这个房地产公司。于是找当初带我们看房子的业务员，问他总部位置，说是：朝阳区财满街8号楼2单元703，于是有话2小时去这个地方，这个地方是对的，找到他们领导，说明了情况，登记了紧急退租表，给我们说是8月10号退租。其实这时候心还是有点怀疑他们说的话，但是不信也没什么办法啊，于是回家了，今天一天都在处理这个事情了，上午9点出发，下午4点才到家，等吧。这里附上总部图片：还有房管的电话：15510302000，欢迎去骚扰他，骂他更好。 好了，希望大家记住这几点，并告诉身边的朋友们，多谢了。]]></content>
      <categories>
        <category>个人黑名单</category>
      </categories>
      <tags>
        <tag>租房</tag>
        <tag>骗局</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链应用]]></title>
    <url>%2F2018%2F07%2F25%2F%E5%8C%BA%E5%9D%97%E9%93%BE%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[区块链技术，会颠覆传统互联网信息技术行业，成为下一个风口，你要把握住吗？下面来聊聊区块链在目前各大行业中的一些应用，和目前开发区块链应用用到了平台和技术。 一、分类1.公有链任何人均可参加和退出 联盟链加入和退出需要经过联盟授权 3.私有链权利完全控制在一个组织中 二、开发平台1.以太坊2.Hyperledger：IBM开源3.商用区块链组件：共识层（可插拔） 智能合约层 通讯层 数据抽象层 加密抽象层 身份服务 策略服务 API 互操作、模块化三、Hyperledger应用1.金融服务提升透明度，减少交易时间、降低风险数字贸易链：银行间交易跨境支付：swift组织绿色资产管理平台：IBM与中国合作数字身份：菲律宾银行账户的问题房地产交易：房产属主，解决房产产权鉴定的问题 2.供应链环节真实性，透明度更高，效率更高海鲜供应链追踪：偷猎，食品供应链钻石供应链：防止钻石引起的武装冲突食品安全：每个环节的食品安全 3.医疗患者不同医疗组织、机构之间的病例共享医疗记录：病例共享州际医疗许可：美国各州之间的医疗共享 四、开发语言以太坊：c++、java、python、go、solidityHyperledger：js]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链技术存在的问题]]></title>
    <url>%2F2018%2F07%2F14%2F%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8A%80%E6%9C%AF%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[区块链技术，可以说是可以颠覆传统行业规则的一个革命性技术，去中性化、不可篡改、可回溯等特点，让全球化加速，让世界变得可以信赖，这不就是我们想要的世界吗，但是目前区块链经过了几年的发展，各种乱象横生，需要我们清晰地认识，别走弯路，下面介绍下区块链技术目前所存在的问题，开发者们或者区块链创业者们需要了解的。 1.标准不统一区块链是什么，目前业界还没有一个统一的清晰明确的概念。没有清晰统一的概念界定，又缺少权威的机构对区块链产品进行评定，这极易造成在涉及区块链的项目谈判、实施过程中出现问题，更谈不上区块链的大规模推广和应用。市场上已有的区块链应用也是“鱼龙混杂”，无法有效评价产品质量。区块链亟需建立一套统一的标准规范来界定其内涵和外延，并说明评判的方法，从而引导市场健康发展。然而区块链技术仍在不断创新变化，应用场景也在不断地探索中，过早的标准化会限制区块链技术的创新和行业的发展。因此，为适应目前区块链行业的发展阶段，区块链的标准化工作应从满足用户的角度出发，以测试某个区块链系统对用户需求的匹配度为原则，开展功能和性能测试的“黑盒”标准化，而不是过早地对区块链技术进行规范。 2.衍生市场混乱处于炒作高峰期的区块链技术，不仅受到社会大众的广泛关注，而且存在着被不法分子所利用进行欺诈的情况。目前市场上存在着大量的打着数字货币的旗号，进行传销、诈骗、非法融资，这些数字货币利用门户网站、微博、微信公众号、贴吧等渠道进行宣传和招商活动，进行炒作，而不真正地拿着投资者的钱去研究、开发区块链引用上。 3.安全威胁在大量资本融入到区块链行业中时，区块链技术得到了飞速的发展，同时，安全问题也得到了广泛的关注，近期许多数字货币交易平台出现黑客攻击，盗取用户的数字货币达到百亿元级别，这是交易平台技术上未达到安全的要求。而在区块链财务类系统中，私钥是用户身份的唯一凭证，在有些应用中，需要将用户的私钥跟用户身份进行绑定，这样就需要通过平台来对用户的私钥进行管理，这种情况下，秘钥的管理会存在安全问题，而这个问题，并不能通过区块链系统自身来解决，而是需要区块链系统外部来解决。 4.难以监管区块链技术采用去中心化的理念，摆脱了传统中心化的管理机制所带来的诸多问题，但去中心化也意味着，主体不明确，监管困难，缺少对主体的有效控制，比如在上次的黑客勒索时间，犯罪分子以比特币作为交易赎金，导致其身份极其难以追查。 大概介绍到这里，未完待续，我们一起来见证区块链的崛起，有意见，欢迎mail我，邮箱chenzuoli709@gmail.com.]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka命令行基本操作]]></title>
    <url>%2F2018%2F07%2F14%2Fkafka%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[这里先介绍下kafka的基本知识及应用场景：它是一个分布式、高吞吐量、容错性好的消息队列，基于生产者、消费者模型来实现消息的生产消费，在我们的应用系统中，可以起到数据流缓存、解耦合、高效的作用。下面是kafka命令行的基本操作。 对于kafka集群的安装配置，这里就不讲解了，apache官网有详细配置方案，可参考：apache kafka配置详解注：本次使用操作的基本环境为kafka 1.1.0、centos 7.4 1.后台启动kafka broker1./bin/kafka-server-start.sh -daemon config/server.properties 2.关闭kafka broker：1./bin/kafka-server-stop.sh 3.创建topic：1./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 2 --partitions 2 --topic test 4.创建生产者：1./bin/kafka-console-producer.sh --broker-list hadoop31:9092,hadoop32:9092,hadoop33:9092 --topic test 5.创建消费者：1./bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning 6.查看所有topic：1./bin/kafka-topics.sh --list --zookeeper localhost:2181 7.查看topic状态：1./bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test 8.查看topic消费情况：1./bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list hadoop31:9092,hadoop32:9092,hadoop33:9092 --topic sparktest --time -1 9.删除某个topic：1./bin/kafka-topics.sh --delete --zookeeper hadoop31:2181,hadoop32:2181,hadoop33:2181 --topic sparktest 注意设置配置参数delete.topic.enable=true，然后重启kafka和zookeeper才可以生效； 好了，到这里还没完，后期会持续更新，我会把我工作中使用到的经过测试没问题的kafka知识记录下来分享给大家，如果有什么问题，请大家mail我，希望大家支持。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[比特币原理]]></title>
    <url>%2F2018%2F07%2F05%2F%E6%AF%94%E7%89%B9%E5%B8%81%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大家好，今天来说说18年很火的比特币，由于现代社会的全球化进程加快，各个国家之间的信息交换，信息共享出现了许许多多的问题，比如你出国旅游，还得更换货币，还得办个护照来证明你是个人，还有就是各个银行或金融机构对货币的监督和管理，一旦这些机构出现问题，那么我们的钱就这样没了，这是不是很亏呢，今天将的区块链技术，就可以解决这个问题，下面来详细讲解它的运行原理和应用场景。 一、去中心化1.如何确认付款方是否有足够的比特币进行支付？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;去中心化网络，舍去银行等金融机构（他们通过用户账户余额来解决这个问题）的依赖，比特币的解决方案是每笔交易都必须把以前的交易记录作为基础。 2.转账记录的存储和维护2.1如何进行同步，互联网上的计算机交易记录同步；2.2如何防止黑客篡改记录；2.3如何防止同一笔比特币收入被重复使用&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个时候就需要用到区块链技术，区块链仅仅维护一个交易链，每个人将自己的转账记录发布到网络上，矿工收集这些转账记录，生成一个区块，世界上有许多矿工，那么到底哪一个矿工生成的区块才能链接到区块链的末尾呢？这时，就出现了一个机制，每个矿工在生成了这个区块后，需要对前一个区块链上前一个区块的sha256函数值+这个新区块的基本信息+这个新区块所包含的所有交易记录+随机数进行sha256函数计算，得到一个hash值前72位均为0，那么找到符合要求的随机数需要进行2的72次方sha256函数运算，计算机大概平均需要10分钟左右算出来，然后发布到区块链网络上，在这10分钟之内，一般只有一个矿工能够计算出符合要求的随机数，所以就避免了多个矿工同时生成区块而无法判断到底将哪一个区块链接到区块链的尾端的问题了。矿工得到符合要求的随机数后，发布到网络上，网络上的其他计算机会进行校验：随机数校验，交易记录校验。一切都没有问题后，就讲该区块添加到自己电脑上区块链的末尾，完成交易记录的同步 二、不可篡改：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;针对转账交易来进行说明，利用非对称加密算法，达到不可篡改的目的，具体如下,如，小红转账给小白50元，这条记录 1.原始记录进行SHA256加密得到hash值1；2.小红利用她的私钥对hash值1进行加密得到hash值2；3.其他人利用小红的公钥（公钥是公开的），对hash值2进行解密得到hash值3；&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果hash值3等于hash值1，那么说明这个签名是针对这条记录的，并且这条记录是小红发出的，接受到的记录与原始记录相同，未被篡改。 三、记录可回溯&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;比特币的每条交易记录都记录在区块链上，当小红转账给小白时，会先计算所有转账给小红的比特币数量，来确认小红有足够的比特币进行交易，所以记录可回溯。 四、比特币问答1.比特币是如何发行的？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;新比特币作为对矿工的奖励，进入比特币网络进行流通，每生成21万个区块，奖励减半，从第0个区块到第21万个区块，每生成一个区块，奖励给矿工50个比特币，从第21万个区块开始的21万个区块，每生成一个区块，奖励给矿工25个比特币，从第42万个区块开始的21万个区块，每生成一个区块，奖励给矿工12.5个区块，以此类推。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从第693个区块开始，对矿工的奖励为0，也就是不再有新的比特币流入比特币网络，到时，累计有2100万个比特币流入到比特币网络，矿工的收入将完全来自于每笔比特币转账交易的交易费，交易费只是比特币在账户之间转移，不是新产生的比特币。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;也就是说，比特币网络上的比特币总量永远不会超过2100万个。 2.比特币存在什么地方？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;比特币一般存在比特币客户端软件的数据文件里&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果把数据文件弄丢了，比如计算机硬盘坏了，就永远地失去了里面的比特币，而且比特币网络里流通的比特币总量也会减少。 3.比特币转账和支付宝转账有啥区别？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;比特币不是任何银行和金融机构发行的，使用比特币不需要绑定银行卡，不需要任何身份证明，不需要手机短信认证，只要能上网，只要安装了比特币客户端软件，就可以转账或收款，所有的账户不受任何机构监督和管理，转错了人，没有后悔药，完全没有挽回的余地。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在中国大陆，支付宝转账转的一般是人民币，人民币是中国人民银行发行的，人民币的发行量由中国人民银行根据社会发展需要决定。使用支付宝，需要绑定银行卡，转账或收款受支付宝和银行管理。转错了人，可以找支付宝和银行协调，有可能挽回损失。 4.比特币转账的手续费怎么算？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;比特币软件会给一个推荐值和最低值，但具体多少由付款方自己定。既然手续费自己定，那么付款方将手续费设为最低值会怎么样呢？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;请看下面这张图片：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;比特币网络中，支付最少交易费是可以的。但是请注意，当交易量大到超出网络可处理时，矿工会选择手续费更高的交易记录到账本，而您的交易可能永远被搁置，无法确认。 5.比特币所使用的主要技术和特点：5.1利用sha256和非对称加密算法制作签名；5.2利用区块链中的区块存储比特币交易记录；5.3设置额外的工作，从而控制单位时间内生成区块的个数，同时保护比特币网络；5.4将一定数额的比特币和区块内的所有交易费奖励给成功生成该区块的矿工激励更多矿工加入比特币网络，促进比特币网络的茁壮成长；5.5比特币转账不依赖任何银行或其他金融机构；&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;好了，到这里基本上就讲完了，这是我最近从youtube网站上看过很多次讲解的各种比特币、区块链的视频才了解的，国内的资源还很少，天朝也不看好比特币，但是区块链技术是在积极推动的，希望大家看完了总结之后，对比特币的原理有一定的了解，如果有什么不对的地方，请留言指正，或者发送到邮箱chenzuoli709@gmail.com. 附上资源：比特币原理https://www.youtube.com/watch?v=obRzfcvMshM&amp;t=0s&amp;list=LL6p-2jKOMljSPte26mVy3Vw区块链开放前景及学习平台https://www.youtube.com/watch?v=8YY8yuKqziw&amp;t=0s&amp;list=LL6p-2jKOMljSPte26mVy3Vw许知远对话搜狗CEO王小川将区块链https://www.youtube.com/watch?v=pV2DxjxpKu4&amp;t=0s&amp;list=LL6p-2jKOMljSPte26mVy3Vw 五、数字货币投资&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;鄙人还是非常非常看好比特币、区块链技术的，也在火币平台上购买了一些比特币，期待它在以后的日子里带我实现财务自由，想参与的伙伴们，点击链接注册https://www.huobi.br.com/zh-cn/topic/invited/?invite_code=2i9d3确认邀请码：2i9d3]]></content>
      <categories>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>bitcoin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018-06-19]]></title>
    <url>%2F2018%2F06%2F19%2FETL%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[大家好，好久没更新了，疲于工作和团队建设，都是一团糟，但是代码还是敲了一些，见我的github/ETL.git项目，写的是基本清洗工具类，点击查看详情。 https://github.com/chenzuoli/ETL.git该项目包括如下内容： ETL数据基本清洗包括以下分类： 1.日期时间；2.数值；3.字符串；4.字符；5.金钱；6.数据库（mysql、postgresql、mongodb、hbase、hdfs、memcached）；7.加解密（md5、sha、base64、aes、rsa）；8.文件；9.http服务；10.正则表达式；11.个人信息：身份证号、手机号、姓名清洗和扩展；后期会不断更新，望大家指正，多谢。]]></content>
      <categories>
        <category>工具类</category>
      </categories>
      <tags>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读取配置文件工具类]]></title>
    <url>%2F2018%2F04%2F03%2F%E8%AF%BB%E5%8F%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[我们在编程过程中，尤其是应用程序，需要经常更改的配置参数或者某些使用较多的固定值，我们可以把它提取出来，放到一个配置文件中，当我们需要修改这个值时，就可以做到不重新发布应用，或者不更改许多的代码，这样，即降低了程序代码的后期维护成本，也降低了程序代码的耦合性，这是我们每个合格的程序员应该具备的基本技能。下面来介绍一个读取配置文件的工具类。 maven项目引入依赖123456&lt;!-- https://mvnrepository.com/artifact/log4j/log4j --&gt;&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt;&lt;/dependency&gt; 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package com.payegis.czl.util;import org.apache.log4j.Logger;import java.io.File;import java.io.InputStreamReader;import java.util.Enumeration;import java.util.HashMap;import java.util.Map;import java.util.Properties;/** * User: chenzuoli * Date: 2018/3/20 * Time: 15:13 * Description: 读取配置文件工具类 * Ps: Properties */public class PropertiesUtils &#123; private static Logger logger = Logger.getLogger(PropertiesUtils.class); private static Properties props; private static String configHome = System.getenv(&quot;pesdk_home&quot;); private static String configFilePath = configHome + File.separator + &quot;conf&quot; + File.separator + &quot;db.properties&quot;; static &#123; readProperties(configFilePath); logger.info(&quot;配置文件加载成功。&quot;); &#125; public static void main(String[] args) &#123; logger.info(get(&quot;psqlPassword&quot;)); &#125; /** * 加载配置文件 * * @param fileName */ private static void readProperties(String fileName) &#123; try &#123; props = new Properties(); InputStreamReader inputStreamReader = new InputStreamReader(new FileInputStream(new File(fileName)), &quot;utf-8&quot;); props.load(inputStreamReader); &#125; catch (Exception e) &#123; logger.error(&quot;加载配置文件失败！&quot;); e.printStackTrace(); &#125; &#125; /** * 根据key读取对应的value * * @param key * @return */ public static String get(String key) &#123; return props.getProperty(key); &#125; /** * 得到所有的配置信息 * * @return */ public static Map&lt;?, ?&gt; getAll() &#123; Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); Enumeration&lt;?&gt; enu = props.propertyNames(); while (enu.hasMoreElements()) &#123; String key = (String) enu.nextElement(); String value = props.getProperty(key); map.put(key, value); &#125; return map; &#125; 使用方法首先在本地环境变量中配置一个环境变量，名称为pesdk_home，当然你自己也可以随便定义，然后在该环境变量对应的路径下创建conf文件夹，再在conf文件夹下创建db.properties文件，你的配置项就可以添加到该配置文件中了，使用的时候，直接调用get方法，传入响应的key就可以获得value，赶紧试试吧。 ps如果大家在使用logger打印不出任何东西的时候，可能原因是你没有配置log4j的打印等级，这里就粘贴一下log4j的配置文件吧。这个配置文件的功能是error及fatal级日志打印到一个文件中，info及warn打印到另一个文件中，分日期打印。 123456789101112131415161718192021222324252627# Root logger optionlog4j.rootLogger=INFO, file, stdout # Direct log messages to a log filelog4j.appender.file=org.apache.log4j.RollingFileAppenderlog4j.appender.file.File=DFTSystemWeb2.loglog4j.appender.file.MaxFileSize=10MBlog4j.appender.file.MaxBackupIndex=1log4j.appender.file.layout=org.apache.log4j.PatternLayoutlog4j.appender.file.layout.ConversionPattern=[%d&#123;dd/MM/yy HH:mm:ss:sss z&#125;] %5p %c&#123;1&#125;:%L - %m%n# Direct log messages to stdoutlog4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.Target=System.outlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=[%d&#123;dd/MM/yy HH:mm:ss:sss z&#125;] %5p %c&#123;1&#125;:%L - %m%nlog4j.logger.org.eclipse.jetty=INFOlog4j.logger.org.springframework=INFOlog4j.logger.com.mchange=ERRORlog4j.logger.org.hibernate=INFO#log4j.logger.org.hibernate.type=tracelog4j.logger.com.tulando.common.filter.MethodProfileAspect=info,ProfileAspectlog4j.appender.ProfileAspect=org.apache.log4j.RollingFileAppenderlog4j.appender.ProfileAspect.File=api-profile.loglog4j.appender.ProfileAspect.MaxFileSize=1024KBlog4j.appender.ProfileAspect.MaxBackupIndex=5log4j.appender.ProfileAspect.Append=truelog4j.appender.ProfileAspect.layout=org.apache.log4j.PatternLayoutlog4j.appender.ProfileAspect.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; [%c]-[%p] %m%n 整个方式到这里就配置完成了，如果在使用的过程中，有什么问题，或者有值得优化的地方，请联系我chenzuoli709@gmail.com.]]></content>
      <categories>
        <category>工具类</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作mysql工具类]]></title>
    <url>%2F2018%2F04%2F02%2F%E6%93%8D%E4%BD%9Cmysql%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[下面介绍的是操作mysql的工具类，集成增删改查等功能方法，使用dbcp数据库连接池，让你的程序更高效。具体请看详情。 备注：代码环境jdk8（jdk7也可以） maven项目依赖12345678910111213141516&lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.41&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp2&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;version&gt;2.4.2&lt;/version&gt;&lt;/dependency&gt; 数据库连接配置文件配置文件jdbc.properties放置在项目resources目录下，配置如下： 123456789driverClassName=com.mysql.jdbc.Driverurl=jdbc:mysql://localhost:3306/zs1?useSSL=falseusername=rootpassword=rootinitialSize=10maxIdle=5minIdle=2autoReconnect=trueautoReconnectForPools=true 具体代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270import com.payegis.czl.model.QueryLogHistory;import org.apache.commons.dbcp2.BasicDataSourceFactory;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import javax.sql.DataSource;import java.io.IOException;import java.sql.*;import java.util.*;/** * User: 陈作立 * Date: 2018/2/2 * Time: 13:39 * Description: 操作mysql数据库工具类 * Ps: mysql */public class DBCPUtil &#123; private static Logger loger = LoggerFactory.getLogger(DBCPUtil.class); private static DataSource dataSource = null; static &#123; loger.info(&quot;---------开始初始化数据库连接池---------&quot;); Properties prop = new Properties(); try &#123; prop.load(DBCPUtil.class.getClassLoader().getResourceAsStream(&quot;jdbc.properties&quot;)); dataSource = BasicDataSourceFactory.createDataSource(prop); &#125; catch (IOException e) &#123; loger.error(&quot;---------加载[jdbc.properties]失败---------&quot;, e); &#125; catch (Exception e) &#123; loger.error(&quot;----------初始化数据库连接池异常失败---------&quot;, e); &#125; loger.info(&quot;---------数据库连接池初始化完成---------&quot;); &#125; /** * 获取数据库连接 * * @return */ public static Connection getConnection() &#123; Connection conn = null; if (conn != null) &#123; return conn; &#125; try &#123; conn = dataSource.getConnection(); &#125; catch (SQLException e) &#123; loger.error(&quot;---------数据库连接池获取连接异常---------&quot;, e); &#125; return conn; &#125; /** * 关闭数据库连接 * * @param connection 数据库连接 */ public static void close(Connection connection) &#123; if (connection != null) &#123; try &#123; connection.close(); &#125; catch (SQLException e) &#123; loger.error(&quot;---------关闭Connection异常---------&quot;, e); &#125; &#125; &#125; /** * 关闭数据库连接 * * @param conn 数据库连接 * @param stat 预编译 */ public static void close(Connection conn, Statement stat) &#123; try &#123; if (stat != null) &#123; stat.close(); &#125; &#125; catch (SQLException e) &#123; loger.error(&quot;---------关闭Connection、PreparedStatement异常---------&quot;, e); &#125; finally &#123; close(conn); &#125; &#125; /** * 关闭数据库连接 * * @param conn 数据库连接 * @param stat 预编译 * @param rs 结果集 */ public static void close(Connection conn, Statement stat, ResultSet rs) &#123; try &#123; if (rs != null) &#123; rs.close(); &#125; &#125; catch (SQLException e) &#123; loger.error(&quot;---------关闭ResultSet异常---------&quot;, e); &#125; finally &#123; close(conn, stat); &#125; &#125; /** * 执行查询 * * @param sql * @param params * @return */ public static List&lt;Map&lt;String, Object&gt;&gt; executeQuery(String sql, Object... params) &#123; List&lt;Map&lt;String, Object&gt;&gt; rowDataList = new ArrayList&lt;Map&lt;String, Object&gt;&gt;(); Connection conn = null; PreparedStatement stat = null; ResultSet resultSet = null; try &#123; conn = getConnection(); stat = conn.prepareStatement(sql); stat.setFetchSize(10000); setStatParams(stat, params); resultSet = stat.executeQuery(); rowDataList = getResultList(resultSet); &#125; catch (SQLException e) &#123; loger.error(&quot;---------数据查询异常[&quot; + sql + &quot;]---------&quot;, e); &#125; finally &#123; close(conn, stat, resultSet); &#125; return rowDataList; &#125; /** * 更新数据 * * @param sql sql语句 * @param params 参数 * @return 更新成功:true 更新失败:false */ public static boolean executeUpdate(String sql, Object... params) &#123; boolean isUpdated = false; Connection conn = null; PreparedStatement stat = null; try &#123; conn = getConnection(); conn.setAutoCommit(false); stat = conn.prepareStatement(sql); setStatParams(stat, params); int updatedNum = stat.executeUpdate(); isUpdated = updatedNum == 1; conn.commit(); &#125; catch (SQLException e) &#123; try &#123; conn.rollback(); &#125; catch (SQLException e1) &#123; e1.printStackTrace(); &#125; loger.error(&quot;---------更新失败! sql:[&quot; + sql + &quot;], params:[&quot; + Arrays.toString(params) + &quot;]---------&quot;, e); &#125; finally &#123; close(conn, stat); &#125; return isUpdated; &#125; /** * 执行批处理 * * @param sqlList sql语句集合 * @return */ public static boolean executeBatch(List&lt;String&gt; sqlList) &#123; if (sqlList == null || sqlList.isEmpty()) &#123; return true; &#125; Connection conn = null; Statement stat = null; try &#123; conn = getConnection(); conn.setAutoCommit(false); stat = conn.createStatement(); for (String sql : sqlList) &#123; stat.addBatch(sql); &#125; stat.executeBatch(); conn.commit(); return true; &#125; catch (SQLException e) &#123; try &#123; conn.rollback(); loger.error(&quot;---------批处理异常，执行回滚---------&quot;); &#125; catch (SQLException e1) &#123; loger.error(&quot;---------回滚异常---------&quot;, e1); &#125; loger.error(&quot;---------执行批处理异常---------&quot;); loger.error(&quot;---------批处理异常sql：&quot; + Arrays.toString(sqlList.toArray())); &#125; finally &#123; try &#123; if (conn != null) &#123; conn.setAutoCommit(true); &#125; &#125; catch (SQLException e) &#123; loger.error(&quot;---------设置自动提交异常---------&quot;, e); &#125; close(conn, stat); &#125; return false; &#125; /** * 获取列名及数据 * * @param rs 数据集 * @return */ private static List&lt;Map&lt;String, Object&gt;&gt; getResultList(ResultSet rs) throws SQLException &#123; List&lt;Map&lt;String, Object&gt;&gt; rowDataList = new ArrayList&lt;Map&lt;String, Object&gt;&gt;(); List&lt;String&gt; colNameList = getColumnName(rs); while (rs.next()) &#123; Map&lt;String, Object&gt; rowData = new HashMap&lt;String, Object&gt;(); for (String colName : colNameList) &#123; rowData.put(colName, rs.getObject(colName)); &#125; if (!rowData.isEmpty()) &#123; rowDataList.add(rowData); &#125; &#125; return rowDataList; &#125; /** * 获取列名 * * @param rs 数据集 * @return */ private static List&lt;String&gt; getColumnName(ResultSet rs) throws SQLException &#123; List&lt;String&gt; columnList = new ArrayList&lt;String&gt;(); try &#123; ResultSetMetaData metaData = rs.getMetaData(); int columnCount = metaData.getColumnCount(); for (int i = 1; i &lt;= columnCount; i++) &#123; columnList.add(metaData.getColumnName(i)); &#125; &#125; catch (SQLException e) &#123; loger.info(&quot;------获取表列表异常------&quot;, e); throw e; &#125; return columnList; &#125; /** * 设置参数 * * @param stat 预编译 * @param params 参数 */ private static void setStatParams(PreparedStatement stat, Object... params) throws SQLException &#123; if (stat != null &amp;&amp; params != null) &#123; try &#123; for (int len = params.length, i = 1; i &lt;= len; i++) &#123; stat.setObject(i, params[i - 1]); &#125; &#125; catch (SQLException e) &#123; loger.error(&quot;------设置sql参数异常---------&quot;); throw e; &#125; &#125; &#125;&#125; 好了，到这里就结束了，这个类基本可以满足操作mysql的需求了，大家放心使用吧，如果有什么问题，或者可以优化的地方，欢迎大家email我chenzuoli709@gmail.com]]></content>
      <categories>
        <category>工具类</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>utils</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[身份证号校验工具类IdentityUtil]]></title>
    <url>%2F2018%2F03%2F30%2F%E8%BA%AB%E4%BB%BD%E8%AF%81%E5%8F%B7%E6%A0%A1%E9%AA%8C%E5%B7%A5%E5%85%B7%E7%B1%BBIdentityUtil%2F</url>
    <content type="text"><![CDATA[一个人的身份证号，每个字符都有他独特的含义，前2位代表省、自治区、直辖市代码，3-4位代表地级市、盟、自治州代码，5-6位代表县、县级市、区代码，7-14位代表出生年月日，15-17位代表当天出生的顺序号，奇数代表男，偶数代表女，18位为校验码，由0-9、X组成，这个校验码的由来，是由前17位数字计算得来，具体计算方式，可以参考下述代码。 本代码介绍的是校验身份证的合法性工具类，具体如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128import java.util.Calendar;import java.util.GregorianCalendar;import java.util.HashMap;import java.util.Map;/** * 身份证验证的工具（支持5位或18位省份证） * 身份证号码结构： * 17位数字和1位校验码：6位地址码数字，8位生日数字，3位出生时间顺序号，1位校验码。 * 地址码（前6位）：表示对象常住户口所在县（市、镇、区）的行政区划代码，按GB/T2260的规定执行。 * 出生日期码，（第七位 至十四位）：表示编码对象出生年、月、日，按GB按GB/T7408的规定执行，年、月、日代码之间不用分隔符。 * 顺序码（第十五位至十七位）：表示在同一地址码所标示的区域范围内，对同年、同月、同日出生的人编订的顺序号， * 顺序码的奇数分配给男性，偶数分配给女性。 * 校验码（第十八位数）： * 十七位数字本体码加权求和公式 s = sum(Ai*Wi), i = 0,,16，先对前17位数字的权求和； * Ai:表示第i位置上的身份证号码数字值.Wi:表示第i位置上的加权因.Wi: 7 9 10 5 8 4 2 1 6 3 7 9 10 5 8 4 2； * 计算模 Y = mod(S, 11) * 通过模得到对应的校验码 Y: 0 1 2 3 4 5 6 7 8 9 10 校验码: 1 0 X 9 8 7 6 5 4 3 2 */public class IdentityUtil &#123; final static Map&lt;Integer, String&gt; zoneNum = new HashMap&lt;Integer, String&gt;(); static &#123; zoneNum.put(11, &quot;北京&quot;); zoneNum.put(12, &quot;天津&quot;); zoneNum.put(13, &quot;河北&quot;); zoneNum.put(14, &quot;山西&quot;); zoneNum.put(15, &quot;内蒙古&quot;); zoneNum.put(21, &quot;辽宁&quot;); zoneNum.put(22, &quot;吉林&quot;); zoneNum.put(23, &quot;黑龙江&quot;); zoneNum.put(31, &quot;上海&quot;); zoneNum.put(32, &quot;江苏&quot;); zoneNum.put(33, &quot;浙江&quot;); zoneNum.put(34, &quot;安徽&quot;); zoneNum.put(35, &quot;福建&quot;); zoneNum.put(36, &quot;江西&quot;); zoneNum.put(37, &quot;山东&quot;); zoneNum.put(41, &quot;河南&quot;); zoneNum.put(42, &quot;湖北&quot;); zoneNum.put(43, &quot;湖南&quot;); zoneNum.put(44, &quot;广东&quot;); zoneNum.put(45, &quot;广西&quot;); zoneNum.put(46, &quot;海南&quot;); zoneNum.put(50, &quot;重庆&quot;); zoneNum.put(51, &quot;四川&quot;); zoneNum.put(52, &quot;贵州&quot;); zoneNum.put(53, &quot;云南&quot;); zoneNum.put(54, &quot;西藏&quot;); zoneNum.put(61, &quot;陕西&quot;); zoneNum.put(62, &quot;甘肃&quot;); zoneNum.put(63, &quot;青海&quot;); zoneNum.put(64, &quot;宁夏&quot;); zoneNum.put(65, &quot;新疆&quot;); zoneNum.put(71, &quot;台湾&quot;); zoneNum.put(81, &quot;香港&quot;); zoneNum.put(82, &quot;澳门&quot;); zoneNum.put(91, &quot;外国&quot;); &#125; final static int[] PARITYBIT = &#123;&apos;1&apos;, &apos;0&apos;, &apos;X&apos;, &apos;9&apos;, &apos;8&apos;, &apos;7&apos;, &apos;6&apos;, &apos;5&apos;, &apos;4&apos;, &apos;3&apos;, &apos;2&apos;&#125;; final static int[] POWER_LIST = &#123; 7, 9, 10, 5, 8, 4, 2, 1, 6, 3, 7, 9, 10, 5, 8, 4, 2&#125;; /** * 身份证验证 *@param s 号码内容 *@return 是否有效 null和&quot;&quot; 都是false */ public static boolean checkIDCard(String certNo)&#123; if(certNo == null || (certNo.length() != 15 &amp;&amp; certNo.length() != 18)) return false; final char[] cs = certNo.toUpperCase().toCharArray(); //校验位数 int power = 0; for(int i=0; i&lt;cs.length; i++)&#123; if(i==cs.length-1 &amp;&amp; cs[i] == &apos;X&apos;) break;//最后一位可以 是X或x if(cs[i]&lt;&apos;0&apos; || cs[i]&gt;&apos;9&apos;) return false; if(i &lt; cs.length -1)&#123; power += (cs[i] - &apos;0&apos;) * POWER_LIST[i]; &#125; &#125; //校验区位码 if(!zoneNum.containsKey(Integer.valueOf(certNo.substring(0,2))))&#123; return false; &#125; //校验年份 String year = certNo.length() == 15 ? getIdcardCalendar() + certNo.substring(6,8) :certNo.substring(6, 10); final int iyear = Integer.parseInt(year); if(iyear &lt; 1900 || iyear &gt; Calendar.getInstance().get(Calendar.YEAR)) return false;//1900年的PASS，超过今年的PASS //校验月份 String month = certNo.length() == 15 ? certNo.substring(8, 10) : certNo.substring(10,12); final int imonth = Integer.parseInt(month); if(imonth &lt;1 || imonth &gt;12)&#123; return false; &#125; //校验天数 String day = certNo.length() ==15 ? certNo.substring(10, 12) : certNo.substring(12, 14); final int iday = Integer.parseInt(day); if(iday &lt; 1 || iday &gt; 31) return false; //校验&quot;校验码&quot; if(certNo.length() == 15) return true; return cs[cs.length -1 ] == PARITYBIT[power % 11]; &#125; private static int getIdcardCalendar() &#123; GregorianCalendar curDay = new GregorianCalendar(); int curYear = curDay.get(Calendar.YEAR); int year2bit = Integer.parseInt(String.valueOf(curYear).substring(2)); return year2bit; &#125; public static void main(String[] args) &#123; boolean mark = checkIDCard(&quot;650105195604040056&quot;); System.out.println(mark); &#125;&#125; 到这里就结束了，如有什么问题，请联系chenzuoli709@gmail.com]]></content>
      <categories>
        <category>工具类</category>
      </categories>
      <tags>
        <tag>utils</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java操作hbase工具类]]></title>
    <url>%2F2018%2F03%2F29%2Fjava%E6%93%8D%E4%BD%9Chbase%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[HBase是一个基于HDFS的数据库，拥有高可用、大量数据存储、列式存储等特点，在非结构化数据与半结构化数据存储方面，有很大的优势。我们一般测试时使用hbase shell命令行的方式来操作hbase数据库比较方便，但是在数据逻辑处理比较复杂时，那肯定是用它提供的API来操作更方便啦，下面就来给出一个java版操作hbase的工具类，提供给大家，我自己也一直使用这个类。 备注：本工具类使用的环境：hbase1.4.1 jdk1.8 hadoop3.0 maven项目添加依赖123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;!--hadoop/hbase都要依赖(RPC通信)，注意protobuf-java的版本，hbase1.4.1自带的protobuf-java版本是2.5.0的，所以如果你的程序是跑在服务器上的，需要跟服务器一致，不然会出现NoClsssFoundError--&gt;&lt;!--https://mvnrepository.com/artifact/com.google.protobuf/protobuf-java--&gt;&lt;dependency&gt; &lt;groupId&gt;com.google.protobuf&lt;/groupId&gt; &lt;artifactId&gt;protobuf-java&lt;/artifactId&gt; &lt;version&gt;3.5.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--hbase--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;$&#123;zookeeper.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt; &lt;artifactId&gt;hbase-client&lt;/artifactId&gt; &lt;version&gt;$&#123;hbase.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt; &lt;artifactId&gt;hbase-common&lt;/artifactId&gt; &lt;version&gt;$&#123;hbase.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.hbase/hbase --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt; &lt;artifactId&gt;hbase&lt;/artifactId&gt; &lt;version&gt;1.4.1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.hbase/hbase-spark --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt; &lt;artifactId&gt;hbase-spark&lt;/artifactId&gt; &lt;version&gt;1.2.0-cdh5.14.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.apache.hbase/hbase-server --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt; &lt;artifactId&gt;hbase-server&lt;/artifactId&gt; &lt;version&gt;1.4.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/fastutil/fastutil 这里使用fastutil，对比javautil自带集合类，它的读写性能更优，尤其在大数据的情况下，所以当你写的mr或者spark程序，使用到fastutil，会提升一些性能--&gt;&lt;dependency&gt; &lt;groupId&gt;fastutil&lt;/groupId&gt; &lt;artifactId&gt;fastutil&lt;/artifactId&gt; &lt;version&gt;5.0.5&lt;/version&gt;&lt;/dependency&gt; 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474package com.payegis.czl.util;import it.unimi.dsi.fastutil.objects.ObjectArrayList;import net.sf.json.JSONObject;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.hbase.HBaseConfiguration;import org.apache.hadoop.hbase.HColumnDescriptor;import org.apache.hadoop.hbase.HTableDescriptor;import org.apache.hadoop.hbase.TableName;import org.apache.hadoop.hbase.client.*;import org.apache.hadoop.hbase.filter.*;import org.apache.hadoop.hbase.io.compress.Compression;import org.apache.hadoop.hbase.util.Bytes;import org.apache.log4j.Logger;import java.io.BufferedReader;import java.io.FileInputStream;import java.io.IOException;import java.io.InputStreamReader;import java.util.*;/** * User: chenzuoli * Date: 2018/3/29 * Time: 9:20 * Description: Java操作HBase工具类 * Ps: Java HBase */public class HBaseUtil &#123; public static Configuration conf; public static Connection connection; public static Admin admin; public static Table table; private static Logger logger = Logger.getLogger(HBaseUtil.class); static &#123; try &#123; conf = HBaseConfiguration.create(); conf.set(&quot;hbase.zookeeper.property.clientPort&quot;, &quot;2181&quot;); conf.set(&quot;hbase.zookeeper.quorum&quot;, &quot;dev11,dev13,dev14&quot;); connection = ConnectionFactory.createConnection(conf); admin = connection.getAdmin(); logger.info(&quot;初始化hbase连接成功！&quot;); &#125; catch (IOException e) &#123; logger.error(&quot;初始化hbase连接异常！&quot;); e.printStackTrace(); &#125; catch (Exception e) &#123; logger.error(&quot;初始化hbase连接异常！&quot;); e.printStackTrace(); &#125; &#125; /** * @Description: 建表，如果表存在，那么不创建。如果未指定列族名称，默认定义一个cf1 * @Param: [tableName, familyName] * @return: boolean * @Author: CHEN ZUOLI * @Date: 2018/3/29 * @Time: 9:24 */ public static boolean createTable(String tableName, String familyName) &#123; boolean flag = false; if (familyName == null || familyName.length() == 0) &#123; familyName = &quot;cf1&quot;; &#125; TableName tbl = TableName.valueOf(tableName); Admin admin = null; try &#123; admin = connection.getAdmin(); if (admin.tableExists(tbl)) &#123; logger.info(&quot;Table &quot; + tbl.getNameAsString() + &quot; is already exists!&quot;); return flag; &#125; HTableDescriptor tableDescriptor = new HTableDescriptor(tbl); tableDescriptor.addFamily(new HColumnDescriptor(familyName).setCompressionType(Compression.Algorithm.SNAPPY)); admin.createTable(tableDescriptor); logger.info(&quot;Create table &quot; + tbl.getNameAsString() + &quot; success!&quot;); flag = true; &#125; catch (IOException e) &#123; logger.error(&quot;Create table failed!&quot;); e.printStackTrace(); &#125; catch (Exception e) &#123; logger.error(&quot;Create table failed!&quot;); e.printStackTrace(); &#125; return flag; &#125; /** * @Description: 插入一条数据到hbase * @Param: [connection, tableName, rowkey, columnFamily, key, value] * @return: void * @Author: CHEN ZUOLI * @Date: 2018/3/28 * @Time: 14:06 */ public static void insertOne(String tableName, String rowkey, String columnFamily, String key, String value) &#123; Table table = null; try &#123; table = connection.getTable(TableName.valueOf(tableName)); Put put = new Put(Bytes.toBytes(rowkey)); put.addColumn(Bytes.toBytes(columnFamily), Bytes.toBytes(key), Bytes.toBytes(value)); table.put(put); &#125; catch (IOException e) &#123; logger.error(&quot;insert hbase failed: &quot; + rowkey + &quot;,&quot; + columnFamily + &quot;,&quot; + key + &quot;,&quot; + value); e.printStackTrace(); &#125; catch (Exception e) &#123; logger.error(&quot;insert hbase failed: &quot; + rowkey + &quot;,&quot; + columnFamily + &quot;,&quot; + key + &quot;,&quot; + value); e.printStackTrace(); &#125; finally &#123; closeTableAndResult(table, null); &#125; &#125; /** * @Description: 批量插入数据到hbase * @Param: [filePath, tableName, familyName] * @return: void * @Author: CHEN ZUOLI * @Date: 2018/3/30 * @Time: 13:31 */ public static void insertBatch(String filePath, String tableName, String familyName) &#123; ObjectArrayList&lt;Put&gt; puts = new ObjectArrayList&lt;&gt;(); Table table = null; FileInputStream fis = null; BufferedReader br = null; try &#123; table = connection.getTable(TableName.valueOf(tableName)); fis = new FileInputStream(filePath); br = new BufferedReader(new InputStreamReader(fis)); String line = br.readLine(); while (line != null) &#123; JSONObject lineJsonObject = JSONObject.fromObject(line); String rowkey = MD5Utils.strToMd5_16(UUID.randomUUID().toString()); Set&lt;String&gt; keys = lineJsonObject.keySet(); Put put = new Put(Bytes.toBytes(rowkey)); for (String key : keys) &#123; put.addColumn(Bytes.toBytes(familyName), Bytes.toBytes(key), Bytes.toBytes(lineJsonObject.optString(key))); puts.add(put); &#125; line = br.readLine(); &#125; table.put(puts); &#125; catch (IOException e) &#123; logger.error(&quot;insert batch data to hbase failed!&quot;); e.printStackTrace(); &#125; catch (Exception e) &#123; logger.error(&quot;insert batch data to hbase failed!&quot;); e.printStackTrace(); &#125; finally &#123; try &#123; if (table != null) table.close(); if (fis != null) fis.close(); if (br != null) br.close(); &#125; catch (IOException e) &#123; logger.error(&quot;close table or stream failed!&quot;); e.printStackTrace(); &#125; &#125; &#125; /** * @Description: 批量插入数据到hbase * @Param: [rows, tableName, familyName] * @return: void * @Author: CHEN ZUOLI * @Date: 2018/4/2 * @Time: 10:19 */ public static void insertBatch(List&lt;Map&lt;String, Object&gt;&gt; rows, String tableName, String familyName) &#123; ObjectArrayList&lt;Put&gt; puts = new ObjectArrayList&lt;&gt;(); Table table = null; try &#123; table = connection.getTable(TableName.valueOf(tableName)); for (Map&lt;String, Object&gt; row : rows) &#123; String rowkey = MD5Utils.strToMd5_16(UUID.randomUUID().toString()); Put put = new Put(Bytes.toBytes(rowkey)); for (Map.Entry&lt;String, Object&gt; kv : row.entrySet()) &#123; String key = kv.getKey(); Object value = kv.getValue(); if (value == null) &#123; put.addColumn(Bytes.toBytes(familyName), Bytes.toBytes(key), null); &#125; else &#123; put.addColumn(Bytes.toBytes(familyName), Bytes.toBytes(key), Bytes.toBytes(value.toString())); &#125; &#125; puts.add(put); &#125; table.put(puts); &#125; catch (IOException e) &#123; logger.error(&quot;insert batch data to hbase failed!&quot;); e.printStackTrace(); &#125; catch (Exception e) &#123; logger.error(&quot;insert batch data to hbase failed!&quot;); e.printStackTrace(); &#125; finally &#123; closeTableAndResult(table, null); &#125; &#125; /** * @Description: 删除一张表 * @Param: [tableName] * @return: boolean * @Author: CHEN ZUOLI * @Date: 2018/3/29 * @Time: 9:40 */ public static boolean dropTable(String tableName) &#123; boolean flag = false; try &#123; admin.disableTable(TableName.valueOf(tableName)); admin.deleteTable(TableName.valueOf(tableName)); flag = true; &#125; catch (IOException e) &#123; logger.error(&quot;delete &quot; + tableName + &quot; table failed!&quot;); e.printStackTrace(); &#125; catch (Exception e) &#123; logger.error(&quot;delete &quot; + tableName + &quot; table failed!&quot;); e.printStackTrace(); &#125; return flag; &#125; /** * @Description: 根据rowkey删除一条记录 * @Param: [tablename, rowkey] * @return: boolean * @Author: CHEN ZUOLI * @Date: 2018/3/29 * @Time: 9:40 */ public static boolean deleteOneRowByRowkey(String tablename, String rowkey) &#123; boolean flag = false; try &#123; Delete d = new Delete(rowkey.getBytes()); table.delete(d); logger.info(&quot;delete row &quot; + rowkey + &quot; success!&quot;); flag = true; &#125; catch (IOException e) &#123; logger.error(&quot;delete row &quot; + rowkey + &quot; failed!&quot;); e.printStackTrace(); &#125; catch (Exception e) &#123; logger.error(&quot;delete row &quot; + rowkey + &quot; failed!&quot;); e.printStackTrace(); &#125; return flag; &#125; /** * @Description: 批量删除rowkey * @Param: [tablename, rowkeyList] * @return: boolean * @Author: CHEN ZUOLI * @Date: 2018/3/29 * @Time: 9:47 */ public static boolean deleteBatchRowByRowkey(String tablename, List&lt;String&gt; rowkeyList) &#123; boolean flag = false; ObjectArrayList&lt;Delete&gt; listDelete = new ObjectArrayList&lt;&gt;(); try &#123; for (int i = 0; i &lt; rowkeyList.size(); i++) &#123; Delete delete = new Delete(rowkeyList.get(i).getBytes()); listDelete.add(delete); &#125; table.delete(listDelete); logger.info(&quot;delete row list &quot; + rowkeyList + &quot; success!&quot;); flag = true; &#125; catch (IOException e) &#123; logger.error(&quot;delete row &quot; + rowkeyList + &quot; failed!&quot;); e.printStackTrace(); &#125; catch (Exception e) &#123; logger.error(&quot;delete row &quot; + rowkeyList + &quot; failed!&quot;); e.printStackTrace(); &#125; return flag; &#125; /** * @Description: 查询表中所有数据 * @Param: [tableName] * @return: List&lt;HashMap&lt;String,HashMap&lt;String,String&gt;&gt;&gt; * @Author: CHEN ZUOLI * @Date: 2018/3/29 * @Time: 9:51 */ public static List&lt;HashMap&lt;String, HashMap&lt;String, String&gt;&gt;&gt; queryAll(String tableName) &#123; ObjectArrayList&lt;HashMap&lt;String, HashMap&lt;String, String&gt;&gt;&gt; rowMapList = new ObjectArrayList&lt;&gt;(); // &lt;familyName, &lt;columnName, columnValue&gt;&gt; Table table = null; ResultScanner rs = null; try &#123; table = connection.getTable(TableName.valueOf(tableName));// ResultScanner rs = table.getScanner(new Scan().setMaxVersions()); // 获取所有版本数据 rs = table.getScanner(new Scan()); for (Result r : rs) &#123; rowMapList.add(resolveResult(r)); &#125; &#125; catch (IOException e) &#123; logger.error(&quot;Get all table data failed!&quot;); e.printStackTrace(); &#125; finally &#123; closeTableAndResult(table, rs); &#125; return rowMapList; &#125; /** * @Description: 单条件查询, 根据rowkey查询唯一一条记录 * @Param: [tableName, rowKey] * @return: List&lt;HashMap&lt;String,HashMap&lt;String,String&gt;&gt;&gt; * @Author: CHEN ZUOLI * @Date: 2018/3/29 * @Time: 10:47 */ public static List&lt;HashMap&lt;String, HashMap&lt;String, String&gt;&gt;&gt; queryByCondition(String tableName, String rowKey) &#123; ObjectArrayList&lt;HashMap&lt;String, HashMap&lt;String, String&gt;&gt;&gt; rowMapList = new ObjectArrayList&lt;&gt;(); // &lt;familyName, &lt;columnName, columnValue&gt;&gt; Table table = null; try &#123; Get get = new Get(rowKey.getBytes());// get.setMaxVersions(); // 获取所有版本数据 table = connection.getTable(TableName.valueOf(tableName)); Result r = table.get(get); rowMapList.add(resolveResult(r)); logger.info(&quot;获得到rowkey: &quot; + new String(r.getRow())); &#125; catch (IOException e) &#123; logger.error(&quot;Get table one data failed!&quot;); e.printStackTrace(); &#125; finally &#123; closeTableAndResult(table, null); &#125; return rowMapList; &#125; /** * @Description: 单条件按查询，查询多条记录 * @Param: [tableName] * @return: List&lt;HashMap&lt;String,HashMap&lt;String,String&gt;&gt;&gt; * @Author: CHEN ZUOLI * @Date: 2018/3/29 * @Time: 13:16 */ public static List&lt;HashMap&lt;String, HashMap&lt;String, String&gt;&gt;&gt; queryByCondition(String tableName, String familyName, String columnName, String columnValue) &#123; ObjectArrayList&lt;HashMap&lt;String, HashMap&lt;String, String&gt;&gt;&gt; rowMapList = new ObjectArrayList&lt;&gt;(); // &lt;familyName, &lt;columnName, columnValue&gt;&gt; Table table = null; ResultScanner rs = null; try &#123; table = connection.getTable(TableName.valueOf(tableName)); Filter filter = new SingleColumnValueFilter(Bytes.toBytes(familyName), Bytes.toBytes(columnName), CompareFilter.CompareOp.EQUAL, Bytes.toBytes(columnValue)); // 当列columnName的值为columnValue时进行查询 Scan s = new Scan(); s.setFilter(filter); rs = table.getScanner(s); for (Result r : rs) &#123; rowMapList.add(resolveResult(r)); &#125; &#125; catch (Exception e) &#123; logger.error(&quot;query with one filter failed!&quot;); e.printStackTrace(); &#125; finally &#123; closeTableAndResult(table, rs); &#125; return rowMapList; &#125; /** * @Description: 组合条件查询 * @Param: [tableName] * @return: List&lt;HashMap&lt;String,HashMap&lt;String,String&gt;&gt;&gt; * @Author: CHEN ZUOLI * @Date: 2018/3/29 * @Time: 13:26 */ public static List&lt;HashMap&lt;String, HashMap&lt;String, String&gt;&gt;&gt; queryByCondition(String tableName, String familyName, HashMap&lt;String, String&gt; paramMap) &#123; ObjectArrayList&lt;HashMap&lt;String, HashMap&lt;String, String&gt;&gt;&gt; rowMapList = new ObjectArrayList&lt;&gt;(); // &lt;familyName, &lt;columnName, columnValue&gt;&gt; Table table = null; ResultScanner rs = null; try &#123; table = connection.getTable(TableName.valueOf(tableName)); FilterList filterList = new FilterList(); for (Map.Entry&lt;String, String&gt; entry : paramMap.entrySet()) &#123; Filter filter = new SingleColumnValueFilter(Bytes.toBytes(familyName), Bytes.toBytes(entry.getKey()), CompareFilter.CompareOp.EQUAL, Bytes.toBytes(entry.getValue())); filterList.addFilter(filter); &#125; Scan scan = new Scan(); scan.setFilter(filterList); rs = table.getScanner(scan); for (Result r : rs) &#123; rowMapList.add(resolveResult(r)); &#125; rs.close(); &#125; catch (Exception e) &#123; logger.error(&quot;query with more filter failed!&quot;); e.printStackTrace(); &#125; finally &#123; closeTableAndResult(table, rs); &#125; return rowMapList; &#125; /** * @Description: 查询hbase，匹配rowkey前缀为dianRong的行 * @Param: [tableName] * @return: java.util.List&lt;java.util.HashMap&lt;java.lang.String,java.util.HashMap&lt;java.lang.String,java.lang.String&gt;&gt;&gt; * @Author: CHEN ZUOLI * @Date: 2018/4/3 * @Time: 20:21 */ public static List&lt;HashMap&lt;String, HashMap&lt;String, String&gt;&gt;&gt; rowkeyFuzzyQuery(String tableName)&#123; ObjectArrayList&lt;HashMap&lt;String, HashMap&lt;String, String&gt;&gt;&gt; rowMapList = new ObjectArrayList&lt;&gt;(); Table table = null; ResultScanner rs = null; try &#123; table = connection.getTable(TableName.valueOf(tableName)); Scan scan = new Scan(); Filter filter = new RowFilter(CompareFilter.CompareOp.EQUAL, new RegexStringComparator(&quot;dianRong.*&quot;)); scan.setFilter(filter); rs = table.getScanner(scan); for (Result r : rs) &#123; rowMapList.add(resolveResult(r)); &#125; &#125; catch (Exception e) &#123; logger.error(&quot;query with more filter failed!&quot;); e.printStackTrace(); &#125; finally &#123; closeTableAndResult(table, rs); &#125; return rowMapList; &#125; /** * @Description: 解析查询hbase得到的结果，放入到HashMap中 * @Param: [result] * @return: java.util.HashMap&lt;String,HashMap&lt;String,String&gt;&gt; * @Author: CHEN ZUOLI * @Date: 2018/3/29 * @Time: 13:52 */ public static HashMap&lt;String, HashMap&lt;String, String&gt;&gt; resolveResult(Result result) &#123; HashMap&lt;String, HashMap&lt;String, String&gt;&gt; rowMap = new HashMap&lt;&gt;(); // &lt;familyName, &lt;columnName, columnValue&gt;&gt; HashMap&lt;String, String&gt; kvMap = new HashMap&lt;&gt;(); NavigableMap&lt;byte[], NavigableMap&lt;byte[], NavigableMap&lt;Long, byte[]&gt;&gt;&gt; map = result.getMap(); for (Map.Entry&lt;byte[], NavigableMap&lt;byte[], NavigableMap&lt;Long, byte[]&gt;&gt;&gt; entry : map.entrySet()) &#123; String familyName = new String(entry.getKey()); NavigableMap&lt;byte[], NavigableMap&lt;Long, byte[]&gt;&gt; valueInfoMap = entry.getValue(); for (Map.Entry&lt;byte[], NavigableMap&lt;Long, byte[]&gt;&gt; valueInfo : valueInfoMap.entrySet()) &#123; String key = new String(valueInfo.getKey()); NavigableMap&lt;Long, byte[]&gt; values = valueInfo.getValue(); Map.Entry&lt;Long, byte[]&gt; firstEntry = values.firstEntry(); Long timestampLastest = firstEntry.getKey(); String valueLastest = new String(firstEntry.getValue()); logger.info(&quot;familyName: &quot; + familyName + &quot;, key: &quot; + key + &quot;, value: &quot; + valueLastest + &quot;, timestamp: &quot; + timestampLastest);// for (Map.Entry&lt;Long, byte[]&gt; vals : values.entrySet()) &#123;// Long timestamp = vals.getKey();// String value = new String(vals.getValue());// &#125; kvMap.put(key, valueLastest); rowMap.put(familyName, kvMap); &#125; &#125; return rowMap; &#125; public static void closeTableAndResult(Table table, ResultScanner rs)&#123; try &#123; if (rs != null) rs.close(); if (table != null) table.close(); &#125; catch (IOException e) &#123; logger.error(&quot;close table failed!&quot;); e.printStackTrace(); &#125; &#125;&#125; 好了，文章到这里就结束了，如果大家在使用过程中，遇到什么问题，请联系我chenzuoli709@gmail.com。]]></content>
      <categories>
        <category>HBase</category>
      </categories>
      <tags>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark累加器的使用方法]]></title>
    <url>%2F2018%2F03%2F17%2FAccumulator%20must%20be%20registered%20before%20send%20to%20executor%2F</url>
    <content type="text"><![CDATA[运行spark程序，使用到了累加器Accumulator，目前使用的是spark2.3.0，累加器Accumulator的定义方法变了，具体查看详细内容。 之前spark1.6.0时，累加器的定义及使用方式为： 123456Accumulator&lt;Integer&gt; accum = sc.accumulator(0);sc.parallelize(Arrays.asList(1, 2, 3, 4)).foreach(x -&gt; accum.add(x));// ...// 10/09/29 18:41:08 INFO SparkContext: Tasks finished in 0.317106 saccum.value();// returns 10 在spark2.3.0中，累加器的定义方式应该为： 123456LongAccumulator accum = jsc.sc().longAccumulator();sc.parallelize(Arrays.asList(1, 2, 3, 4)).foreach(x -&gt; accum.add(x));// ...// 10/09/29 18:41:08 INFO SparkContext: Tasks finished in 0.317106 saccum.value();// returns 10 之前的方式已被标记为Deprecated。也可以如此，先定义，在注册到SparkConf： 1234LongAccumulator countDftResult = new LongAccumulator();LongAccumulator countFailed = new LongAccumulator();sc.register(countDftResult); // 注册累加器sc.register(countFailed); 如果不注册，会出现Accumulator must be registered before send to executor异常。到这里就基本可以使用累加器了，谢谢大家，如果有什么问题，请留言。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git服务器端配置详解]]></title>
    <url>%2F2018%2F03%2F10%2FGit%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[我们在公司中，一个项目在开发过程中必定要涉及到同事之间的协同作战，此时代码管理就必不可少了，程序员用的最多的就是git了吧，但是公司的代码是禁止上传到github上的，所以需要自己搭建一个内部的git server服务器供公司内部使用，下面来具体就介绍。 本安装教程适用于centos服务器，其他版本linux服务器步骤一样，运行命令会不相同，自己转换即可。配置git server，原理就是将客户端的公钥id_rsa.pub添加到服务端的密钥文件authorized_keys中，多个用户另起一行拼接到该文件中即可。下面介绍安装的两种方法： 方法一：yum安装安装git软件12yum install git -ygit --version git –version可以查看安装的git版本 12[git@hadoop3 gitrepo]$ git --versiongit version 1.8.3.1 系统是centos7，自带git版本太低，但可以使用。 添加git用户组和用户12groupadd gituseradd git -g git 创建登录证书1234su gitcdmkdir .ssh &amp;&amp; chmod 700 .sshtouch .ssh/authorized_keys &amp;&amp; chmod 600 .ssh/authorized_keys 这里注意，一定要设置authorized_keys文件的权限为600，权限太大或太小都会造成cannot access的问题，我就遇到过这个坑。 免秘钥复制客户端的公钥到服务端的authorized_keys文件中 初始化git仓库创建一个git仓库文件夹，专门存放项目的地方，并创建一个项目，初始化： 12345mkdir /srv/git -pcd /srv/gitmkdir project.gitcd project.gitgit init --bare bare的意思就是初始化一个裸仓库，并不存储用户push的数据，只存储元数据。 提交项目到git server下面的命令是在客户端（另一台机器，可以是windows，也可以是linux）上执行的： 12345678cd myprojectgit initgit config --global user.email “chenzuoli709@163.com”git config --global user.name “chenzuoli”git add .git commit -m “initial commit”git remote add origin git@gitserver:/srv/git/project.gitgit push origin master 注意：提交的时候需要将gitserver更换成自己的git服务器的ip或者映射域名。 克隆项目1git clone git@gitserver:/srv/git/project.git 也是要替换gitserver的。 方法二：自定义安装下载最新稳定版gitgit最新版下载 添加git用户组和用户12groupadd gituseradd git -g git 上传解压1234su gitcd $GIT_HOMExz -d git-2.9.5.tar.xztar xvf git-2.9.5.tar 环境准备1yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel perl-devel gcc -y 预编译、编译、安装123cd git-2.9.5./configure -prefix=$GIT_HOMEmake &amp;&amp; make install 其中GIT_HOME是自己指定的git安装目录。 配置配置跟方法一一样 添加链接上述步骤配置完成后，我们在push clone时会出现如下问题： 12345678bash: git-receive-pack: command not foundfatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists.bash: git-upload-pack: command not foundfatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists. 原因是自定义安装时git的执行文件不在/usr/bin下，添加链接即可： 12345ln -s /usr/local/gitserver/install/bin/git /usr/bin/gitln -s /usr/local/gitserver/install/bin/git-shell /usr/bin/git-shellln -s /usr/local/gitserver/install/bin/git-upload-archive /usr/bin/git-upload-archiveln -s /usr/local/gitserver/install/bin/git-upload-pack /usr/bin/git-upload-packln -s /usr/local/gitserver/install/bin/git-receive-pack /usr/bin/git-receive-pack 到这里配置就基本完成了，谢谢大家，如果有什么问题，请留言。]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ambari管理监控hadoop生态系统的环境安装及问题解答]]></title>
    <url>%2F2018%2F03%2F10%2Fambari%E7%AE%A1%E7%90%86%E7%9B%91%E6%8E%A7hadoop%E7%94%9F%E6%80%81%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E5%8F%8A%E9%97%AE%E9%A2%98%E8%A7%A3%E7%AD%94%2F</url>
    <content type="text"><![CDATA[首先来介绍下ambari，它是一个apache的一个顶级项目，hadoop生态组件的监控、管理工具，相比较于cloudera公司的CDH，它的特点是完全开源，一键部署安装、管理、监控大数据各组件，省时省力，下面就来介绍ambari环境是如何安装的。 本安装教程适用于操作系统centos7，在某一台服务器上安装，原理就是虚拟化该服务器成多个virtual box，然后启动ambari服务，管理这些虚拟机。 安装安装步骤可以参考官网：ambari.apache.org 环境准备1yum install lrzsz openssl openssh-clients git maven -y 下载安装VirtualBox、VagrantVirtualBox选择最新稳定版.rpm文件下载即可上传到服务器使用yum安装 下载ambari-vagrant123git clone https://github.com/u39kun/ambari-vagrant.gitcat ambari-vagrant/append-to-etc-hosts.txt &gt;&gt; /etc/hosts --配置ip、域名映射vagrant --生成密钥 启动VMs1cd ambari-vagrant 你可以看到在该文件夹下有许多centos的版本，官方说centos6.8对ambari的兼容性最好，我们就用centos6.8吧。 123cd centos6.8cp ~/.vagrant.d/insecure_private_key . --将密钥复制到当前文件夹，注意不要少了组后面的一个点，代表当前文件夹./up.sh 3 --启动3个virtual machine 正常的话，就启动了c6801 c6802 c6803这三台虚拟机 登录VMs12vagrant ssh c6801su - ssh没问题的话，说明安装是没问题的，下面来安装ambari-server，以root用户完成下面的操作。 安装ambari-server下载ambari的源，安装并启动ambari-server 1234wget -O /etc/yum.repos.d/ambari.repo http://public-repo-1.hortonworks.com/ambari/centos6/2.x/updates/2.5.1.0/ambari.repoyum install ambari-server -yambari-server setup -sambari-server start 启动成功后，我们可以访问ambari的web界面： http://c6801.ambari.apache.org:8080，初始的登录用户名和密码均为admin，以同样的方式可以访问c6802 c6803，然后我们就可以对着三台虚拟机进行安装hadoop生态的各个组件了。 问题安装过程中会出现各种问题，具体问题及解决方案如下： 启动虚拟盒的时候报错运行命令： 1./up.sh 3 错误日志如下： 1234There was an error while excuting &apos;VBoxMange&apos;, a CLI used by vagrant for controlling VirtualBox, The command and stderr is shown below.Command: [&quot;startvm&quot;, &quot;afb1736b-3bab-4d1a-a968-16aba764195a&quot;, &quot;--type&quot;, &quot;gui&quot;]Stderr: VBoxManage: error: The virtual machine &quot;centos68-c6801-1520048454672_80399&quot; has terminated upexpectedly during startup because of singal 6.VBoxManage: error: Details: code NS_ERROR_FAILURE (0x80004005), componnent MachineWrap, interface IMachine. 错误原因：linux系统中的kernel module与ambari需要使用的kernel模块版本不匹配，导致vboxdrv服务启动异常，可以使用命令查看vboxdrv服务的启动情况： 1systemctl status vboxdrv 解决办法：1.安装更新kernel 1yum install kernel -y 2.安装kernel-devel 1yum install kernel -y 3.重启服务器 1reboot 4.启动vboxdrv服务 12systemctl start vboxdrvsystemctl status vboxdrv --查看状态 到这里配置就基本完成了，谢谢大家，如果有什么问题，请留言。]]></content>
      <categories>
        <category>环境安装</category>
      </categories>
      <tags>
        <tag>ambari</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows下gvim打开文件中文乱码]]></title>
    <url>%2F2018%2F02%2F08%2Fwindows%E4%B8%8Bvim%E6%89%93%E5%BC%80%E6%96%87%E4%BB%B6%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%2F</url>
    <content type="text"><![CDATA[习惯了linux操作命令，突然有需要使用到windows cmd命令，例如安装某些软件时，需要用命令方式去安装： 1npm install hexo-cli 安装完成后，需要编辑一些配置文件，这个时候，去’计算机’中重新定位到该配置文件的位置时，是很不方便的，如果有个类似vim的工具多好，windows自带的文本编辑工具notepad打开后还不能像vim一样操作，很是不适，不过总有神一般的人物开发出好用的工具。windows下有类似linux下的vim工具gvim，但是gvim打开某些文件时，中文乱码，很是让人烦恼，下面就来介绍如何解决乱码的问题。 windows下默认vim打开是gbk格式的，所以中文乱码，需要进行设置vim打开时加载文件时的编码，参照如下设置： 打开gvim客户端 编辑_vimrc配置文件方式一： 方式二：直接编辑文件%VIM_HOME%_vimrc添加如下配置：12set enc=utf8 设置打开文件缓冲区编码set fencs=utf8,gbk,gb2312,gb18030,cp936 设置文件编码 设置后，再次打开ok。如果gvim菜单栏中文乱码编辑配置文件_vimrc，添加如下配置： 12source $VIMRUNTIME/delmenu.vim 设置gvim菜单文件编码source $VIMRUNTIME/menu.vim 设置gvim菜单文件编码]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>gvim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu防火墙操作]]></title>
    <url>%2F2018%2F02%2F07%2Fubuntu%E9%98%B2%E7%81%AB%E5%A2%99%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[使用过了centos的同胞们，听说ubuntu的交互性很不错，可视化界面也很炫酷，果断更换ubuntu系统，但是安装完成之后，感觉都不会使用linux系统了，于是各种google查询操作方法，下面来简单介绍ubuntu防火墙的操作。 使用ubuntu系统，配置防火墙稍微跟centos不太一样，有一样工具，叫做ufw，即uncomplicated firewall简单防火墙，刚开始用的时候不太习惯，记住这两个单词就行。ubuntu系统自带就有这个工具，可能版本的原因，你的ubuntu可能没有，不用担心，没有先来安装。 安装ufw工具1sudo apt install ufw -y 如果报错找不到包： 1234Reading package lists... DoneBuilding dependency tree Reading state information... DoneE: Unable to locate package ufw 更新一下依赖库就行： 1sudo apt-get update 然后继续安装ufw，安装完成后，我们来启动它1sudo ufw enable 此时防火墙就开启了，默认可以访问部分端口，不如22、443，想关闭所有外部ip对本机的端口访问的话，执行命令：1sudo ufw default deny 查看防火墙状态1sudo ufw status 启用或者禁用端口、服务允许外部访问端口12sudo ufw allow 22sudo ufw allow sshd 禁止外部访问端口12sudo ufw delete allow 80sudo ufw delete allow apache2 允许某个ip访问本机所有端口1sudo ufw allow from 192.168.1.1 OK，希望对大家有帮助，我们一起进步，有问题欢迎在下方留言，或者给我发邮件，邮件地址：chenzuoli709@gmail.com。]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c3p0数据库连接池的使用方法]]></title>
    <url>%2F2018%2F02%2F03%2Fc3p0%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[c3p0数据库连接池，一个jdbc连接池，封装了增删改查的各种方法，并为我们自动优化了数据库连接，提高程序的运行效率。 需要添加的依赖： 123456789101112&lt;!-- https://mvnrepository.com/artifact/c3p0/c3p0 --&gt;&lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/com.mchange/c3p0 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.mchange&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.5.2&lt;/version&gt;&lt;/dependency&gt; 项目src/resources下需要配置文件c3p0.properties 1234567891011c3p0.JDBC.url=jdbc:mysql://localhost:3306/ms_cms?characterEncoding=utf8 --jdbc连接urlc3p0.DriverClass=com.mysql.jdbc.Driver --数据库驱动c3p0.user=root --用户名c3p0.pwd=xxx --密码c3p0.acquireIncrement=3 --当连接池中的连接耗尽时，一次性获取的连接数c3p0.idleConnectionTestPeriod=60 --检查连接池中的空闲连接c3p0.initialPoolSize=10 --初始化连接数c3p0.maxIdleTime=60 --最大空闲时间c3p0.maxPoolSize=20 --连接池最大连接数c3p0.maxStatements=100 --最大会话数c3p0.minPoolSize=5 --连接池最小连接数 java代码使用方法： 1234567891011121314151617181920212223242526272829public Connection dd() throws FileNotFoundException, IOException, PropertyVetoException, SQLException&#123; Properties pr = new Properties(); String c3p0Properties = this.getClass().getClassLoader().getResource(&quot;c3p0.properties&quot;).getPath(); //获得src下的c3p0.properties的路径 c3p0Properties = URLDecoder.decode(c3p0Properties, &quot;utf-8&quot;); //路径的编码是UTF-8 java.io.File c3p0File = new java.io.File(c3p0Properties); //得到文件c3p0.properties文件 pr.load(new FileInputStream(c3p0File)); //读取c3p0文件的内容 // pr.save(new FileOutputStream(c3p0File), null); ComboPooledDataSource cpds = new ComboPooledDataSource(); //使用c3p0操作数据库 cpds.setDriverClass(pr.getProperty(&quot;c3p0DriverClass&quot;)); //加载数据驱动 cpds.setJdbcUrl(pr.getProperty(&quot;c3p0.JDBC.url&quot;)); //连接特定的数据库 cpds.setUser(pr.getProperty(&quot;c3p0.user&quot;)); //数据库用户名 cpds.setPassword(pr.getProperty(&quot;c3p0.pwd&quot;)); //数据库用户密码 Connection conn = cpds.getConnection(); //获得连接 return conn; &#125;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>c3p0</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows远程连接linux图形界面配置详解]]></title>
    <url>%2F2017%2F12%2F28%2FWindows%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5linux%E5%9B%BE%E5%BD%A2%E7%95%8C%E9%9D%A2%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Windows远程连接linux图形界面，利用VNC服务实现windows远程连接linux图形化界面，linux作为VNC Server，windows作为VNC Viewer。原理很简单，在vnc server端生成一个桌面号，在vnc client端去连接该桌面号即可。其中很神奇的地方在于，如果两个人同时连接上一个桌面号的话，一个人可以看到另一个人的操作。 安装步骤 mini版centos安装图形化界面如果已经安装了图形化界面，则此步骤可以省略。 安装X window1yum groupinstall &quot;X Window System&quot; 安装GNOME Desktop1yum groupinstall &quot;GNOME Desktop&quot; 如果是centos7以前的版本，则安装命令为 1yum groupinstall &quot;Desktop&quot; 如果找不到Desktop，那么试试： 1yum grouplist 查看可以安装的group，可能不同的版本group组的名字不同。 启动gnome1startx 切换到图形化界面 linux安装VNC Server安装1yum install vnc-server –y 配置12cp /lib/systemd/system/vncserver@.service /etc/systemd/system/cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service 编辑vim /etc/systemd/system/vncserver@:1.service将更换为root 设置开机自启动1systemctl enable vncserver@:1.service 添加防火墙信任规则12firewall-cmd --permanent --add-service vnc-serverfirewall-cmd –reload 重启服务器reboot启动vnc服务启动方式： 1vncserver :桌面号 注意：中间需留有空格，桌面号用数字表示，表示每个用户占用一个桌面连接。以上命令执行的过程中，因为是第一次执行，需要输入密码，密码被加密/root/.vnc/passwd中；同时在用户主目录下的.vnc子目录中为用户自动建立xstartup配置文件（/root/.vnc/xstartup），在每次启动VND服务时，都会读取该文件中的配置信息。 VNC服务使用的端口号与桌面号的关系 windows安装VNC Viewer安装测试输入ip:桌面号连接 其他修改vnc密码1vncpasswd 关闭vnc服务1vncserver -kill :1 防火墙添加信任12firewall-cmd --permanent --add-service vnc-serverfirewall-cmd --reload]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>windows</tag>
        <tag>vnc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建maven私服nexus]]></title>
    <url>%2F2017%2F12%2F26%2F%E6%90%AD%E5%BB%BAmaven%E7%A7%81%E6%9C%8Dnexus%2F</url>
    <content type="text"><![CDATA[maven私服搭建，目的就是我们在使用maven打包时，如果私服中有相对应的包时，可以直接拉取过来，而不需要去下载，仅仅第一次使用该包时才会下载，这样会减少很多的时间，提高效率。 安装配置nexus下载：nexus下载解压： 1$ tar zxvf nexus-3.6.1-02-unix.tar.gz nexus详解文档参考 修改启动用户1$ vim $NEXUS_HOME/bin/nexus.rc 修改默认端口1$ vim $NEXUS_HOME/ etc/nexus-default.properties 启动1$ ./bin/nexus run 访问浏览器访问8081端口，默认登陆：user: adminpassword: admin123 配置maven-central：maven中央库，默认从https://repo1.maven.org/maven2上拉取jar包；maven-releases：私库发行版jar，初次安装nexus请将Deployment policy设置成Allow redeploy；maven-snapshots：私库快照调试版本jar；maven-public：仓库分组，把上面三个仓库组合起来一起对外提供服务，在本地maven配置settings.xml中使用。 本地maven使用私服nexusmaven默认配置settings.xml1234567891011121314151617181920212223242526272829303132333435363738394041&lt;servers&gt; &lt;server&gt; &lt;id&gt;releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt;&lt;/servers&gt;&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;url&gt;http://123.207.66.156:8081/repository/maven-public/&lt;/url&gt; &lt;/mirror&gt;&lt;/mirrors&gt;&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;Nexus&lt;/id&gt; &lt;url&gt;http://123.207.66.156:8081/repository/maven-public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;/profile&gt;&lt;/profiles&gt;&lt;activeProfiles&gt; &lt;activeProfile&gt;dev&lt;/activeProfile&gt;&lt;/activeProfiles&gt; 修改工程pom.xml123456789101112&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;releases&lt;/id&gt; &lt;name&gt;Releases&lt;/name&gt; &lt;url&gt;http://123.207.66.156:8081/repository/maven-releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;name&gt;Snapshot&lt;/name&gt; &lt;url&gt;http://123.207.66.156:8081/repository/maven-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt;&lt;/distributionManagement&gt; 注意上面的repository的id值一定要跟settings.xml文件中配置的server一致。]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>nexus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spark基于zookeeper的高可用搭建]]></title>
    <url>%2F2017%2F12%2F26%2Fspark%E5%9F%BA%E4%BA%8Ezookeeper%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[spark提供服务时，master的角色非常的重要，它负责任务分发、任务调度，可谓任重道远啊，所以我们要对master做高可用，基于zookeeper的高可用，可以自动实现master挂掉后备用的master启动，堆外提供服务。 节点分布：zookeeper: node1 node2 node3spark: node1 node2 node3 node4 编辑SPARK_HOME/conf/spark-env.sh注释掉HADOOP_CONF_DIR，添加SPARK_DAEMON_JAVA_OPTS，其他配置不变。 1export SPARK_DAEMON_JAVA_OPTS=&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=node1:2181,node2:2181,node3:2181 -Dspark.deploy.zookeeper.dir=/spark20170302&quot; 同步该配置文件spark-env.sh到其他节点scp spark-env.sh root@node2:$SPARK_HOME/confscp spark-env.sh root@node3:$SPARK_HOME/confscp spark-env.sh root@node4:$SPARK_HOME/conf 在node2节点上编辑spark-env.sh，将SPARK_MASTER_HOST修改为node21SPARK_MASTER_HOST=node2 启动spark服务在node1节点上启动spark集群 1$ ./sbin/start-all.sh 启动另一个master在node2节点上只启动master 1$ ./sbin/start-master.sh 访问webUI查看启动情况如果配置正确，启动正常，那么master会有两个（node1， node2），一个为ACTIVE状态，一个为STANDBY状态。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>spark</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019年世界上最好的机场]]></title>
    <url>%2F2017%2F12%2F26%2F2019%E5%B9%B4%E4%B8%96%E7%95%8C%E4%B8%8A%E6%9C%80%E5%A5%BD%E7%9A%84%E6%9C%BA%E5%9C%BA%2F</url>
    <content type="text"><![CDATA[机场的好坏，决定因素：1.要看城市的经济规模，政治、文化聚集度；2.有强大的基地航空公司或者合作关系；3.地理位置；4.政治环境； 如下是综合评价得到的世界机场排名： 1.樟宜（新加坡）2.羽田（东京）3.仁川（首尔）4.哈马德（多哈）5.香港机场（中国）6.中部国际机场（日本）7.慕尼黑机场（德国）8.希思罗机场（伦敦）9.成田（东京）10.苏黎世机场（瑞士）]]></content>
      <categories>
        <category>世界排名</category>
      </categories>
      <tags>
        <tag>世界机场</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单台服务器安装spark、hadoop服务文档]]></title>
    <url>%2F2017%2F12%2F26%2F%E5%8D%95%E5%8F%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%89%E8%A3%85spark%E3%80%81hadoop%E6%9C%8D%E5%8A%A1%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[spark作为分布式计算引擎，如果内存足够，是需要很少的磁盘空间的，在shuffle可能用到，在reduce阶段一定会用到，它是基于hdfs作为存储介质的，所以在使用spark时，应该搭建一个hdfs。 安装JDK1.8安装并配置环境变量，步骤略。 安装scala2.11.8安装并配置环境变量，步骤略。 hadoop伪分布式搭建关闭防火墙配置本机对本机免秘钥登录ssh-keygen -t rsa -P ‘’ -f ~/.ssh/id_rsassh-copy-id ip其中ip为本机ipSsh ip首次本机ssh本机需要输入密码或者yes，输入即可，第二次或者以后就不需要输入参数了。 下载hadoop-2.7.4.tar.gz包解压修改配置文件HADOOP_HOME/etc/hadoop下Hadoop.env.sh修改JAVA_HOME为jdk路径； Core-site.xmlFs.defaltFS属性修改为namenode的ipHadoop.tmp.dir修改为自定义目录，并创建好该目录 123456789101112&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://192.168.109.235:9000&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/root/chen/hadoop/data/temp&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;fs.trash.interval&lt;/name&gt; &lt;value&gt;1440&lt;/value&gt;&lt;/property&gt; Hdfs-site.xml使用默认值即可 12345678&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt;&lt;/property&gt; Mapred-env.sh修改JAVA_HOME为jdk路径，其他默认。 Mapred-site.xml1234&lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt; yarn-env.sh修改JAVA_HOME为java安装路径 yarn-site.xml123456789101112131415161718yarn.resourcemanager.hostname属性指定为namenode的ip地址。&lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;description&gt;The hostname of the RM.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;192.168.109.235&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt; &lt;value&gt;2048&lt;/value&gt;&lt;/property&gt; 添加slaves文件在HADOOP_HOME/etc/hadoop文件夹下添加slaves文件，指定datanode节点添加localhost即可。 格式化namenode./bin/hdfs namenode –format 启动hdfs./sbin/start-all.sh jps查看节点服务的启动情况如果启动正常，那么应该有NamenodeSecondaryNamenodeResourcemanagerNodemanagerDataNode这5个角色 Web Ui访问：http://ip:50070Spark搭建下载并解压spark-2.1.0-bin-hadoop2.7.tgz修改配置文件cp slaves.template slavescp spark-env.sh.template spark-env.shcp spark-defaults.conf.template spark-defaults.confvi spark-env.sh增加参数 123456789SPARK_MASTER_HOST=修改为ipSPARK_MASTER_PORT=7077SPARK_WORKER_CORES=2SPARK_WORKER_MEMORY=4gSPARK_WORKER_INSTANCES=3HADOOP_CONF_DIR=/chen/hadoop2.7/hadoop-2.7.4/etc/hadoop修改为hadoop配置文件的位置SPARK_DRIVER_MEMORY=1024MJAVA_HOME=/chen/jdk8/jdk1.8.0_144修改为jdk的路径MAVEN_OPTS=&quot;-Xms1024m -Xmx4096m -XX:PermSize=1024m&quot; vi spark-deafults.conf其中需要修改hdfs的ip地址，并创建路径/user/spark/logs 启动spark./sbin/start-all.sh正常启动的话应该有：1个Master3个Worker两个角色Web Ui访问http://ip:8080]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux高效编程]]></title>
    <url>%2F2017%2F12%2F25%2Flinux%E9%AB%98%E6%95%88%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[本文将介绍linux命令行经常使用到的一些快捷键、编辑命令，还有强大的vim编辑器，能让你在linux上编程更高效。作为一个程序员，会使用各种快捷键不也是更炫酷的一件事吗？ linux命令行光标移动1234567891011121314151617181920212223ctrl+a --- 把光标移到行首（ahead）ctrl+e --- 把光标移到行尾（end）ctrl+l --- 清除终端（clear）ctrl+u --- 删除当前字符到行首（带有剪切功能）ctrl+k --- 删除当前字符到行尾（带有剪切功能）ctrl+y --- 粘贴ctrl+f --- 向前移动一个字符（forward）ctrl+b --- 向后移动一个字符（back）ctrl+左右箭头 --- 把光标在单词之间左右移动ctrl+w --- 删除光标前面的单词cd ~ --- 进入home目录cd - --- 返回上一目录mkdir -p path/to/filealias cd3=”cd ../../../”rename ‘.java’ ‘.java.bak’ *.java --- 批量备份文件ctrl+r --- 查询历史命令history --- 历史命令执行历史命令方法 --- ！+ 命令序号ctrl+p --- 上一条命令（或者上下箭头） 查找进程12345678910进程 进程号 所占用端口号ps -ef显示所有进程信息，包括命令行，与grep配合使用，查找特定进程显示环境变量ps -aux显示所有进程信息，包括资源占用情况，与grep配合使用netstat -anp显示协议、端口、进程号、进程名称等信息 Vimvim与vi的区别：增加了新特性：语法高亮、可视化操作、多平台支持（windows、mac、terminal） 正常模式：浏览和修改文本内容1234567891011121314151617181920R --- 替换（覆盖）当前光标位置及后面的若干文本J --- 合并当前行及下一行为一行j --- 下k --- 上h --- 左l --- 右H --- 当前屏幕第一行M --- 当前屏幕中间行L --- 当前屏幕最后一行w --- 当前光标移至下一个单词词首b --- 当前光标移至上一个单词词首e --- 下一个单词词尾$ --- 当前光标移至行尾^ --- 当前光标移至行首u --- 撤销ctrl+r --- 恢复上一步被撤销的动作 复制123456yy --- 复制当前行5yy --- 复制当前行和后4行yw --- 当前字符到下一单词的起始位置y$ --- 当前字符到当前行末尾y0/y^ --- 当前字符到当前行行首yngg/ynG --- 复制当前行到文件第n行 粘贴1p 删除1234567dw --- 删除当前光标至单词末尾ndw --- 删除当前光标后的n个字符dd --- 删除当前行d$ --- 删除光标位置至行尾d^ --- 删除光标位置至行首dgg --- 删除首行至当前行dG --- 删除当前行至末行 编辑模式 — 编辑文本从正常模式进入编辑模式 123456a --- 在当前光标位置的右边添加文本A --- 在当前行的末尾位置添加文本i --- 在当前光标位置的左边添加文本I --- 在当前行的开始处添加文本(非空字符的行首)O --- 在当前行的上面新建一行o --- 在当前行的下面新建一行 可视模式：高亮选取文本后的正常模式1234v+hjkl --- 选中文本后y复制d剪切，p粘贴ctrl+v --- 以块为选取单位V --- 以行为选取单位行、块为选取单位的模式可以随意切换 命令行模式：操作文本文件123456w --- 保存wq --- 保存并退出q --- 退出q! --- 不保存退出/ --- 查询，n下一个匹配字符串，N上一个匹配字符串:set number --- 设置行号]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[以Hexo网页制作模板构建Github Pages个人网站]]></title>
    <url>%2F2017%2F12%2F19%2FcreateWebsiteHelp%2F</url>
    <content type="text"><![CDATA[个人网站制作过程，以Hexo为例，为大家讲解如何制作，如果有什么错误的地方，欢迎指正，如果有什么不懂的地方，可以email我：chenzuoli709@gmail.com。具体请看详细内容 —&gt; 1.准备环境Node.jsGit 2.安装Hexo1$ npm install -g hexo-cli 3.创建github pagesGithub官网项目名称为.github.io 4.配置Hexo123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install 初始化完成后，该目录下的文件结构如下： 1234567_config.yml --- 全局配置文件package.jsonscaffolds --- 模板source --- 文件仓库 _drafts --- 草稿 _posts --- 发布过的文件themes --- 主题 编辑_config.yml：指定项目部署的方式为git，上传到远程仓库repo的master分支上 1234deploy: type: git repo: https://github.com/chenzuoli/chenzuoli.github.io.git branch: master 5.部署12hexo generate --- 生成hexo deploy --- 部署到github 6.域名映射第一步：登录你购买域名服务商提供给你的域名管理中心，我购买的是腾讯云，域名为chenzuoli.com，首先绑定主域名映射到github.com所对应的ip地址，绑定完成后，隔几分钟测试，因为DNS解析先从你的域名提供商开始，然后到其他的域名提供商，再到国外： 1ping chenzuoli.com 看是否能够ping通，如果ping通，说明域名映射已经ok了第二步：登录github到.github.io项目，进入settings选项，设置自定义域名chenzuoli.com，save后，可以看到在该项目下会自动生成一个CNAME的文件，文件内容就是你设置的域名chenzuoli.com。稍等几分钟，就可以访问chenzuoli.com了。这里说明一下域名映射的流程：chenzuoli.com -&gt; github.com -&gt; chenzuoli.github.iochenzuoli.com映射到github.com，然后github.com会解析该请求寻找CNAME为chenzuoli.com的项目，然后就找到了chenzuoli.github.io，于是就可以访问了。大家赶紧试试吧。]]></content>
      <tags>
        <tag>hexo</tag>
        <tag>github pages</tag>
        <tag>blog</tag>
      </tags>
  </entry>
</search>
